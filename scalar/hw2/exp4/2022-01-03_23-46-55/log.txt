#!/bin/bash
export PYTHONPATH=.

DATA_DIR=./data
EXP_DIR=${DATA_DIR}/exp4/`date +%Y-%m-%d_%H-%M-%S`
LOG_PATH=${EXP_DIR}/log.txt
# clear other data files
rm -rf $(find ${DATA_DIR} -maxdepth 1 -name '*q4_*' 2> /dev/null)
# create data directory for this experiment and logfile
mkdir -p $EXP_DIR; touch $LOG_PATH
# dump experiment commands and hyperparameters (this file) to logfile
cat $0 >> $LOG_PATH; echo "\n\n" >> $LOG_PATH

# for b in 10000 30000 50000; do
#     for r in 0.005 0.01 0.02; do
#     python cs285/scripts/run_hw2.py --env_name HalfCheetah-v2 --ep_len 150 \
#         --discount 0.95 -n 100 -l 2 -s 32 -b ${b} -lr ${r} -rtg --nn_baseline \
#         --exp_name q4_search_b${b}_lr${r}_rtg_nnbaseline >> $LOG_PATH
#     done
# done

b=30000
lr=0.02
python cs285/scripts/run_hw2.py --env_name HalfCheetah-v2 --ep_len 150 \
    --discount 0.95 -n 100 -l 2 -s 32 -b ${b} -lr ${lr} \
    --exp_name q4_b${b}_r${lr} >> $LOG_PATH &

python cs285/scripts/run_hw2.py --env_name HalfCheetah-v2 --ep_len 150 \
    --discount 0.95 -n 100 -l 2 -s 32 -b ${b} -lr ${lr} -rtg \
    --exp_name q4_b${b}_r${lr}_rtg >> $LOG_PATH &

python cs285/scripts/run_hw2.py --env_name HalfCheetah-v2 --ep_len 150 \
    --discount 0.95 -n 100 -l 2 -s 32 -b ${b} -lr ${lr} --nn_baseline \
    --exp_name q4_b${b}_r${lr}_nnbaseline >> $LOG_PATH &

python cs285/scripts/run_hw2.py --env_name HalfCheetah-v2 --ep_len 150 \
    --discount 0.95 -n 100 -l 2 -s 32 -b ${b} -lr ${lr} -rtg --nn_baseline \
    --exp_name q4_b${b}_r${lr}_rtg_nnbaseline >> $LOG_PATH &

wait

# move data file to experiment data directory
mv $(find ${DATA_DIR} -maxdepth 1 -name '*q4_*' 2> /dev/null) $EXP_DIR



########################
logging outputs to  /home/zzh/Desktop/hw2/cs285/scripts/../../data/q2_pg_q4_b30000_r0.02_rtg_nnbaseline_HalfCheetah-v2_2022-01-03_23-46-55
########################
Using GPU id 0


********** Iteration 0 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -72.96001434326172
Eval_StdReturn : 16.113019943237305
Eval_MaxReturn : -50.40350341796875
Eval_MinReturn : -87.03953552246094
Eval_AverageEpLen : 150.0
Train_AverageReturn : -88.6635513305664
Train_StdReturn : 35.259578704833984
Train_MaxReturn : -6.332161903381348
Train_MinReturn : -179.19308471679688
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 30000
TimeSinceStart : 57.79471731185913
Training Loss : -0.04264784976840019
Baseline Loss : 1.0207469463348389
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -64.46845245361328
Eval_StdReturn : 24.06587791442871
Eval_MaxReturn : -40.046688079833984
Eval_MinReturn : -97.20816040039062
Eval_AverageEpLen : 150.0
Train_AverageReturn : -83.49671936035156
Train_StdReturn : 35.5989875793457
Train_MaxReturn : -11.876167297363281
Train_MinReturn : -171.1678466796875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 60000
TimeSinceStart : 115.97475504875183
Training Loss : -0.05950387194752693
Baseline Loss : 1.2063874006271362
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 2 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -83.06905364990234
Eval_StdReturn : 14.68069839477539
Eval_MaxReturn : -70.45013427734375
Eval_MinReturn : -103.65634155273438
Eval_AverageEpLen : 150.0
Train_AverageReturn : -77.48397827148438
Train_StdReturn : 30.29902458190918
Train_MaxReturn : 8.66446304321289
Train_MinReturn : -160.73646545410156
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 90000
TimeSinceStart : 174.97458720207214
Training Loss : -0.06854047626256943
Baseline Loss : 1.0380606651306152
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 3 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -71.6136703491211
Eval_StdReturn : 39.296592712402344
Eval_MaxReturn : -21.911788940429688
Eval_MinReturn : -117.99658203125
Eval_AverageEpLen : 150.0
Train_AverageReturn : -73.29414367675781
Train_StdReturn : 29.629077911376953
Train_MaxReturn : 5.225554466247559
Train_MinReturn : -211.72987365722656
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 120000
TimeSinceStart : 233.85255765914917
Training Loss : -0.06933020055294037
Baseline Loss : 1.00505793094635
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 4 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -96.9802017211914
Eval_StdReturn : 60.61022186279297
Eval_MaxReturn : -48.26261901855469
Eval_MinReturn : -182.41555786132812
Eval_AverageEpLen : 150.0
Train_AverageReturn : -71.23564147949219
Train_StdReturn : 29.03510093688965
Train_MaxReturn : 15.649858474731445
Train_MinReturn : -162.5025634765625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 150000
TimeSinceStart : 293.50105929374695
Training Loss : -0.07414799928665161
Baseline Loss : 1.0116596221923828
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 5 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -60.690338134765625
Eval_StdReturn : 30.473066329956055
Eval_MaxReturn : -30.376689910888672
Eval_MinReturn : -102.37495422363281
Eval_AverageEpLen : 150.0
Train_AverageReturn : -70.2860336303711
Train_StdReturn : 31.927490234375
Train_MaxReturn : 48.78816223144531
Train_MinReturn : -200.71316528320312
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 180000
TimeSinceStart : 352.0434465408325
Training Loss : -0.05430908501148224
Baseline Loss : 0.9972848296165466
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 6 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -49.96732711791992
Eval_StdReturn : 20.027435302734375
Eval_MaxReturn : -22.469810485839844
Eval_MinReturn : -69.59504699707031
Eval_AverageEpLen : 150.0
Train_AverageReturn : -66.75743103027344
Train_StdReturn : 33.726837158203125
Train_MaxReturn : 24.912662506103516
Train_MinReturn : -145.58932495117188
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 210000
TimeSinceStart : 412.91818165779114
Training Loss : -0.06166593357920647
Baseline Loss : 0.9785815477371216
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 7 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -47.9249267578125
Eval_StdReturn : 24.969972610473633
Eval_MaxReturn : -12.807004928588867
Eval_MinReturn : -68.69292449951172
Eval_AverageEpLen : 150.0
Train_AverageReturn : -62.684207916259766
Train_StdReturn : 30.909711837768555
Train_MaxReturn : 33.81820297241211
Train_MinReturn : -181.448974609375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 240000
TimeSinceStart : 477.0648274421692
Training Loss : -0.04364095255732536
Baseline Loss : 0.9684377908706665
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 8 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -83.66197967529297
Eval_StdReturn : 19.002897262573242
Eval_MaxReturn : -62.78858184814453
Eval_MinReturn : -108.75784301757812
Eval_AverageEpLen : 150.0
Train_AverageReturn : -59.41460418701172
Train_StdReturn : 34.63930892944336
Train_MaxReturn : 14.005029678344727
Train_MinReturn : -166.34719848632812
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 270000
TimeSinceStart : 538.3778927326202
Training Loss : -0.06760909408330917
Baseline Loss : 0.9581337571144104
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 9 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -62.462066650390625
Eval_StdReturn : 14.72479248046875
Eval_MaxReturn : -47.32880783081055
Eval_MinReturn : -82.41690063476562
Eval_AverageEpLen : 150.0
Train_AverageReturn : -56.78010559082031
Train_StdReturn : 34.76042556762695
Train_MaxReturn : 56.315406799316406
Train_MinReturn : -159.16937255859375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 300000
TimeSinceStart : 599.1531796455383
Training Loss : -0.04777800291776657
Baseline Loss : 0.9489585757255554
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 10 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -60.9956169128418
Eval_StdReturn : 19.797195434570312
Eval_MaxReturn : -43.547760009765625
Eval_MinReturn : -88.68194580078125
########################
logging outputs to  /home/zzh/Desktop/hw2/cs285/scripts/../../data/q2_pg_q4_b30000_r0.02_HalfCheetah-v2_2022-01-03_23-46-55
########################
Using GPU id 0


********** Iteration 0 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -133.05914306640625
Eval_StdReturn : 29.99561882019043
Eval_MaxReturn : -96.88758850097656
Eval_MinReturn : -170.33657836914062
Eval_AverageEpLen : 150.0
Train_AverageReturn : -88.6635513305664
Train_StdReturn : 35.259578704833984
Train_MaxReturn : -6.332161903381348
Train_MinReturn : -179.19308471679688
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 30000
TimeSinceStart : 57.74047517776489
Training Loss : 0.003799545345827937
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -80.57038116455078
Eval_StdReturn : 27.98489761352539
Eval_MaxReturn : -41.12679672241211
Eval_MinReturn : -103.10005187988281
Eval_AverageEpLen : 150.0
Train_AverageReturn : -92.72562408447266
Train_StdReturn : 37.970672607421875
Train_MaxReturn : 2.7300052642822266
Train_MinReturn : -216.80197143554688
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 60000
TimeSinceStart : 115.89485025405884
Training Loss : -0.029937811195850372
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 2 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -101.54720306396484
Eval_StdReturn : 26.520191192626953
Eval_MaxReturn : -66.8293228149414
Eval_MinReturn : -131.19363403320312
Eval_AverageEpLen : 150.0
Train_AverageReturn : -96.5064468383789
Train_StdReturn : 34.74520492553711
Train_MaxReturn : -22.020801544189453
Train_MinReturn : -217.8456573486328
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 90000
TimeSinceStart : 174.758118391037
Training Loss : -0.010607922449707985
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 3 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -82.7237319946289
Eval_StdReturn : 14.599438667297363
Eval_MaxReturn : -71.45240020751953
Eval_MinReturn : -103.34049987792969
Eval_AverageEpLen : 150.0
Train_AverageReturn : -98.09309387207031
Train_StdReturn : 33.8241081237793
Train_MaxReturn : 1.003401756286621
Train_MinReturn : -199.6168975830078
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 120000
TimeSinceStart : 233.63043093681335
Training Loss : -0.020414717495441437
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 4 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -84.14168548583984
Eval_StdReturn : 25.550357818603516
Eval_MaxReturn : -63.32631301879883
Eval_MinReturn : -120.12810516357422
Eval_AverageEpLen : 150.0
Train_AverageReturn : -99.12464904785156
Train_StdReturn : 31.401357650756836
Train_MaxReturn : -27.097143173217773
Train_MinReturn : -213.55116271972656
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 150000
TimeSinceStart : 293.20347356796265
Training Loss : -0.006494923960417509
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 5 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -80.29098510742188
Eval_StdReturn : 12.354850769042969
Eval_MaxReturn : -62.927398681640625
Eval_MinReturn : -90.65885162353516
Eval_AverageEpLen : 150.0
Train_AverageReturn : -96.16494750976562
Train_StdReturn : 34.47283172607422
Train_MaxReturn : 3.9891834259033203
Train_MinReturn : -180.312255859375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 180000
TimeSinceStart : 351.6789710521698
Training Loss : -0.0018063151510432363
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 6 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -116.91446685791016
Eval_StdReturn : 8.843574523925781
Eval_MaxReturn : -108.87586975097656
Eval_MinReturn : -129.23129272460938
Eval_AverageEpLen : 150.0
Train_AverageReturn : -98.78654479980469
Train_StdReturn : 34.03858184814453
Train_MaxReturn : -4.007534027099609
Train_MinReturn : -204.16741943359375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 210000
TimeSinceStart : 412.54477643966675
Training Loss : -0.014670947566628456
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 7 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -143.65274047851562
Eval_StdReturn : 17.64116859436035
Eval_MaxReturn : -123.87686920166016
Eval_MinReturn : -166.71270751953125
Eval_AverageEpLen : 150.0
Train_AverageReturn : -107.02660369873047
Train_StdReturn : 33.67168426513672
Train_MaxReturn : -22.739028930664062
Train_MinReturn : -276.51019287109375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 240000
TimeSinceStart : 476.8549723625183
Training Loss : -0.011491160839796066
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 8 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -123.44766998291016
Eval_StdReturn : 42.187767028808594
Eval_MaxReturn : -93.42469787597656
Eval_MinReturn : -183.10977172851562
Eval_AverageEpLen : 150.0
Train_AverageReturn : -103.09252166748047
Train_StdReturn : 28.66476058959961
Train_MaxReturn : -32.42232894897461
Train_MinReturn : -208.066650390625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 270000
TimeSinceStart : 538.1276502609253
Training Loss : -0.029379162937402725
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 9 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -104.9301986694336
Eval_StdReturn : 36.256141662597656
Eval_MaxReturn : -71.21167755126953
Eval_MinReturn : -155.2417755126953
Eval_AverageEpLen : 150.0
Train_AverageReturn : -106.41681671142578
Train_StdReturn : 30.550861358642578
Train_MaxReturn : -24.600727081298828
Train_MinReturn : -197.07826232910156
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 300000
TimeSinceStart : 598.950187921524
Training Loss : -0.012479353696107864
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 10 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -71.74797821044922
Eval_StdReturn : 11.492506980895996
Eval_MaxReturn : -59.75044250488281
Eval_MinReturn : -87.24205780029297
Eval_AverageEpLen : 150.0
Train_AverageReturn : -112.429443359375
Train_StdReturn : 34.08079528808594
Train_MaxReturn : 0.6382908821105957
Train_MinReturn : -203.80978393554688
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 330000
TimeSinceStart : 660.0843148231506
Training Loss : -0.0056751687079668045
########################
logging outputs to  /home/zzh/Desktop/hw2/cs285/scripts/../../data/q2_pg_q4_b30000_r0.02_rtg_HalfCheetah-v2_2022-01-03_23-46-55
########################
Using GPU id 0


********** Iteration 0 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -96.56005859375
Eval_StdReturn : 25.320926666259766
Eval_MaxReturn : -65.50827026367188
Eval_MinReturn : -127.53146362304688
Eval_AverageEpLen : 150.0
Train_AverageReturn : -88.6635513305664
Train_StdReturn : 35.259578704833984
Train_MaxReturn : -6.332161903381348
Train_MinReturn : -179.19308471679688
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 30000
TimeSinceStart : 57.843754053115845
Training Loss : -0.07158958166837692
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -60.81502151489258
Eval_StdReturn : 11.739953994750977
Eval_MaxReturn : -44.38471221923828
Eval_MinReturn : -71.097412109375
Eval_AverageEpLen : 150.0
Train_AverageReturn : -82.1352310180664
Train_StdReturn : 33.851539611816406
Train_MaxReturn : 17.10694694519043
Train_MinReturn : -172.88516235351562
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 60000
TimeSinceStart : 116.00707459449768
Training Loss : -0.07940403372049332
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 2 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -72.73368072509766
Eval_StdReturn : 6.209867477416992
Eval_MaxReturn : -64.60108947753906
Eval_MinReturn : -79.67041015625
Eval_AverageEpLen : 150.0
Train_AverageReturn : -73.84545135498047
Train_StdReturn : 34.57876205444336
Train_MaxReturn : 4.773445129394531
Train_MinReturn : -202.0938720703125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 90000
TimeSinceStart : 174.8482310771942
Training Loss : -0.07581860572099686
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 3 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -61.63603210449219
Eval_StdReturn : 22.109481811523438
Eval_MaxReturn : -45.4021110534668
Eval_MinReturn : -92.89578247070312
Eval_AverageEpLen : 150.0
Train_AverageReturn : -69.4795150756836
Train_StdReturn : 26.385629653930664
Train_MaxReturn : 2.079357147216797
Train_MinReturn : -161.94175720214844
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 120000
TimeSinceStart : 233.71356105804443
Training Loss : -0.09350327402353287
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 4 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -40.413272857666016
Eval_StdReturn : 19.206308364868164
Eval_MaxReturn : -13.612439155578613
Eval_MinReturn : -57.63597869873047
Eval_AverageEpLen : 150.0
Train_AverageReturn : -63.25315475463867
Train_StdReturn : 25.203384399414062
Train_MaxReturn : 32.976104736328125
Train_MinReturn : -134.72979736328125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 150000
TimeSinceStart : 293.26331400871277
Training Loss : -0.0832354873418808
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 5 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -76.28289794921875
Eval_StdReturn : 35.65339660644531
Eval_MaxReturn : -43.080474853515625
Eval_MinReturn : -125.74664306640625
Eval_AverageEpLen : 150.0
Train_AverageReturn : -60.69906234741211
Train_StdReturn : 24.189823150634766
Train_MaxReturn : 4.082562446594238
Train_MinReturn : -120.89572143554688
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 180000
TimeSinceStart : 351.7691433429718
Training Loss : -0.08955004066228867
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 6 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -87.71900177001953
Eval_StdReturn : 26.44636344909668
Eval_MaxReturn : -61.42216110229492
Eval_MinReturn : -123.8994140625
Eval_AverageEpLen : 150.0
Train_AverageReturn : -58.011199951171875
Train_StdReturn : 27.336803436279297
Train_MaxReturn : 17.09352684020996
Train_MinReturn : -161.43161010742188
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 210000
TimeSinceStart : 412.6099269390106
Training Loss : -0.05783125013113022
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 7 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -50.03572463989258
Eval_StdReturn : 1.5471333265304565
Eval_MaxReturn : -48.425113677978516
Eval_MinReturn : -52.123558044433594
Eval_AverageEpLen : 150.0
Train_AverageReturn : -54.00835037231445
Train_StdReturn : 29.609634399414062
Train_MaxReturn : 25.809951782226562
Train_MinReturn : -132.56613159179688
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 240000
TimeSinceStart : 477.10350704193115
Training Loss : -0.07695022970438004
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 8 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -47.81185531616211
Eval_StdReturn : 7.503772258758545
Eval_MaxReturn : -41.744171142578125
Eval_MinReturn : -58.38541030883789
Eval_AverageEpLen : 150.0
Train_AverageReturn : -47.239532470703125
Train_StdReturn : 28.13686752319336
Train_MaxReturn : 41.944313049316406
Train_MinReturn : -139.96337890625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 270000
TimeSinceStart : 538.6827256679535
Training Loss : -0.07267206162214279
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 9 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -52.2986946105957
Eval_StdReturn : 25.234210968017578
Eval_MaxReturn : -21.82094955444336
Eval_MinReturn : -83.61483001708984
Eval_AverageEpLen : 150.0
Train_AverageReturn : -47.71699142456055
Train_StdReturn : 30.14362144470215
Train_MaxReturn : 16.454627990722656
Train_MinReturn : -152.57504272460938
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 300000
TimeSinceStart : 599.6575169563293
Training Loss : -0.07213418185710907
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 10 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -37.02871322631836
Eval_StdReturn : 27.52043342590332
Eval_MaxReturn : 1.5125885009765625
Eval_MinReturn : -60.988441467285156
Eval_AverageEpLen : 150.0
Train_AverageReturn : -42.28255844116211
Train_StdReturn : 27.11612892150879
Train_MaxReturn : 17.705156326293945
Train_MinReturn : -124.4244384765625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 330000
TimeSinceStart : 661.2578024864197
Training Loss : -0.061367832124233246
Initial_DataCollection_AverageReturn : -88.6635513305664
########################
logging outputs to  /home/zzh/Desktop/hw2/cs285/scripts/../../data/q2_pg_q4_b30000_r0.02_nnbaseline_HalfCheetah-v2_2022-01-03_23-46-55
########################
Using GPU id 0


********** Iteration 0 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -99.0215835571289
Eval_StdReturn : 18.84063148498535
Eval_MaxReturn : -76.61103057861328
Eval_MinReturn : -122.70802307128906
Eval_AverageEpLen : 150.0
Train_AverageReturn : -88.6635513305664
Train_StdReturn : 35.259578704833984
Train_MaxReturn : -6.332161903381348
Train_MinReturn : -179.19308471679688
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 30000
TimeSinceStart : 57.85226345062256
Training Loss : 0.010975239798426628
Baseline Loss : 1.0229240655899048
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -93.746826171875
Eval_StdReturn : 16.77338218688965
Eval_MaxReturn : -70.02583312988281
Eval_MinReturn : -105.68063354492188
Eval_AverageEpLen : 150.0
Train_AverageReturn : -101.23815155029297
Train_StdReturn : 37.24448013305664
Train_MaxReturn : -3.335592269897461
Train_MinReturn : -203.84312438964844
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 60000
TimeSinceStart : 116.00847220420837
Training Loss : -0.025695862248539925
Baseline Loss : 1.230404257774353
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 2 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -76.29651641845703
Eval_StdReturn : 24.069143295288086
Eval_MaxReturn : -42.61836624145508
Eval_MinReturn : -97.41603088378906
Eval_AverageEpLen : 150.0
Train_AverageReturn : -97.34357452392578
Train_StdReturn : 36.691951751708984
Train_MaxReturn : -1.5144157409667969
Train_MinReturn : -218.21109008789062
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 90000
TimeSinceStart : 174.98388600349426
Training Loss : -0.020202158018946648
Baseline Loss : 1.0536079406738281
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 3 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -85.26294708251953
Eval_StdReturn : 13.982024192810059
Eval_MaxReturn : -65.52861022949219
Eval_MinReturn : -96.20828247070312
Eval_AverageEpLen : 150.0
Train_AverageReturn : -102.24618530273438
Train_StdReturn : 37.862857818603516
Train_MaxReturn : -8.097829818725586
Train_MinReturn : -210.25343322753906
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 120000
TimeSinceStart : 233.9363694190979
Training Loss : 0.005445458926260471
Baseline Loss : 1.007041573524475
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 4 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -74.68920135498047
Eval_StdReturn : 24.862565994262695
Eval_MaxReturn : -39.627864837646484
Eval_MinReturn : -94.51068115234375
Eval_AverageEpLen : 150.0
Train_AverageReturn : -104.13117218017578
Train_StdReturn : 37.73740768432617
Train_MaxReturn : 3.3156943321228027
Train_MinReturn : -228.72830200195312
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 150000
TimeSinceStart : 293.71508955955505
Training Loss : -0.02497692219913006
Baseline Loss : 1.0206434726715088
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 5 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -103.35482025146484
Eval_StdReturn : 13.726785659790039
Eval_MaxReturn : -83.94772338867188
Eval_MinReturn : -113.45896911621094
Eval_AverageEpLen : 150.0
Train_AverageReturn : -103.0449447631836
Train_StdReturn : 36.110389709472656
Train_MaxReturn : -8.828926086425781
Train_MinReturn : -204.57232666015625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 180000
TimeSinceStart : 352.27938985824585
Training Loss : -0.014098014682531357
Baseline Loss : 1.018241047859192
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 6 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -94.40017700195312
Eval_StdReturn : 30.513076782226562
Eval_MaxReturn : -51.2520866394043
Eval_MinReturn : -116.47798156738281
Eval_AverageEpLen : 150.0
Train_AverageReturn : -116.17048645019531
Train_StdReturn : 40.736507415771484
Train_MaxReturn : 28.84497833251953
Train_MinReturn : -230.1486358642578
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 210000
TimeSinceStart : 413.36213088035583
Training Loss : -0.006304850336164236
Baseline Loss : 1.0112072229385376
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 7 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -123.3442611694336
Eval_StdReturn : 11.869022369384766
Eval_MaxReturn : -112.74800109863281
Eval_MinReturn : -139.916259765625
Eval_AverageEpLen : 150.0
Train_AverageReturn : -116.23853302001953
Train_StdReturn : 40.944339752197266
Train_MaxReturn : -15.499832153320312
Train_MinReturn : -270.8310241699219
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 240000
TimeSinceStart : 478.2145504951477
Training Loss : -0.007995596155524254
Baseline Loss : 1.0055738687515259
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 8 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -101.18683624267578
Eval_StdReturn : 20.24300765991211
Eval_MaxReturn : -80.00121307373047
Eval_MinReturn : -128.45436096191406
Eval_AverageEpLen : 150.0
Train_AverageReturn : -113.9269790649414
Train_StdReturn : 41.71485137939453
Train_MaxReturn : -11.119009017944336
Train_MinReturn : -230.7464599609375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 270000
TimeSinceStart : 539.7514598369598
Training Loss : -0.018842848017811775
Baseline Loss : 1.0051907300949097
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 9 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -132.5738983154297
Eval_StdReturn : 28.231952667236328
Eval_MaxReturn : -98.99090576171875
Eval_MinReturn : -168.06570434570312
Eval_AverageEpLen : 150.0
Train_AverageReturn : -115.84403991699219
Train_StdReturn : 40.218963623046875
Train_MaxReturn : -33.46520233154297
Train_MinReturn : -243.53915405273438
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 300000
TimeSinceStart : 600.686199426651
Training Loss : -0.0074027711525559425
Baseline Loss : 1.006321907043457
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 10 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -134.03260803222656
Eval_StdReturn : 49.8463020324707
Eval_MaxReturn : -79.329833984375
Eval_MinReturn : -199.8896484375
Eval_AverageEpLen : 150.0
Train_AverageReturn : -118.54206085205078
Train_StdReturn : 38.88249206542969
Train_MaxReturn : -20.294878005981445
Train_MinReturn : -231.1673583984375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 330000
TimeSinceStart : 662.16122174263
Training Loss : -0.026558682322502136
Baseline Loss : 0.9993725419044495
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -132.3542938232422
Eval_StdReturn : 21.930641174316406
Eval_MaxReturn : -108.88665771484375
Eval_MinReturn : -161.64892578125
Eval_AverageEpLen : 150.0
Train_AverageReturn : -118.63156127929688
Train_StdReturn : 34.35927963256836
Train_MaxReturn : -15.461398124694824
Train_MinReturn : -208.31143188476562
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 360000
TimeSinceStart : 726.1296677589417
Training Loss : 0.0020204326137900352
Baseline Loss : 0.9965470433235168
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 12 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -122.19058990478516
Eval_StdReturn : 9.311745643615723
Eval_MaxReturn : -115.41169738769531
Eval_MinReturn : -135.35745239257812
Eval_AverageEpLen : 150.0
Train_AverageReturn : -120.24832916259766
Train_StdReturn : 33.68438720703125
Train_MaxReturn : -7.225770950317383
Train_MinReturn : -222.95404052734375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 390000
TimeSinceStart : 787.9373736381531
Training Loss : -0.018641628324985504
Baseline Loss : 0.992808997631073
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 13 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -137.02244567871094
Eval_StdReturn : 3.2309463024139404
Eval_MaxReturn : -133.06544494628906
Eval_MinReturn : -140.9796142578125
Eval_AverageEpLen : 150.0
Train_AverageReturn : -129.96914672851562
Train_StdReturn : 35.23918533325195
Train_MaxReturn : -40.84283447265625
Train_MinReturn : -260.0426025390625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 420000
TimeSinceStart : 848.4875524044037
Training Loss : -0.0060661244206130505
Baseline Loss : 0.9906126856803894
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 14 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -111.1612777709961
Eval_StdReturn : 19.196243286132812
Eval_MaxReturn : -88.63688659667969
Eval_MinReturn : -135.54721069335938
Eval_AverageEpLen : 150.0
Train_AverageReturn : -129.75466918945312
Train_StdReturn : 33.07430648803711
Train_MaxReturn : -4.007881164550781
Train_MinReturn : -218.43768310546875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 450000
TimeSinceStart : 909.6031565666199
Training Loss : -0.0068929484114050865
Baseline Loss : 0.9875815510749817
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 15 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -124.14102935791016
Eval_StdReturn : 11.151270866394043
Eval_MaxReturn : -108.52092742919922
Eval_MinReturn : -133.83139038085938
Eval_AverageEpLen : 150.0
Train_AverageReturn : -133.0751953125
Train_StdReturn : 32.272151947021484
Train_MaxReturn : -55.39015197753906
Train_MinReturn : -247.27532958984375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 480000
TimeSinceStart : 970.7053170204163
Training Loss : -0.025190269574522972
Baseline Loss : 0.9892472624778748
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 16 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -166.06637573242188
Eval_StdReturn : 23.622604370117188
Eval_MaxReturn : -132.89617919921875
Eval_MinReturn : -186.09307861328125
Eval_AverageEpLen : 150.0
Train_AverageReturn : -131.13253784179688
Train_StdReturn : 31.15691375732422
Train_MaxReturn : -28.260587692260742
Train_MinReturn : -247.95684814453125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 510000
TimeSinceStart : 1032.1796853542328
Training Loss : -0.017962926998734474
Baseline Loss : 0.987359881401062
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 17 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -113.44342041015625
Eval_StdReturn : 38.87085723876953
Eval_MaxReturn : -75.03291320800781
Eval_MinReturn : -166.70582580566406
Eval_AverageEpLen : 150.0
Train_AverageReturn : -123.0658187866211
Train_StdReturn : 28.85357093811035
Train_MaxReturn : -57.76226806640625
Train_MinReturn : -234.99440002441406
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 540000
TimeSinceStart : 1092.9521372318268
Training Loss : -0.0109831178560853
Baseline Loss : 0.9869505763053894
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 18 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -132.4180908203125
Eval_StdReturn : 40.1755256652832
Eval_MaxReturn : -77.1639175415039
Eval_MinReturn : -171.50559997558594
Eval_AverageEpLen : 150.0
Train_AverageReturn : -113.51724243164062
Train_StdReturn : 32.79765701293945
Train_MaxReturn : -28.765766143798828
Train_MinReturn : -212.84246826171875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 570000
TimeSinceStart : 1154.8974616527557
Training Loss : -0.008093282580375671
Baseline Loss : 0.9843317866325378
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 19 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -88.97095489501953
Eval_StdReturn : 17.20050048828125
Eval_MaxReturn : -71.9116439819336
Eval_MinReturn : -112.51795959472656
Eval_AverageEpLen : 150.0
Train_AverageReturn : -111.40374755859375
Train_StdReturn : 31.141159057617188
Train_MaxReturn : -28.24102783203125
Train_MinReturn : -227.21835327148438
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 600000
TimeSinceStart : 1215.2844927310944
Training Loss : -0.02546219527721405
Baseline Loss : 0.9824398756027222
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 20 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -93.68294525146484
Eval_StdReturn : 15.872244834899902
Eval_MaxReturn : -71.96088409423828
Eval_MinReturn : -109.443603515625
Eval_AverageEpLen : 150.0
Train_AverageReturn : -96.83736419677734
Train_StdReturn : 29.027835845947266
Train_MaxReturn : -32.21320724487305
Train_MinReturn : -182.67510986328125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 630000
TimeSinceStart : 1275.5166554450989
Training Loss : -0.011929642409086227
Baseline Loss : 0.9946661591529846
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 21 ************
Eval_AverageEpLen : 150.0
Train_AverageReturn : -53.1367301940918
Train_StdReturn : 26.10165786743164
Train_MaxReturn : 6.061668395996094
Train_MinReturn : -126.7098388671875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 330000
TimeSinceStart : 660.2267909049988
Training Loss : -0.05889366939663887
Baseline Loss : 0.9375211000442505
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -34.161407470703125
Eval_StdReturn : 13.09717082977295
Eval_MaxReturn : -24.144763946533203
Eval_MinReturn : -52.66246795654297
Eval_AverageEpLen : 150.0
Train_AverageReturn : -48.79610824584961
Train_StdReturn : 30.321012496948242
Train_MaxReturn : 22.850662231445312
Train_MinReturn : -130.83102416992188
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 360000
TimeSinceStart : 724.4280142784119
Training Loss : -0.0678333044052124
Baseline Loss : 0.9392316341400146
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 12 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -32.245296478271484
Eval_StdReturn : 27.154226303100586
Eval_MaxReturn : -11.990318298339844
Eval_MinReturn : -70.62751770019531
Eval_AverageEpLen : 150.0
Train_AverageReturn : -43.871482849121094
Train_StdReturn : 28.687936782836914
Train_MaxReturn : 30.21268653869629
Train_MinReturn : -144.17269897460938
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 390000
TimeSinceStart : 786.3033919334412
Training Loss : -0.051444459706544876
Baseline Loss : 0.9119782447814941
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 13 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -23.483154296875
Eval_StdReturn : 9.188849449157715
Eval_MaxReturn : -15.925699234008789
Eval_MinReturn : -36.416996002197266
Eval_AverageEpLen : 150.0
Train_AverageReturn : -34.0761833190918
Train_StdReturn : 26.528411865234375
Train_MaxReturn : 25.097076416015625
Train_MinReturn : -115.32765197753906
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 420000
TimeSinceStart : 846.8087091445923
Training Loss : -0.0729648619890213
Baseline Loss : 0.8940317630767822
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 14 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -46.53336715698242
Eval_StdReturn : 34.727088928222656
Eval_MaxReturn : -11.96922492980957
Eval_MinReturn : -94.03044128417969
Eval_AverageEpLen : 150.0
Train_AverageReturn : -28.513906478881836
Train_StdReturn : 27.585195541381836
Train_MaxReturn : 51.9217529296875
Train_MinReturn : -140.95436096191406
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 450000
TimeSinceStart : 907.888947725296
Training Loss : -0.053966742008924484
Baseline Loss : 0.8953592777252197
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 15 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -5.758206844329834
Eval_StdReturn : 19.644155502319336
Eval_MaxReturn : 17.551010131835938
Eval_MinReturn : -30.50286865234375
Eval_AverageEpLen : 150.0
Train_AverageReturn : -26.941490173339844
Train_StdReturn : 32.42171859741211
Train_MaxReturn : 43.564979553222656
Train_MinReturn : -124.78850555419922
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 480000
TimeSinceStart : 968.7291209697723
Training Loss : -0.028330057859420776
Baseline Loss : 0.8858203887939453
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 16 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -45.207584381103516
Eval_StdReturn : 13.510923385620117
Eval_MaxReturn : -35.187076568603516
Eval_MinReturn : -64.30718231201172
Eval_AverageEpLen : 150.0
Train_AverageReturn : -19.375057220458984
Train_StdReturn : 29.4939022064209
Train_MaxReturn : 40.51994323730469
Train_MinReturn : -105.93097686767578
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 510000
TimeSinceStart : 1029.372502565384
Training Loss : -0.032152581959962845
Baseline Loss : 0.8686238527297974
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 17 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 21.639822006225586
Eval_StdReturn : 22.653881072998047
Eval_MaxReturn : 52.40553665161133
Eval_MinReturn : -1.4825763702392578
Eval_AverageEpLen : 150.0
Train_AverageReturn : -19.985849380493164
Train_StdReturn : 32.36604309082031
Train_MaxReturn : 71.14916229248047
Train_MinReturn : -129.10372924804688
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 540000
TimeSinceStart : 1089.8724203109741
Training Loss : -0.06049736216664314
Baseline Loss : 0.8509402275085449
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 18 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -16.772905349731445
Eval_StdReturn : 11.621232986450195
Eval_MaxReturn : -2.479267120361328
Eval_MinReturn : -30.9445743560791
Eval_AverageEpLen : 150.0
Train_AverageReturn : -18.594968795776367
Train_StdReturn : 29.879098892211914
Train_MaxReturn : 41.11589050292969
Train_MinReturn : -140.37779235839844
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 570000
TimeSinceStart : 1151.7179508209229
Training Loss : -0.06751357764005661
Baseline Loss : 0.8591763377189636
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 19 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -17.251544952392578
Eval_StdReturn : 8.906465530395508
Eval_MaxReturn : -4.775168418884277
Eval_MinReturn : -24.987300872802734
Eval_AverageEpLen : 150.0
Train_AverageReturn : -13.688743591308594
Train_StdReturn : 28.419788360595703
Train_MaxReturn : 53.08000946044922
Train_MinReturn : -113.833251953125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 600000
TimeSinceStart : 1211.7739524841309
Training Loss : -0.050497643649578094
Baseline Loss : 0.8287897706031799
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 20 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 11.16150188446045
Eval_StdReturn : 8.85145378112793
Eval_MaxReturn : 23.352685928344727
Eval_MinReturn : 2.6054978370666504
Eval_AverageEpLen : 150.0
Train_AverageReturn : -2.987708330154419
Train_StdReturn : 27.965471267700195
Train_MaxReturn : 96.32614135742188
Train_MinReturn : -94.50426483154297
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 630000
TimeSinceStart : 1271.797512292862
Training Loss : -0.05896790325641632
Baseline Loss : 0.8106352090835571
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 21 ************

Collecting data to be used for training...
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -117.31427001953125
Eval_StdReturn : 16.509809494018555
Eval_MaxReturn : -95.12754821777344
Eval_MinReturn : -134.70626831054688
Eval_AverageEpLen : 150.0
Train_AverageReturn : -107.03428649902344
Train_StdReturn : 34.270328521728516
Train_MaxReturn : -22.205707550048828
Train_MinReturn : -226.94642639160156
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 360000
TimeSinceStart : 724.1284673213959
Training Loss : -0.01643192209303379
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 12 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -97.64785766601562
Eval_StdReturn : 28.387237548828125
Eval_MaxReturn : -71.70905303955078
Eval_MinReturn : -137.15283203125
Eval_AverageEpLen : 150.0
Train_AverageReturn : -115.47058868408203
Train_StdReturn : 38.74845504760742
Train_MaxReturn : 7.4043402671813965
Train_MinReturn : -276.2711181640625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 390000
TimeSinceStart : 786.0329418182373
Training Loss : -0.012409239076077938
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 13 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -112.0194091796875
Eval_StdReturn : 18.57855224609375
Eval_MaxReturn : -97.1889877319336
Eval_MinReturn : -138.21726989746094
Eval_AverageEpLen : 150.0
Train_AverageReturn : -108.5888900756836
Train_StdReturn : 41.16651153564453
Train_MaxReturn : 29.435441970825195
Train_MinReturn : -235.01089477539062
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 420000
TimeSinceStart : 846.5958409309387
Training Loss : -0.02336871437728405
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 14 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -77.50778198242188
Eval_StdReturn : 53.38507843017578
Eval_MaxReturn : -31.337242126464844
Eval_MinReturn : -152.32467651367188
Eval_AverageEpLen : 150.0
Train_AverageReturn : -105.48150634765625
Train_StdReturn : 36.288002014160156
Train_MaxReturn : 10.420415878295898
Train_MinReturn : -201.82388305664062
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 450000
TimeSinceStart : 907.6434707641602
Training Loss : -0.005809820722788572
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 15 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -93.27716827392578
Eval_StdReturn : 31.001737594604492
Eval_MaxReturn : -63.3177490234375
Eval_MinReturn : -135.9784698486328
Eval_AverageEpLen : 150.0
Train_AverageReturn : -102.28113555908203
Train_StdReturn : 35.85085678100586
Train_MaxReturn : -20.950210571289062
Train_MinReturn : -207.2020263671875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 480000
TimeSinceStart : 968.4666430950165
Training Loss : -0.026857154443860054
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 16 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -89.1868896484375
Eval_StdReturn : 25.79352569580078
Eval_MaxReturn : -52.76891326904297
Eval_MinReturn : -109.20062255859375
Eval_AverageEpLen : 150.0
Train_AverageReturn : -100.18816375732422
Train_StdReturn : 33.61130142211914
Train_MaxReturn : 4.766012191772461
Train_MinReturn : -202.7435760498047
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 510000
TimeSinceStart : 1029.3310797214508
Training Loss : -0.029956301674246788
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 17 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -85.41632080078125
Eval_StdReturn : 7.796358108520508
Eval_MaxReturn : -77.73002624511719
Eval_MinReturn : -96.10530853271484
Eval_AverageEpLen : 150.0
Train_AverageReturn : -94.33513641357422
Train_StdReturn : 34.20915222167969
Train_MaxReturn : 16.72541046142578
Train_MinReturn : -205.75425720214844
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 540000
TimeSinceStart : 1089.9020011425018
Training Loss : -0.02906198799610138
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 18 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -99.3674087524414
Eval_StdReturn : 36.56246566772461
Eval_MaxReturn : -53.64356994628906
Eval_MinReturn : -143.13909912109375
Eval_AverageEpLen : 150.0
Train_AverageReturn : -93.64175415039062
Train_StdReturn : 32.185359954833984
Train_MaxReturn : -5.573173522949219
Train_MinReturn : -188.4639434814453
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 570000
TimeSinceStart : 1151.9312376976013
Training Loss : -0.0012611816637217999
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 19 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -66.53131866455078
Eval_StdReturn : 18.769203186035156
Eval_MaxReturn : -44.523494720458984
Eval_MinReturn : -90.38693237304688
Eval_AverageEpLen : 150.0
Train_AverageReturn : -96.09423065185547
Train_StdReturn : 35.00886154174805
Train_MaxReturn : 1.563943862915039
Train_MinReturn : -181.63394165039062
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 600000
TimeSinceStart : 1212.0558667182922
Training Loss : -0.021596236154437065
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 20 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -90.39718627929688
Eval_StdReturn : 21.428340911865234
Eval_MaxReturn : -63.75724792480469
Eval_MinReturn : -116.22698974609375
Eval_AverageEpLen : 150.0
Train_AverageReturn : -90.6107406616211
Train_StdReturn : 35.901851654052734
Train_MaxReturn : 62.965328216552734
Train_MinReturn : -192.58154296875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 630000
TimeSinceStart : 1272.0484235286713
Training Loss : -0.027908284217119217
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 21 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -107.429443359375
Eval_StdReturn : 16.203731536865234
Eval_MaxReturn : -92.09111022949219
Eval_MinReturn : -129.84286499023438
Eval_AverageEpLen : 150.0
Train_AverageReturn : -91.03504180908203
Train_StdReturn : 34.54164505004883
Train_MaxReturn : 10.289628028869629
Train_MinReturn : -202.24154663085938
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 660000
TimeSinceStart : 1331.2788789272308
Training Loss : -0.018598204478621483
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 22 ************
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -38.24265670776367
Eval_StdReturn : 13.151459693908691
Eval_MaxReturn : -22.035858154296875
Eval_MinReturn : -54.24834060668945
Eval_AverageEpLen : 150.0
Train_AverageReturn : -44.45713806152344
Train_StdReturn : 33.241249084472656
Train_MaxReturn : 38.55644989013672
Train_MinReturn : -188.53305053710938
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 360000
TimeSinceStart : 725.4956367015839
Training Loss : -0.05594893917441368
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 12 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -13.157366752624512
Eval_StdReturn : 39.42850875854492
Eval_MaxReturn : 41.7308349609375
Eval_MinReturn : -49.10881805419922
Eval_AverageEpLen : 150.0
Train_AverageReturn : -41.649192810058594
Train_StdReturn : 31.5927677154541
Train_MaxReturn : 39.641353607177734
Train_MinReturn : -144.61012268066406
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 390000
TimeSinceStart : 787.4152677059174
Training Loss : -0.0531691238284111
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 13 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -31.208688735961914
Eval_StdReturn : 20.894311904907227
Eval_MaxReturn : -1.7082500457763672
Eval_MinReturn : -47.42570877075195
Eval_AverageEpLen : 150.0
Train_AverageReturn : -38.54069519042969
Train_StdReturn : 30.48256492614746
Train_MaxReturn : 21.565998077392578
Train_MinReturn : -155.64892578125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 420000
TimeSinceStart : 848.0434362888336
Training Loss : -0.06341415643692017
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 14 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -37.56906509399414
Eval_StdReturn : 15.444337844848633
Eval_MaxReturn : -22.25281524658203
Eval_MinReturn : -58.71239471435547
Eval_AverageEpLen : 150.0
Train_AverageReturn : -33.69664001464844
Train_StdReturn : 29.060285568237305
Train_MaxReturn : 52.908023834228516
Train_MinReturn : -112.02592468261719
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 450000
TimeSinceStart : 909.2080838680267
Training Loss : -0.055311255156993866
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 15 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -19.730466842651367
Eval_StdReturn : 13.178041458129883
Eval_MaxReturn : -1.1064863204956055
Eval_MinReturn : -29.635478973388672
Eval_AverageEpLen : 150.0
Train_AverageReturn : -27.771434783935547
Train_StdReturn : 30.08501625061035
Train_MaxReturn : 38.379066467285156
Train_MinReturn : -122.78227233886719
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 480000
TimeSinceStart : 970.2148170471191
Training Loss : -0.06660128384828568
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 16 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 18.9525203704834
Eval_StdReturn : 11.816923141479492
Eval_MaxReturn : 33.4814338684082
Eval_MinReturn : 4.536664009094238
Eval_AverageEpLen : 150.0
Train_AverageReturn : -28.080188751220703
Train_StdReturn : 25.24353790283203
Train_MaxReturn : 46.22229766845703
Train_MinReturn : -100.59382629394531
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 510000
TimeSinceStart : 1031.5716006755829
Training Loss : -0.06072001904249191
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 17 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -21.184988021850586
Eval_StdReturn : 18.591873168945312
Eval_MaxReturn : -4.059006690979004
Eval_MinReturn : -47.025482177734375
Eval_AverageEpLen : 150.0
Train_AverageReturn : -24.451642990112305
Train_StdReturn : 25.529800415039062
Train_MaxReturn : 38.16695022583008
Train_MinReturn : -105.81953430175781
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 540000
TimeSinceStart : 1092.3532917499542
Training Loss : -0.06981413811445236
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 18 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -7.952951908111572
Eval_StdReturn : 20.240938186645508
Eval_MaxReturn : 18.117496490478516
Eval_MinReturn : -31.224977493286133
Eval_AverageEpLen : 150.0
Train_AverageReturn : -17.945110321044922
Train_StdReturn : 26.27519989013672
Train_MaxReturn : 53.914127349853516
Train_MinReturn : -100.8868637084961
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 570000
TimeSinceStart : 1154.4897396564484
Training Loss : -0.06609023362398148
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 19 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -11.459200859069824
Eval_StdReturn : 20.65446662902832
Eval_MaxReturn : 16.27223777770996
Eval_MinReturn : -33.27073669433594
Eval_AverageEpLen : 150.0
Train_AverageReturn : -11.803110122680664
Train_StdReturn : 28.708724975585938
Train_MaxReturn : 77.33122253417969
Train_MinReturn : -101.11590576171875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 600000
TimeSinceStart : 1214.7643251419067
Training Loss : -0.08008014410734177
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 20 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -32.955074310302734
Eval_StdReturn : 35.361289978027344
Eval_MaxReturn : 17.053314208984375
Eval_MinReturn : -58.003665924072266
Eval_AverageEpLen : 150.0
Train_AverageReturn : -18.260583877563477
Train_StdReturn : 30.65513038635254
Train_MaxReturn : 51.19724655151367
Train_MinReturn : -83.85799407958984
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 630000
TimeSinceStart : 1274.8412337303162
Training Loss : -0.03989700600504875
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 21 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -26.66326332092285
Eval_StdReturn : 30.414020538330078
Eval_MaxReturn : 14.546088218688965
Eval_MinReturn : -57.93851089477539
Eval_AverageEpLen : 150.0
Train_AverageReturn : -14.295676231384277
Train_StdReturn : 34.60040283203125
Train_MaxReturn : 71.24729919433594
Train_MinReturn : -111.34614562988281
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 660000
TimeSinceStart : 1334.4024257659912
Training Loss : -0.055536042898893356
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 22 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 3.4908363819122314
Eval_StdReturn : 13.859132766723633
Eval_MaxReturn : 23.047752380371094
Eval_MinReturn : -7.409520626068115
Eval_AverageEpLen : 150.0
Train_AverageReturn : -2.6804566383361816
Train_StdReturn : 27.211946487426758
Train_MaxReturn : 81.17919921875
Train_MinReturn : -100.07238006591797
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 660000
TimeSinceStart : 1330.9830462932587
Training Loss : -0.0738663598895073
Baseline Loss : 0.8014541864395142
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 22 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 6.507981777191162
Eval_StdReturn : 15.674882888793945
Eval_MaxReturn : 28.45285987854004
Eval_MinReturn : -7.179176330566406
Eval_AverageEpLen : 150.0
Train_AverageReturn : -2.1141388416290283
Train_StdReturn : 27.172544479370117
Train_MaxReturn : 58.66725158691406
Train_MinReturn : -125.39408874511719
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 690000
TimeSinceStart : 1390.4348711967468
Training Loss : -0.04696505144238472
Baseline Loss : 0.7427203059196472
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 23 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 25.037397384643555
Eval_StdReturn : 15.417245864868164
Eval_MaxReturn : 46.18538284301758
Eval_MinReturn : 9.868921279907227
Eval_AverageEpLen : 150.0
Train_AverageReturn : -3.4976086616516113
Train_StdReturn : 28.703514099121094
Train_MaxReturn : 56.90021514892578
Train_MinReturn : -78.75106811523438
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 720000
TimeSinceStart : 1448.986961364746
Training Loss : -0.06823912262916565
Baseline Loss : 0.7007617950439453
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 24 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 7.617824554443359
Eval_StdReturn : 7.421343803405762
Eval_MaxReturn : 18.112903594970703
Eval_MinReturn : 2.3031210899353027
Eval_AverageEpLen : 150.0
Train_AverageReturn : 2.3750717639923096
Train_StdReturn : 33.230133056640625
Train_MaxReturn : 73.9035873413086
Train_MinReturn : -123.80136108398438
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 750000
TimeSinceStart : 1508.7592704296112
Training Loss : -0.05303047224879265
Baseline Loss : 0.7042903900146484
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 25 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 1.0801048278808594
Eval_StdReturn : 26.68259048461914
Eval_MaxReturn : 32.60847473144531
Eval_MinReturn : -32.63992691040039
Eval_AverageEpLen : 150.0
Train_AverageReturn : 1.7412909269332886
Train_StdReturn : 33.34792709350586
Train_MaxReturn : 67.13819122314453
Train_MinReturn : -117.20187377929688
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 780000
TimeSinceStart : 1568.2451436519623
Training Loss : -0.05909847468137741
Baseline Loss : 0.6823407411575317
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 26 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -0.4549064636230469
Eval_StdReturn : 21.077632904052734
Eval_MaxReturn : 23.019004821777344
Eval_MinReturn : -28.101970672607422
Eval_AverageEpLen : 150.0
Train_AverageReturn : -1.969675898551941
Train_StdReturn : 33.17125701904297
Train_MaxReturn : 83.13532257080078
Train_MinReturn : -96.67220306396484
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 810000
TimeSinceStart : 1626.706627368927
Training Loss : -0.040679458528757095
Baseline Loss : 0.6699506640434265
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 27 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 25.63702392578125
Eval_StdReturn : 31.997943878173828
Eval_MaxReturn : 69.23907470703125
Eval_MinReturn : -6.649641036987305
Eval_AverageEpLen : 150.0
Train_AverageReturn : 3.1582765579223633
Train_StdReturn : 35.732086181640625
Train_MaxReturn : 93.54437255859375
Train_MinReturn : -133.3599395751953
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 840000
TimeSinceStart : 1684.9189956188202
Training Loss : -0.03873664513230324
Baseline Loss : 0.7345094680786133
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 28 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -17.844186782836914
Eval_StdReturn : 15.800187110900879
Eval_MaxReturn : 3.5195789337158203
Eval_MinReturn : -34.19713592529297
Eval_AverageEpLen : 150.0
Train_AverageReturn : 5.378828048706055
Train_StdReturn : 31.105445861816406
Train_MaxReturn : 86.78115844726562
Train_MinReturn : -108.42840576171875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 870000
TimeSinceStart : 1743.0790240764618
Training Loss : -0.050694260746240616
Baseline Loss : 0.6924606561660767
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 29 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 26.871856689453125
Eval_StdReturn : 4.0694475173950195
Eval_MaxReturn : 31.661958694458008
Eval_MinReturn : 21.714235305786133
Eval_AverageEpLen : 150.0
Train_AverageReturn : 9.330765724182129
Train_StdReturn : 34.87555694580078
Train_MaxReturn : 72.83024597167969
Train_MinReturn : -133.3902130126953
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 900000
TimeSinceStart : 1801.2878952026367
Training Loss : -0.03449995815753937
Baseline Loss : 0.6679256558418274
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 30 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 44.60919189453125
Eval_StdReturn : 26.593080520629883
Eval_MaxReturn : 79.71485900878906
Eval_MinReturn : 15.373810768127441
Eval_AverageEpLen : 150.0
Train_AverageReturn : 15.991267204284668
Train_StdReturn : 28.02293586730957
Train_MaxReturn : 78.86308288574219
Train_MinReturn : -54.78546142578125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 930000
TimeSinceStart : 1860.2245817184448
Training Loss : -0.04268791526556015
Baseline Loss : 0.6501367092132568
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 31 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 74.1701431274414
Eval_StdReturn : 13.67257308959961
Eval_MaxReturn : 84.64164733886719
Eval_MinReturn : 54.85711669921875
Eval_AverageEpLen : 150.0
Train_AverageReturn : 29.227710723876953
Train_StdReturn : 38.067481994628906
Train_MaxReturn : 128.3752899169922
Train_MinReturn : -80.95654296875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 960000
TimeSinceStart : 1919.8709077835083

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -107.973388671875
Eval_StdReturn : 21.691667556762695
Eval_MaxReturn : -82.6244125366211
Eval_MinReturn : -135.6099853515625
Eval_AverageEpLen : 150.0
Train_AverageReturn : -97.0234146118164
Train_StdReturn : 28.87425994873047
Train_MaxReturn : -28.50604248046875
Train_MinReturn : -196.14736938476562
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 660000
TimeSinceStart : 1335.3977692127228
Training Loss : 0.0013829183299094439
Baseline Loss : 0.9952295422554016
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 22 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -88.37264251708984
Eval_StdReturn : 8.479131698608398
Eval_MaxReturn : -77.28765106201172
Eval_MinReturn : -97.87565612792969
Eval_AverageEpLen : 150.0
Train_AverageReturn : -93.52993774414062
Train_StdReturn : 34.78935623168945
Train_MaxReturn : -13.960113525390625
Train_MinReturn : -197.3816375732422
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 690000
TimeSinceStart : 1394.5814776420593
Training Loss : -0.01625720225274563
Baseline Loss : 0.9819397330284119
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 23 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -93.68938446044922
Eval_StdReturn : 22.107812881469727
Eval_MaxReturn : -62.95030212402344
Eval_MinReturn : -114.00511169433594
Eval_AverageEpLen : 150.0
Train_AverageReturn : -97.87530517578125
Train_StdReturn : 38.642417907714844
Train_MaxReturn : -16.385169982910156
Train_MinReturn : -226.35711669921875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 720000
TimeSinceStart : 1453.2071278095245
Training Loss : 0.008533235639333725
Baseline Loss : 0.962946891784668
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 24 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -115.8545913696289
Eval_StdReturn : 35.88182830810547
Eval_MaxReturn : -65.11013793945312
Eval_MinReturn : -141.3192138671875
Eval_AverageEpLen : 150.0
Train_AverageReturn : -92.29533386230469
Train_StdReturn : 36.032535552978516
Train_MaxReturn : -5.059605121612549
Train_MinReturn : -224.60989379882812
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 750000
TimeSinceStart : 1513.15957736969
Training Loss : 0.0026674235705286264
Baseline Loss : 0.9614389538764954
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 25 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -151.29945373535156
Eval_StdReturn : 13.78451156616211
Eval_MaxReturn : -140.88302612304688
Eval_MinReturn : -170.77801513671875
Eval_AverageEpLen : 150.0
Train_AverageReturn : -99.29920196533203
Train_StdReturn : 36.84504699707031
Train_MaxReturn : -16.001441955566406
Train_MinReturn : -205.15179443359375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 780000
TimeSinceStart : 1572.824854850769
Training Loss : 0.007845243439078331
Baseline Loss : 0.9516003727912903
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 26 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -78.23299407958984
Eval_StdReturn : 18.3603572845459
Eval_MaxReturn : -61.138267517089844
Eval_MinReturn : -103.70613098144531
Eval_AverageEpLen : 150.0
Train_AverageReturn : -98.27153015136719
Train_StdReturn : 38.19282531738281
Train_MaxReturn : 0.270233154296875
Train_MinReturn : -207.19369506835938
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 810000
TimeSinceStart : 1631.2235343456268
Training Loss : -6.184895755723119e-05
Baseline Loss : 0.9602593779563904
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 27 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -74.79544830322266
Eval_StdReturn : 29.65256690979004
Eval_MaxReturn : -52.488887786865234
Eval_MinReturn : -116.70137786865234
Eval_AverageEpLen : 150.0
Train_AverageReturn : -93.65107727050781
Train_StdReturn : 35.14373779296875
Train_MaxReturn : 9.60551643371582
Train_MinReturn : -196.2064208984375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 840000
TimeSinceStart : 1689.3220975399017
Training Loss : -0.0005838704528287053
Baseline Loss : 0.9439025521278381
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 28 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -78.0400390625
Eval_StdReturn : 15.051132202148438
Eval_MaxReturn : -56.84157943725586
Eval_MinReturn : -90.30474090576172
Eval_AverageEpLen : 150.0
Train_AverageReturn : -92.17208862304688
Train_StdReturn : 37.644432067871094
Train_MaxReturn : 0.27753353118896484
Train_MinReturn : -210.1063232421875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 870000
TimeSinceStart : 1747.4867877960205
Training Loss : -0.0026165975723415613
Baseline Loss : 0.922829806804657
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 29 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -83.79025268554688
Eval_StdReturn : 17.608659744262695
Eval_MaxReturn : -69.29454803466797
Eval_MinReturn : -108.5738754272461
Eval_AverageEpLen : 150.0
Train_AverageReturn : -92.49759674072266
Train_StdReturn : 33.649166107177734
Train_MaxReturn : 6.936974048614502
Train_MinReturn : -165.96597290039062
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 900000
TimeSinceStart : 1805.6224074363708
Training Loss : -0.011328035965561867
Baseline Loss : 0.9618542194366455
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 30 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -98.8599624633789
Eval_StdReturn : 40.16267013549805
Eval_MaxReturn : -42.97227478027344
Eval_MinReturn : -135.5779266357422
Eval_AverageEpLen : 150.0
Train_AverageReturn : -96.33428955078125
Train_StdReturn : 35.46469497680664
Train_MaxReturn : -0.48839378356933594
Train_MinReturn : -201.76473999023438
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 930000
TimeSinceStart : 1864.5466129779816
Training Loss : -0.01769098825752735
Baseline Loss : 0.9382875561714172
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 31 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -90.94790649414062
Eval_StdReturn : 34.883209228515625
Eval_MaxReturn : -51.098243713378906
Eval_MinReturn : -136.05726623535156
Eval_AverageEpLen : 150.0
Train_AverageReturn : -97.0838851928711
Train_StdReturn : 31.40145492553711
Train_MaxReturn : -18.080833435058594
Train_MinReturn : -166.75741577148438
Train_AverageEpLen : 150.0

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -86.52621459960938
Eval_StdReturn : 43.586082458496094
Eval_MaxReturn : -44.69758987426758
Eval_MinReturn : -146.650146484375
Eval_AverageEpLen : 150.0
Train_AverageReturn : -85.80581665039062
Train_StdReturn : 33.43853759765625
Train_MaxReturn : -1.357339859008789
Train_MinReturn : -166.4581298828125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 690000
TimeSinceStart : 1390.6379418373108
Training Loss : -0.010819671675562859
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 23 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -68.58942413330078
Eval_StdReturn : 17.843765258789062
Eval_MaxReturn : -43.538330078125
Eval_MinReturn : -83.74783325195312
Eval_AverageEpLen : 150.0
Train_AverageReturn : -87.30280303955078
Train_StdReturn : 32.95792007446289
Train_MaxReturn : 18.241233825683594
Train_MinReturn : -196.57325744628906
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 720000
TimeSinceStart : 1449.0693316459656
Training Loss : -0.0030509948264807463
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 24 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -89.96685791015625
Eval_StdReturn : 43.33902359008789
Eval_MaxReturn : -29.97707176208496
Eval_MinReturn : -130.83950805664062
Eval_AverageEpLen : 150.0
Train_AverageReturn : -82.87527465820312
Train_StdReturn : 33.606475830078125
Train_MaxReturn : 12.309659004211426
Train_MinReturn : -175.4718475341797
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 750000
TimeSinceStart : 1508.6929869651794
Training Loss : 0.004316219128668308
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 25 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -88.17668914794922
Eval_StdReturn : 3.4437990188598633
Eval_MaxReturn : -84.33316802978516
Eval_MinReturn : -92.6888427734375
Eval_AverageEpLen : 150.0
Train_AverageReturn : -80.79457092285156
Train_StdReturn : 33.501224517822266
Train_MaxReturn : 24.89360809326172
Train_MinReturn : -182.91195678710938
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 780000
TimeSinceStart : 1568.0959157943726
Training Loss : -0.012569978833198547
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 26 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -75.15625762939453
Eval_StdReturn : 35.64746856689453
Eval_MaxReturn : -32.44594955444336
Eval_MinReturn : -119.70591735839844
Eval_AverageEpLen : 150.0
Train_AverageReturn : -83.94039154052734
Train_StdReturn : 34.335243225097656
Train_MaxReturn : 66.92059326171875
Train_MinReturn : -156.5756072998047
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 810000
TimeSinceStart : 1626.4875378608704
Training Loss : -0.015065116807818413
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 27 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -87.31671142578125
Eval_StdReturn : 15.887628555297852
Eval_MaxReturn : -65.44615173339844
Eval_MinReturn : -102.71115112304688
Eval_AverageEpLen : 150.0
Train_AverageReturn : -81.83303833007812
Train_StdReturn : 33.1116828918457
Train_MaxReturn : -6.162694931030273
Train_MinReturn : -172.9552001953125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 840000
TimeSinceStart : 1684.7301778793335
Training Loss : -0.006580883637070656
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 28 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -105.95072174072266
Eval_StdReturn : 31.411205291748047
Eval_MaxReturn : -62.31529998779297
Eval_MinReturn : -134.97662353515625
Eval_AverageEpLen : 150.0
Train_AverageReturn : -80.56427001953125
Train_StdReturn : 33.7974967956543
Train_MaxReturn : 6.931002140045166
Train_MinReturn : -183.83035278320312
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 870000
TimeSinceStart : 1742.8994841575623
Training Loss : -0.017319360747933388
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 29 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -69.25312042236328
Eval_StdReturn : 26.446352005004883
Eval_MaxReturn : -40.94076919555664
Eval_MinReturn : -104.57347106933594
Eval_AverageEpLen : 150.0
Train_AverageReturn : -82.92908477783203
Train_StdReturn : 34.108543395996094
Train_MaxReturn : 46.18997573852539
Train_MinReturn : -191.02481079101562
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 900000
TimeSinceStart : 1801.0248174667358
Training Loss : -0.012864632532000542
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 30 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -80.88599395751953
Eval_StdReturn : 12.614602088928223
Eval_MaxReturn : -68.30794525146484
Eval_MinReturn : -98.13114929199219
Eval_AverageEpLen : 150.0
Train_AverageReturn : -91.58104705810547
Train_StdReturn : 31.130958557128906
Train_MaxReturn : -4.583106994628906
Train_MinReturn : -180.8145751953125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 930000
TimeSinceStart : 1859.9454584121704
Training Loss : -0.0019902607891708612
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 31 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -74.94686889648438
Eval_StdReturn : 30.28746223449707
Eval_MaxReturn : -43.94832229614258
Eval_MinReturn : -116.04522705078125
Eval_AverageEpLen : 150.0
Train_AverageReturn : -95.26771545410156
Train_StdReturn : 29.067768096923828
Train_MaxReturn : -2.6990280151367188
Train_MinReturn : -165.12109375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 960000
TimeSinceStart : 1919.6569876670837
Training Loss : -0.00692105945199728
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 32 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -85.38898468017578
Eval_StdReturn : 19.881555557250977
Eval_MaxReturn : -66.42192840576172
Eval_MinReturn : -112.84756469726562
Eval_AverageEpLen : 150.0
Train_AverageReturn : -92.10681915283203
Train_StdReturn : 26.322980880737305
Train_MaxReturn : -13.066789627075195
Train_MinReturn : -169.5875244140625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 990000
TimeSinceStart : 1979.610288143158
Training Loss : 0.0025538860354572535
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 33 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -18.071815490722656
Eval_StdReturn : 30.825647354125977
Eval_MaxReturn : 25.4257869720459
Eval_MinReturn : -42.33049392700195
Eval_AverageEpLen : 150.0
Train_AverageReturn : -23.719823837280273
Train_StdReturn : 39.90573501586914
Train_MaxReturn : 78.80615997314453
Train_MinReturn : -153.703857421875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 690000
TimeSinceStart : 1393.397007226944
Training Loss : -0.024122273549437523
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 23 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -1.141724944114685
Eval_StdReturn : 29.244230270385742
Eval_MaxReturn : 21.036373138427734
Eval_MinReturn : -42.462154388427734
Eval_AverageEpLen : 150.0
Train_AverageReturn : -21.577899932861328
Train_StdReturn : 34.10362243652344
Train_MaxReturn : 73.348388671875
Train_MinReturn : -103.72657012939453
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 720000
TimeSinceStart : 1451.854748249054
Training Loss : -0.05548616498708725
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 24 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -36.493350982666016
Eval_StdReturn : 9.621240615844727
Eval_MaxReturn : -24.466176986694336
Eval_MinReturn : -48.01717758178711
Eval_AverageEpLen : 150.0
Train_AverageReturn : -23.752668380737305
Train_StdReturn : 37.271881103515625
Train_MaxReturn : 87.03968811035156
Train_MinReturn : -124.68750762939453
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 750000
TimeSinceStart : 1511.573679447174
Training Loss : -0.017648648470640182
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 25 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -18.712520599365234
Eval_StdReturn : 71.25180053710938
Eval_MaxReturn : 73.52886199951172
Eval_MinReturn : -99.95976257324219
Eval_AverageEpLen : 150.0
Train_AverageReturn : -17.494895935058594
Train_StdReturn : 34.90602493286133
Train_MaxReturn : 71.94317626953125
Train_MinReturn : -123.29670715332031
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 780000
TimeSinceStart : 1570.9405102729797
Training Loss : -0.041590575128793716
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 26 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -20.9766788482666
Eval_StdReturn : 34.202484130859375
Eval_MaxReturn : 10.914148330688477
Eval_MinReturn : -68.41726684570312
Eval_AverageEpLen : 150.0
Train_AverageReturn : -16.314050674438477
Train_StdReturn : 35.51496505737305
Train_MaxReturn : 68.17991638183594
Train_MinReturn : -168.92391967773438
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 810000
TimeSinceStart : 1629.3855345249176
Training Loss : -0.045244790613651276
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 27 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 12.690135955810547
Eval_StdReturn : 4.577095031738281
Eval_MaxReturn : 18.390361785888672
Eval_MinReturn : 7.183847904205322
Eval_AverageEpLen : 150.0
Train_AverageReturn : -11.269309997558594
Train_StdReturn : 24.7022705078125
Train_MaxReturn : 57.202850341796875
Train_MinReturn : -121.68286895751953
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 840000
TimeSinceStart : 1687.6181318759918
Training Loss : -0.045389991253614426
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 28 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 18.854782104492188
Eval_StdReturn : 18.744585037231445
Eval_MaxReturn : 41.896751403808594
Eval_MinReturn : -4.016967296600342
Eval_AverageEpLen : 150.0
Train_AverageReturn : -8.981122970581055
Train_StdReturn : 21.860246658325195
Train_MaxReturn : 65.34880828857422
Train_MinReturn : -67.27748107910156
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 870000
TimeSinceStart : 1745.9228036403656
Training Loss : -0.052305664867162704
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 29 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 2.0828258991241455
Eval_StdReturn : 11.147126197814941
Eval_MaxReturn : 17.833234786987305
Eval_MinReturn : -6.367804050445557
Eval_AverageEpLen : 150.0
Train_AverageReturn : -3.8711700439453125
Train_StdReturn : 17.971464157104492
Train_MaxReturn : 48.63384246826172
Train_MinReturn : -50.562252044677734
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 900000
TimeSinceStart : 1804.2260065078735
Training Loss : -0.04153789207339287
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 30 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -14.173431396484375
Eval_StdReturn : 12.222769737243652
Eval_MaxReturn : 0.40958505868911743
Eval_MinReturn : -29.50209617614746
Eval_AverageEpLen : 150.0
Train_AverageReturn : -4.737378120422363
Train_StdReturn : 17.762727737426758
Train_MaxReturn : 57.81907653808594
Train_MinReturn : -68.78129577636719
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 930000
TimeSinceStart : 1863.208894252777
Training Loss : -0.05037255957722664
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 31 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -19.6717472076416
Eval_StdReturn : 11.97569465637207
Eval_MaxReturn : -8.80982780456543
Eval_MinReturn : -36.35614776611328
Eval_AverageEpLen : 150.0
Train_AverageReturn : -9.680976867675781
Train_StdReturn : 14.994608879089355
Train_MaxReturn : 36.253395080566406
Train_MinReturn : -46.950477600097656
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 960000
TimeSinceStart : 1922.9365787506104
Training Loss : -0.03294900059700012
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 32 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -30.941064834594727
Eval_StdReturn : 16.08127784729004
Eval_MaxReturn : -11.32019329071045
Eval_MinReturn : -50.71028137207031
Eval_AverageEpLen : 150.0
Train_AverageReturn : -14.78366470336914
Train_StdReturn : 14.017827033996582
Train_MaxReturn : 55.42750549316406
Train_MinReturn : -47.79160690307617
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 990000
TimeSinceStart : 1982.7171297073364
Training Loss : -0.041169483214616776
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 33 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Training Loss : -0.05196138471364975
Baseline Loss : 0.6374084949493408
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 32 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 3.4658432006835938
Eval_StdReturn : 29.999834060668945
Eval_MaxReturn : 44.057655334472656
Eval_MinReturn : -27.51714324951172
Eval_AverageEpLen : 150.0
Train_AverageReturn : 42.52724075317383
Train_StdReturn : 33.16754150390625
Train_MaxReturn : 131.5549774169922
Train_MinReturn : -58.506500244140625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 990000
TimeSinceStart : 1979.651783466339
Training Loss : -0.03902231901884079
Baseline Loss : 0.6325666904449463
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 33 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 31.748498916625977
Eval_StdReturn : 33.138545989990234
Eval_MaxReturn : 77.70143127441406
Eval_MinReturn : 0.803924560546875
Eval_AverageEpLen : 150.0
Train_AverageReturn : 33.65341567993164
Train_StdReturn : 44.483638763427734
Train_MaxReturn : 141.986328125
Train_MinReturn : -88.00360870361328
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1020000
TimeSinceStart : 2037.8480677604675
Training Loss : -0.04471058025956154
Baseline Loss : 0.5446707010269165
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 34 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 29.81861686706543
Eval_StdReturn : 14.543851852416992
Eval_MaxReturn : 50.38653564453125
Eval_MinReturn : 19.457462310791016
Eval_AverageEpLen : 150.0
Train_AverageReturn : 42.452606201171875
Train_StdReturn : 42.836605072021484
Train_MaxReturn : 153.55271911621094
Train_MinReturn : -80.15640258789062
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1050000
TimeSinceStart : 2096.708646297455
Training Loss : -0.043844375759363174
Baseline Loss : 0.549392819404602
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 35 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 50.58152770996094
Eval_StdReturn : 10.34634780883789
Eval_MaxReturn : 62.691810607910156
Eval_MinReturn : 37.414695739746094
Eval_AverageEpLen : 150.0
Train_AverageReturn : 54.52812957763672
Train_StdReturn : 38.955013275146484
Train_MaxReturn : 161.65878295898438
Train_MinReturn : -104.72172546386719
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1080000
TimeSinceStart : 2156.5488319396973
Training Loss : -0.0408913716673851
Baseline Loss : 0.6127217411994934
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 36 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 51.87408447265625
Eval_StdReturn : 80.60359191894531
Eval_MaxReturn : 143.19293212890625
Eval_MinReturn : -52.87053298950195
Eval_AverageEpLen : 150.0
Train_AverageReturn : 55.682621002197266
Train_StdReturn : 34.549217224121094
Train_MaxReturn : 155.45545959472656
Train_MinReturn : -27.85051918029785
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1110000
TimeSinceStart : 2216.489818572998
Training Loss : -0.044348593801259995
Baseline Loss : 0.6113249063491821
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 37 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 96.12090301513672
Eval_StdReturn : 36.52272415161133
Eval_MaxReturn : 143.53277587890625
Eval_MinReturn : 54.668148040771484
Eval_AverageEpLen : 150.0
Train_AverageReturn : 73.5478515625
Train_StdReturn : 33.861568450927734
Train_MaxReturn : 157.75164794921875
Train_MinReturn : -12.076220512390137
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1140000
TimeSinceStart : 2275.9419519901276
Training Loss : -0.06048562377691269
Baseline Loss : 0.6358745098114014
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 38 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 87.67057037353516
Eval_StdReturn : 15.763457298278809
Eval_MaxReturn : 104.81441497802734
Eval_MinReturn : 66.7578125
Eval_AverageEpLen : 150.0
Train_AverageReturn : 83.11412048339844
Train_StdReturn : 37.87881851196289
Train_MaxReturn : 188.33834838867188
Train_MinReturn : -36.94823455810547
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1170000
TimeSinceStart : 2334.2835211753845
Training Loss : -0.03890949487686157
Baseline Loss : 0.6351719498634338
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 39 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 116.56729125976562
Eval_StdReturn : 12.19777774810791
Eval_MaxReturn : 132.73828125
Eval_MinReturn : 103.28054809570312
Eval_AverageEpLen : 150.0
Train_AverageReturn : 87.8905258178711
Train_StdReturn : 34.04166030883789
Train_MaxReturn : 169.54544067382812
Train_MinReturn : -34.89270782470703
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1200000
TimeSinceStart : 2393.7629339694977
Training Loss : -0.042457856237888336
Baseline Loss : 0.6419941186904907
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 40 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 79.939453125
Eval_StdReturn : 24.666004180908203
Eval_MaxReturn : 100.79120635986328
Eval_MinReturn : 45.295387268066406
Eval_AverageEpLen : 150.0
Train_AverageReturn : 89.11017608642578
Train_StdReturn : 33.71718215942383
Train_MaxReturn : 164.0015869140625
Train_MinReturn : -39.70151138305664
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1230000
TimeSinceStart : 2452.146777868271
Training Loss : -0.045372746884822845
Baseline Loss : 0.6816582083702087
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 41 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 78.34442138671875
Eval_StdReturn : 14.51768970489502
Eval_MaxReturn : 93.01079559326172
Eval_MinReturn : 58.568641662597656
Eval_AverageEpLen : 150.0
Train_AverageReturn : 95.78357696533203
Train_StdReturn : 30.479475021362305
Train_MaxReturn : 197.61070251464844
Train_MinReturn : 29.201894760131836
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1260000
TimeSinceStart : 2510.5041675567627
Training Loss : -0.06298049539327621
Baseline Loss : 0.683735191822052
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 42 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 105.62542724609375
Eval_StdReturn : 6.659121990203857
Eval_MaxReturn : 115.02116394042969
Eval_MinReturn : 100.37437438964844
Eval_AverageEpLen : 150.0
Train_AverageReturn : 92.90106201171875
Train_EnvstepsSoFar : 960000
TimeSinceStart : 1924.230852842331
Training Loss : -0.006395979784429073
Baseline Loss : 0.9331018328666687
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 32 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -68.41343688964844
Eval_StdReturn : 27.034116744995117
Eval_MaxReturn : -40.414974212646484
Eval_MinReturn : -104.95883178710938
Eval_AverageEpLen : 150.0
Train_AverageReturn : -95.65544891357422
Train_StdReturn : 35.287086486816406
Train_MaxReturn : 14.647833824157715
Train_MinReturn : -221.57846069335938
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 990000
TimeSinceStart : 1983.9009773731232
Training Loss : -0.020091088488698006
Baseline Loss : 0.9491938948631287
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 33 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -61.88594436645508
Eval_StdReturn : 12.80563735961914
Eval_MaxReturn : -44.0108642578125
Eval_MinReturn : -73.34095764160156
Eval_AverageEpLen : 150.0
Train_AverageReturn : -94.62088012695312
Train_StdReturn : 33.856990814208984
Train_MaxReturn : -24.90167236328125
Train_MinReturn : -205.71914672851562
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1020000
TimeSinceStart : 2042.1346213817596
Training Loss : -0.00027081705047748983
Baseline Loss : 0.9311097860336304
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 34 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -92.65425872802734
Eval_StdReturn : 18.419775009155273
Eval_MaxReturn : -68.31881713867188
Eval_MinReturn : -112.87007141113281
Eval_AverageEpLen : 150.0
Train_AverageReturn : -96.20819091796875
Train_StdReturn : 35.079437255859375
Train_MaxReturn : -11.741724967956543
Train_MinReturn : -196.62612915039062
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1050000
TimeSinceStart : 2101.088979959488
Training Loss : -0.010592533275485039
Baseline Loss : 0.917447030544281
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 35 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -121.4803237915039
Eval_StdReturn : 19.83677864074707
Eval_MaxReturn : -105.79638671875
Eval_MinReturn : -149.46571350097656
Eval_AverageEpLen : 150.0
Train_AverageReturn : -96.46887969970703
Train_StdReturn : 31.430824279785156
Train_MaxReturn : 12.574504852294922
Train_MinReturn : -175.74331665039062
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1080000
TimeSinceStart : 2161.3109624385834
Training Loss : 0.006654040422290564
Baseline Loss : 0.9521626234054565
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 36 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -77.32207489013672
Eval_StdReturn : 24.5521297454834
Eval_MaxReturn : -54.60923767089844
Eval_MinReturn : -111.4228515625
Eval_AverageEpLen : 150.0
Train_AverageReturn : -97.06996154785156
Train_StdReturn : 31.97826385498047
Train_MaxReturn : -10.644170761108398
Train_MinReturn : -232.91592407226562
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1110000
TimeSinceStart : 2221.061938762665
Training Loss : -0.004576950334012508
Baseline Loss : 0.9227829575538635
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 37 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -113.1108627319336
Eval_StdReturn : 21.310266494750977
Eval_MaxReturn : -94.72994995117188
Eval_MinReturn : -142.98458862304688
Eval_AverageEpLen : 150.0
Train_AverageReturn : -93.38081359863281
Train_StdReturn : 32.85081100463867
Train_MaxReturn : -2.4347076416015625
Train_MinReturn : -218.33438110351562
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1140000
TimeSinceStart : 2280.5438203811646
Training Loss : -0.022243181243538857
Baseline Loss : 0.9486274123191833
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 38 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -76.010986328125
Eval_StdReturn : 17.754833221435547
Eval_MaxReturn : -51.893898010253906
Eval_MinReturn : -94.12144470214844
Eval_AverageEpLen : 150.0
Train_AverageReturn : -94.76692199707031
Train_StdReturn : 36.64677810668945
Train_MaxReturn : 7.666545867919922
Train_MinReturn : -248.2920684814453
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1170000
TimeSinceStart : 2339.121485710144
Training Loss : -0.03460586816072464
Baseline Loss : 0.9285119771957397
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 39 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -76.94414520263672
Eval_StdReturn : 7.262844085693359
Eval_MaxReturn : -68.48741912841797
Eval_MinReturn : -86.22089385986328
Eval_AverageEpLen : 150.0
Train_AverageReturn : -86.22154235839844
Train_StdReturn : 35.066165924072266
Train_MaxReturn : 16.072359085083008
Train_MinReturn : -184.18016052246094
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1200000
TimeSinceStart : 2398.503854036331
Training Loss : 0.0093346843495965
Baseline Loss : 0.923661470413208
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 40 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -62.64767074584961
Eval_StdReturn : 17.81026268005371
Eval_MaxReturn : -37.489410400390625
Eval_MinReturn : -76.27783203125
Eval_AverageEpLen : 150.0
Train_AverageReturn : -86.97022247314453
Train_StdReturn : 35.51524353027344
Train_MaxReturn : 24.698869705200195
Train_MinReturn : -179.406982421875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1230000
TimeSinceStart : 2456.959400177002
Training Loss : 0.008782983757555485
Baseline Loss : 0.9171259999275208
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 41 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -92.74600982666016
Eval_StdReturn : 17.64628791809082
Eval_MaxReturn : -76.20445251464844
Eval_MinReturn : -117.19918823242188
Eval_AverageEpLen : 150.0
Train_AverageReturn : -85.45806884765625
Train_StdReturn : 36.40639114379883
Train_MaxReturn : 11.188015937805176
Train_MinReturn : -217.41346740722656
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1260000
TimeSinceStart : 2515.2729573249817
Training Loss : -0.012883740477263927
Baseline Loss : 0.9442914128303528
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 42 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -90.58199310302734
Eval_StdReturn : 36.710792541503906
Eval_MaxReturn : -45.992000579833984

Collecting data for eval...
Eval_AverageReturn : -62.33219528198242
Eval_StdReturn : 24.462345123291016
Eval_MaxReturn : -35.20576858520508
Eval_MinReturn : -94.48915100097656
Eval_AverageEpLen : 150.0
Train_AverageReturn : -87.31134796142578
Train_StdReturn : 26.461931228637695
Train_MaxReturn : 12.621871948242188
Train_MinReturn : -149.48497009277344
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1020000
TimeSinceStart : 2037.8129253387451
Training Loss : -0.021046696230769157
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 34 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -97.10076904296875
Eval_StdReturn : 32.648658752441406
Eval_MaxReturn : -73.56194305419922
Eval_MinReturn : -143.26995849609375
Eval_AverageEpLen : 150.0
Train_AverageReturn : -73.66846466064453
Train_StdReturn : 27.2877140045166
Train_MaxReturn : -4.625846862792969
Train_MinReturn : -157.9023895263672
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1050000
TimeSinceStart : 2096.81835770607
Training Loss : -0.012801232747733593
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 35 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -47.24892044067383
Eval_StdReturn : 8.222355842590332
Eval_MaxReturn : -37.69594955444336
Eval_MinReturn : -57.767032623291016
Eval_AverageEpLen : 150.0
Train_AverageReturn : -64.1958999633789
Train_StdReturn : 30.52591896057129
Train_MaxReturn : 41.00146484375
Train_MinReturn : -156.9274139404297
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1080000
TimeSinceStart : 2156.81330370903
Training Loss : -0.010145499370992184
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 36 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -64.09163665771484
Eval_StdReturn : 42.42287826538086
Eval_MaxReturn : -11.895042419433594
Eval_MinReturn : -115.80609130859375
Eval_AverageEpLen : 150.0
Train_AverageReturn : -63.57735824584961
Train_StdReturn : 28.57062339782715
Train_MaxReturn : 2.9948863983154297
Train_MinReturn : -183.91519165039062
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1110000
TimeSinceStart : 2217.044760942459
Training Loss : -0.009742912836372852
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 37 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -48.8943977355957
Eval_StdReturn : 23.61595916748047
Eval_MaxReturn : -15.536938667297363
Eval_MinReturn : -66.99796295166016
Eval_AverageEpLen : 150.0
Train_AverageReturn : -62.734310150146484
Train_StdReturn : 34.12548828125
Train_MaxReturn : 19.17026138305664
Train_MinReturn : -170.04986572265625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1140000
TimeSinceStart : 2276.610992193222
Training Loss : -0.007154288701713085
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 38 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -46.10603332519531
Eval_StdReturn : 33.05320358276367
Eval_MaxReturn : -7.392405986785889
Eval_MinReturn : -88.15013122558594
Eval_AverageEpLen : 150.0
Train_AverageReturn : -59.0701789855957
Train_StdReturn : 37.34154510498047
Train_MaxReturn : 26.133800506591797
Train_MinReturn : -217.7860107421875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1170000
TimeSinceStart : 2335.006877183914
Training Loss : -0.027933917939662933
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 39 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -52.52555465698242
Eval_StdReturn : 34.02027893066406
Eval_MaxReturn : -4.98232364654541
Eval_MinReturn : -82.68463134765625
Eval_AverageEpLen : 150.0
Train_AverageReturn : -52.836326599121094
Train_StdReturn : 38.835819244384766
Train_MaxReturn : 53.991268157958984
Train_MinReturn : -152.459716796875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1200000
TimeSinceStart : 2394.5791540145874
Training Loss : -0.014797837473452091
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 40 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -63.017208099365234
Eval_StdReturn : 44.175785064697266
Eval_MaxReturn : -15.205418586730957
Eval_MinReturn : -121.74801635742188
Eval_AverageEpLen : 150.0
Train_AverageReturn : -47.146728515625
Train_StdReturn : 41.79075622558594
Train_MaxReturn : 58.44429016113281
Train_MinReturn : -179.85107421875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1230000
TimeSinceStart : 2453.0972139835358
Training Loss : -0.017872698605060577
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 41 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -18.68854522705078
Eval_StdReturn : 68.6215591430664
Eval_MaxReturn : 41.35847473144531
Eval_MinReturn : -114.73587036132812
Eval_AverageEpLen : 150.0
Train_AverageReturn : -44.327247619628906
Train_StdReturn : 48.643516540527344
Train_MaxReturn : 89.60598754882812
Train_MinReturn : -196.093505859375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1260000
TimeSinceStart : 2511.556131362915
Training Loss : -0.03671722859144211
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 42 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -16.206951141357422
Eval_StdReturn : 12.77990436553955
Eval_MaxReturn : -0.23969268798828125
Eval_MinReturn : -31.523651123046875
Eval_AverageEpLen : 150.0
Train_AverageReturn : -45.15896987915039
Train_StdReturn : 52.4761962890625
Train_MaxReturn : 113.69669342041016
Train_MinReturn : -185.88134765625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1290000
TimeSinceStart : 2569.7193851470947
Training Loss : -0.0134555259719491
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 43 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -69.96283721923828
Eval_StdReturn : 96.11027526855469
Eval_MaxReturn : 57.95424270629883
Eval_MinReturn : -173.71701049804688
Eval_AverageEpLen : 150.0
Train_AverageReturn : -46.852027893066406
Train_StdReturn : 54.727203369140625
Train_MaxReturn : 64.34661865234375
Train_MinReturn : -165.53407287597656
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1320000
TimeSinceStart : 2630.62637090683
Training Loss : -0.0029511190950870514
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 44 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -63.91334915161133
Eval_StdReturn : 53.46932601928711
Eval_MaxReturn : 4.787125110626221
Eval_AverageReturn : -1.5429242849349976
Eval_StdReturn : 19.97216033935547
Eval_MaxReturn : 24.393840789794922
Eval_MinReturn : -24.196033477783203
Eval_AverageEpLen : 150.0
Train_AverageReturn : -15.188032150268555
Train_StdReturn : 12.668281555175781
Train_MaxReturn : 15.015877723693848
Train_MinReturn : -52.8422737121582
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1020000
TimeSinceStart : 2040.9733872413635
Training Loss : -0.03826304152607918
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 34 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -12.458610534667969
Eval_StdReturn : 5.359626770019531
Eval_MaxReturn : -6.922794342041016
Eval_MinReturn : -19.710317611694336
Eval_AverageEpLen : 150.0
Train_AverageReturn : -11.6621675491333
Train_StdReturn : 14.06823444366455
Train_MaxReturn : 38.49948501586914
Train_MinReturn : -52.91053009033203
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1050000
TimeSinceStart : 2099.9721822738647
Training Loss : -0.0723239853978157
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 35 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -1.534871220588684
Eval_StdReturn : 3.428323268890381
Eval_MaxReturn : 1.958099365234375
Eval_MinReturn : -6.1933088302612305
Eval_AverageEpLen : 150.0
Train_AverageReturn : -4.451294422149658
Train_StdReturn : 13.957392692565918
Train_MaxReturn : 39.19405746459961
Train_MinReturn : -45.16239547729492
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1080000
TimeSinceStart : 2159.9087426662445
Training Loss : -0.05698416382074356
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 36 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -3.152500867843628
Eval_StdReturn : 9.910128593444824
Eval_MaxReturn : 10.37276840209961
Eval_MinReturn : -13.095748901367188
Eval_AverageEpLen : 150.0
Train_AverageReturn : -1.7290236949920654
Train_StdReturn : 13.773276329040527
Train_MaxReturn : 43.18778991699219
Train_MinReturn : -54.4368896484375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1110000
TimeSinceStart : 2219.8970935344696
Training Loss : -0.059647683054208755
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 37 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 4.257927417755127
Eval_StdReturn : 20.395105361938477
Eval_MaxReturn : 27.923776626586914
Eval_MinReturn : -21.853872299194336
Eval_AverageEpLen : 150.0
Train_AverageReturn : 1.5040992498397827
Train_StdReturn : 13.53296947479248
Train_MaxReturn : 36.209869384765625
Train_MinReturn : -53.76322555541992
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1140000
TimeSinceStart : 2279.403451681137
Training Loss : -0.06035958230495453
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 38 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -5.912387847900391
Eval_StdReturn : 4.154542922973633
Eval_MaxReturn : -0.29307010769844055
Eval_MinReturn : -10.207910537719727
Eval_AverageEpLen : 150.0
Train_AverageReturn : 5.190656661987305
Train_StdReturn : 12.619600296020508
Train_MaxReturn : 39.6724853515625
Train_MinReturn : -37.79238510131836
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1170000
TimeSinceStart : 2337.8883712291718
Training Loss : -0.048589907586574554
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 39 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 2.1777639389038086
Eval_StdReturn : 28.592439651489258
Eval_MaxReturn : 40.655067443847656
Eval_MinReturn : -27.827232360839844
Eval_AverageEpLen : 150.0
Train_AverageReturn : 8.409567832946777
Train_StdReturn : 14.03096866607666
Train_MaxReturn : 53.67552947998047
Train_MinReturn : -28.517963409423828
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1200000
TimeSinceStart : 2397.442305088043
Training Loss : -0.0536617636680603
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 40 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 12.523884773254395
Eval_StdReturn : 7.119097709655762
Eval_MaxReturn : 21.85321807861328
Eval_MinReturn : 4.581263542175293
Eval_AverageEpLen : 150.0
Train_AverageReturn : 11.956777572631836
Train_StdReturn : 12.62681770324707
Train_MaxReturn : 43.033973693847656
Train_MinReturn : -19.29834747314453
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1230000
TimeSinceStart : 2455.9401626586914
Training Loss : -0.044023219496011734
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 41 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 6.224332809448242
Eval_StdReturn : 25.56696319580078
Eval_MaxReturn : 36.75965118408203
Eval_MinReturn : -25.81235122680664
Eval_AverageEpLen : 150.0
Train_AverageReturn : 15.294297218322754
Train_StdReturn : 13.037922859191895
Train_MaxReturn : 46.53081512451172
Train_MinReturn : -24.6016845703125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1260000
TimeSinceStart : 2514.39745426178
Training Loss : -0.05392632633447647
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 42 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 21.909990310668945
Eval_StdReturn : 8.466946601867676
Eval_MaxReturn : 30.16975975036621
Eval_MinReturn : 10.272382736206055
Eval_AverageEpLen : 150.0
Train_AverageReturn : 20.068214416503906
Train_StdReturn : 13.835297584533691
Train_MaxReturn : 56.97064208984375
Train_MinReturn : -27.173595428466797
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1290000
TimeSinceStart : 2573.0517241954803
Training Loss : -0.04185181483626366
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 43 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 38.98862075805664
Eval_StdReturn : 5.766519069671631
Eval_MaxReturn : 44.591773986816406
Eval_MinReturn : 31.055511474609375
Eval_AverageEpLen : 150.0
Train_AverageReturn : 25.317384719848633
Train_StdReturn : 16.001630783081055
Train_MaxReturn : 69.54475402832031
Train_MinReturn : -44.942420959472656
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1320000
TimeSinceStart : 2633.618524312973
Training Loss : -0.05607856437563896
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 44 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 20.82177734375
Eval_StdReturn : 5.2349958419799805
Eval_MaxReturn : 27.94549560546875
Eval_MinReturn : 15.514281272888184
Eval_MinReturn : -135.90573120117188
Eval_AverageEpLen : 150.0
Train_AverageReturn : -84.33441162109375
Train_StdReturn : 37.5078239440918
Train_MaxReturn : 4.374447345733643
Train_MinReturn : -227.488525390625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1290000
TimeSinceStart : 2573.8451948165894
Training Loss : 0.010564872063696384
Baseline Loss : 0.9408887028694153
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 43 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -76.25023651123047
Eval_StdReturn : 31.707204818725586
Eval_MaxReturn : -42.78810501098633
Eval_MinReturn : -118.83153533935547
Eval_AverageEpLen : 150.0
Train_AverageReturn : -81.95484161376953
Train_StdReturn : 34.36827850341797
Train_MaxReturn : 18.577808380126953
Train_MinReturn : -172.84129333496094
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1320000
TimeSinceStart : 2634.214836835861
Training Loss : 0.0014891622122377157
Baseline Loss : 0.9627550840377808
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 44 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -38.692012786865234
Eval_StdReturn : 29.69820213317871
Eval_MaxReturn : 2.8603248596191406
Eval_MinReturn : -64.76225280761719
Eval_AverageEpLen : 150.0
Train_AverageReturn : -88.6682357788086
Train_StdReturn : 35.079830169677734
Train_MaxReturn : -13.630558013916016
Train_MinReturn : -208.08837890625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1350000
TimeSinceStart : 2694.0381355285645
Training Loss : -0.013636833056807518
Baseline Loss : 0.9321513772010803
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 45 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -112.2441635131836
Eval_StdReturn : 10.809212684631348
Eval_MaxReturn : -98.521240234375
Eval_MinReturn : -124.93826293945312
Eval_AverageEpLen : 150.0
Train_AverageReturn : -82.66854858398438
Train_StdReturn : 32.685482025146484
Train_MaxReturn : 0.6945421695709229
Train_MinReturn : -157.31723022460938
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1380000
TimeSinceStart : 2752.450038909912
Training Loss : 0.004383211489766836
Baseline Loss : 0.9690263867378235
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 46 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -74.73480224609375
Eval_StdReturn : 21.47922134399414
Eval_MaxReturn : -49.312744140625
Eval_MinReturn : -101.8446044921875
Eval_AverageEpLen : 150.0
Train_AverageReturn : -84.82234191894531
Train_StdReturn : 31.435867309570312
Train_MaxReturn : 14.479515075683594
Train_MinReturn : -158.58331298828125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1410000
TimeSinceStart : 2810.839340686798
Training Loss : 0.0013746297918260098
Baseline Loss : 0.9478877186775208
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 47 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -79.7790298461914
Eval_StdReturn : 13.961078643798828
Eval_MaxReturn : -67.18209075927734
Eval_MinReturn : -99.24394989013672
Eval_AverageEpLen : 150.0
Train_AverageReturn : -83.68335723876953
Train_StdReturn : 32.05277633666992
Train_MaxReturn : -8.730854988098145
Train_MinReturn : -194.105712890625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1440000
TimeSinceStart : 2868.9210665225983
Training Loss : -0.014542496763169765
Baseline Loss : 0.9538687467575073
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 48 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -64.22289276123047
Eval_StdReturn : 22.97158432006836
Eval_MaxReturn : -38.84619903564453
Eval_MinReturn : -94.47705841064453
Eval_AverageEpLen : 150.0
Train_AverageReturn : -81.17064666748047
Train_StdReturn : 34.25638198852539
Train_MaxReturn : 4.781623840332031
Train_MinReturn : -186.19183349609375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1470000
TimeSinceStart : 2927.280066728592
Training Loss : -0.017645182088017464
Baseline Loss : 0.9613105654716492
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 49 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -91.67777252197266
Eval_StdReturn : 20.205074310302734
Eval_MaxReturn : -74.87443542480469
Eval_MinReturn : -120.09452056884766
Eval_AverageEpLen : 150.0
Train_AverageReturn : -80.19723510742188
Train_StdReturn : 38.32048797607422
Train_MaxReturn : 41.622772216796875
Train_MinReturn : -188.30763244628906
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1500000
TimeSinceStart : 2985.6443717479706
Training Loss : -0.0011582926381379366
Baseline Loss : 0.9308494329452515
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 50 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -72.54875946044922
Eval_StdReturn : 14.463993072509766
Eval_MaxReturn : -54.02603530883789
Eval_MinReturn : -89.32624816894531
Eval_AverageEpLen : 150.0
Train_AverageReturn : -77.49373626708984
Train_StdReturn : 38.88372802734375
Train_MaxReturn : 26.337844848632812
Train_MinReturn : -206.29501342773438
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1530000
TimeSinceStart : 3043.9618623256683
Training Loss : -0.0053253755904734135
Baseline Loss : 0.9031524658203125
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 51 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -27.66892433166504
Eval_StdReturn : 16.186145782470703
Eval_MaxReturn : -5.814241409301758
Eval_MinReturn : -44.49258041381836
Eval_AverageEpLen : 150.0
Train_AverageReturn : -71.36737823486328
Train_StdReturn : 32.3529167175293
Train_MaxReturn : -2.828538656234741
Train_MinReturn : -160.16293334960938
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1560000
TimeSinceStart : 3102.1546552181244
Training Loss : -0.006871661636978388
Baseline Loss : 0.953348696231842
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 52 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -58.82073974609375
Eval_StdReturn : 29.696643829345703
Eval_MaxReturn : -20.34182357788086
Eval_MinReturn : -92.63297271728516
Eval_AverageEpLen : 150.0
Train_AverageReturn : -61.30165100097656
Train_StdReturn : 36.91334915161133
Train_MaxReturn : 38.9903564453125
Train_MinReturn : -179.42044067382812
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1590000
TimeSinceStart : 3160.9096512794495
Training Loss : -0.008764030411839485
Baseline Loss : 0.9632160663604736
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 53 ************
Train_StdReturn : 32.49392318725586
Train_MaxReturn : 180.807861328125
Train_MinReturn : -32.72915267944336
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1290000
TimeSinceStart : 2568.7003190517426
Training Loss : -0.04335172474384308
Baseline Loss : 0.6513556241989136
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 43 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 88.32162475585938
Eval_StdReturn : 8.462788581848145
Eval_MaxReturn : 99.76991271972656
Eval_MinReturn : 79.57577514648438
Eval_AverageEpLen : 150.0
Train_AverageReturn : 100.0745620727539
Train_StdReturn : 29.552051544189453
Train_MaxReturn : 211.67982482910156
Train_MinReturn : 32.678955078125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1320000
TimeSinceStart : 2629.573381662369
Training Loss : -0.05927013233304024
Baseline Loss : 0.6421164274215698
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 44 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 110.6884765625
Eval_StdReturn : 23.094633102416992
Eval_MaxReturn : 143.33062744140625
Eval_MinReturn : 93.41304779052734
Eval_AverageEpLen : 150.0
Train_AverageReturn : 104.06298828125
Train_StdReturn : 27.819690704345703
Train_MaxReturn : 174.39373779296875
Train_MinReturn : 6.202630996704102
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1350000
TimeSinceStart : 2689.606097459793
Training Loss : -0.04481431469321251
Baseline Loss : 0.6915060877799988
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 45 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 122.2621078491211
Eval_StdReturn : 15.73304557800293
Eval_MaxReturn : 141.12490844726562
Eval_MinReturn : 102.61116027832031
Eval_AverageEpLen : 150.0
Train_AverageReturn : 111.54553985595703
Train_StdReturn : 31.393875122070312
Train_MaxReturn : 187.78802490234375
Train_MinReturn : 14.568073272705078
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1380000
TimeSinceStart : 2748.014672279358
Training Loss : -0.039132650941610336
Baseline Loss : 0.6773850321769714
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 46 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 120.54827880859375
Eval_StdReturn : 38.386661529541016
Eval_MaxReturn : 172.50820922851562
Eval_MinReturn : 80.95112609863281
Eval_AverageEpLen : 150.0
Train_AverageReturn : 120.88939666748047
Train_StdReturn : 27.94261932373047
Train_MaxReturn : 213.02439880371094
Train_MinReturn : 49.126869201660156
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1410000
TimeSinceStart : 2806.5070662498474
Training Loss : -0.034610629081726074
Baseline Loss : 0.66280198097229
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 47 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 143.87498474121094
Eval_StdReturn : 29.36946678161621
Eval_MaxReturn : 172.99591064453125
Eval_MinReturn : 103.6663818359375
Eval_AverageEpLen : 150.0
Train_AverageReturn : 134.1397705078125
Train_StdReturn : 28.80780601501465
Train_MaxReturn : 203.51707458496094
Train_MinReturn : 43.428016662597656
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1440000
TimeSinceStart : 2864.6964445114136
Training Loss : -0.037479184567928314
Baseline Loss : 0.6583786606788635
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 48 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 134.49082946777344
Eval_StdReturn : 51.40248489379883
Eval_MaxReturn : 206.61309814453125
Eval_MinReturn : 90.54884338378906
Eval_AverageEpLen : 150.0
Train_AverageReturn : 149.66275024414062
Train_StdReturn : 32.1356086730957
Train_MaxReturn : 232.70999145507812
Train_MinReturn : -8.826183319091797
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1470000
TimeSinceStart : 2923.0636327266693
Training Loss : -0.05262802913784981
Baseline Loss : 0.6593385338783264
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 49 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 160.74403381347656
Eval_StdReturn : 8.970362663269043
Eval_MaxReturn : 173.4027099609375
Eval_MinReturn : 153.6937713623047
Eval_AverageEpLen : 150.0
Train_AverageReturn : 150.16766357421875
Train_StdReturn : 39.77497863769531
Train_MaxReturn : 272.48919677734375
Train_MinReturn : 49.94617462158203
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1500000
TimeSinceStart : 2981.5589356422424
Training Loss : -0.045673977583646774
Baseline Loss : 0.6077747941017151
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 50 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 146.31324768066406
Eval_StdReturn : 23.558650970458984
Eval_MaxReturn : 179.348388671875
Eval_MinReturn : 126.05067443847656
Eval_AverageEpLen : 150.0
Train_AverageReturn : 145.8997802734375
Train_StdReturn : 40.4294319152832
Train_MaxReturn : 241.3273162841797
Train_MinReturn : 61.27726745605469
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1530000
TimeSinceStart : 3039.831032514572
Training Loss : -0.04190121963620186
Baseline Loss : 0.5766690969467163
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 51 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 205.1702423095703
Eval_StdReturn : 11.06973648071289
Eval_MaxReturn : 220.71621704101562
Eval_MinReturn : 195.80010986328125
Eval_AverageEpLen : 150.0
Train_AverageReturn : 177.2126007080078
Train_StdReturn : 41.237770080566406
Train_MaxReturn : 280.17535400390625
Train_MinReturn : 45.08882522583008
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1560000
TimeSinceStart : 3098.0901765823364
Training Loss : -0.01812147907912731
Baseline Loss : 0.5892581939697266
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 52 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 184.32603454589844
Eval_StdReturn : 55.065895080566406
Eval_MaxReturn : 260.75323486328125
Eval_MinReturn : 133.16868591308594
Eval_AverageEpLen : 150.0
Train_AverageReturn : 185.34683227539062
Train_StdReturn : 42.11624526977539
Train_MaxReturn : 293.1040344238281
Train_MinReturn : 58.98352813720703
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1590000
TimeSinceStart : 3156.607344865799
Training Loss : -0.03480079770088196
Baseline Loss : 0.6256452798843384
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 53 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_MinReturn : -125.62480163574219
Eval_AverageEpLen : 150.0
Train_AverageReturn : -59.22603988647461
Train_StdReturn : 59.73219299316406
Train_MaxReturn : 115.97416687011719
Train_MinReturn : -194.5924530029297
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1350000
TimeSinceStart : 2690.6423964500427
Training Loss : 0.0020638713613152504
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 45 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -70.33847045898438
Eval_StdReturn : 12.421185493469238
Eval_MaxReturn : -56.115665435791016
Eval_MinReturn : -86.37806701660156
Eval_AverageEpLen : 150.0
Train_AverageReturn : -69.5976333618164
Train_StdReturn : 57.23469161987305
Train_MaxReturn : 75.0766830444336
Train_MinReturn : -206.4908447265625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1380000
TimeSinceStart : 2749.023352622986
Training Loss : 0.010653475299477577
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 46 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -87.76019287109375
Eval_StdReturn : 70.93865203857422
Eval_MaxReturn : -36.87226104736328
Eval_MinReturn : -188.07907104492188
Eval_AverageEpLen : 150.0
Train_AverageReturn : -77.20712280273438
Train_StdReturn : 61.61107635498047
Train_MaxReturn : 94.18443298339844
Train_MinReturn : -275.89813232421875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1410000
TimeSinceStart : 2807.5740163326263
Training Loss : 0.0060553038492798805
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 47 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -130.86863708496094
Eval_StdReturn : 20.804460525512695
Eval_MaxReturn : -110.93425750732422
Eval_MinReturn : -159.57626342773438
Eval_AverageEpLen : 150.0
Train_AverageReturn : -70.61702728271484
Train_StdReturn : 68.3811264038086
Train_MaxReturn : 76.18389892578125
Train_MinReturn : -258.85235595703125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1440000
TimeSinceStart : 2865.6656193733215
Training Loss : -0.0006326772272586823
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 48 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -61.00812911987305
Eval_StdReturn : 41.92155838012695
Eval_MaxReturn : -4.219875335693359
Eval_MinReturn : -104.1483154296875
Eval_AverageEpLen : 150.0
Train_AverageReturn : -84.51148223876953
Train_StdReturn : 61.5594482421875
Train_MaxReturn : 82.79658508300781
Train_MinReturn : -215.0139923095703
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1470000
TimeSinceStart : 2924.017451763153
Training Loss : -0.0015440938295796514
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 49 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -118.39794921875
Eval_StdReturn : 30.770109176635742
Eval_MaxReturn : -78.32511901855469
Eval_MinReturn : -153.1253662109375
Eval_AverageEpLen : 150.0
Train_AverageReturn : -78.15400695800781
Train_StdReturn : 68.32671356201172
Train_MaxReturn : 131.7875518798828
Train_MinReturn : -225.70870971679688
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1500000
TimeSinceStart : 2982.5324425697327
Training Loss : 0.009674062952399254
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 50 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -45.43678665161133
Eval_StdReturn : 56.699153900146484
Eval_MaxReturn : 18.988731384277344
Eval_MinReturn : -118.99208068847656
Eval_AverageEpLen : 150.0
Train_AverageReturn : -71.88908386230469
Train_StdReturn : 62.94942092895508
Train_MaxReturn : 71.17109680175781
Train_MinReturn : -187.64358520507812
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1530000
TimeSinceStart : 3040.8478956222534
Training Loss : -0.0031538838520646095
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 51 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -18.623886108398438
Eval_StdReturn : 33.01752853393555
Eval_MaxReturn : 26.874794006347656
Eval_MinReturn : -50.463783264160156
Eval_AverageEpLen : 150.0
Train_AverageReturn : -67.49299621582031
Train_StdReturn : 62.501686096191406
Train_MaxReturn : 99.74629974365234
Train_MinReturn : -200.23532104492188
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1560000
TimeSinceStart : 3099.1183066368103
Training Loss : -0.005495003890246153
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 52 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -113.32852935791016
Eval_StdReturn : 5.242198467254639
Eval_MaxReturn : -108.02717590332031
Eval_MinReturn : -120.46726989746094
Eval_AverageEpLen : 150.0
Train_AverageReturn : -67.22522735595703
Train_StdReturn : 56.973602294921875
Train_MaxReturn : 81.73158264160156
Train_MinReturn : -195.33224487304688
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1590000
TimeSinceStart : 3157.61913394928
Training Loss : -0.01981445960700512
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 53 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -32.56821823120117
Eval_StdReturn : 75.5848159790039
Eval_MaxReturn : 74.1932373046875
Eval_MinReturn : -90.54149627685547
Eval_AverageEpLen : 150.0
Train_AverageReturn : -61.741275787353516
Train_StdReturn : 56.77873611450195
Train_MaxReturn : 93.27969360351562
Train_MinReturn : -216.62623596191406
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1620000
TimeSinceStart : 3216.039479970932
Training Loss : 0.014431801624596119
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 54 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -32.0178108215332
Eval_StdReturn : 17.7954044342041
Eval_MaxReturn : -16.523849487304688
Eval_MinReturn : -56.93941116333008
Eval_AverageEpLen : 150.0
Train_AverageReturn : -57.71625518798828
Train_StdReturn : 55.3999137878418
Train_MaxReturn : 88.01736450195312
Train_MinReturn : -178.17813110351562
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1650000
TimeSinceStart : 3274.040625333786
Training Loss : 0.004867599345743656
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 55 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -42.64825439453125
Eval_StdReturn : 14.538931846618652
Eval_MaxReturn : -26.07462501525879
Eval_MinReturn : -61.47342300415039
Eval_AverageEpLen : 150.0
Train_AverageReturn : -47.584716796875
Train_StdReturn : 45.68291473388672
Eval_AverageEpLen : 150.0
Train_AverageReturn : 27.687925338745117
Train_StdReturn : 17.267078399658203
Train_MaxReturn : 61.25994110107422
Train_MinReturn : -58.469852447509766
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1350000
TimeSinceStart : 2693.651727437973
Training Loss : -0.05616284906864166
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 45 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 25.62421226501465
Eval_StdReturn : 4.649731159210205
Eval_MaxReturn : 29.807750701904297
Eval_MinReturn : 19.138866424560547
Eval_AverageEpLen : 150.0
Train_AverageReturn : 33.01734924316406
Train_StdReturn : 19.536190032958984
Train_MaxReturn : 85.64581298828125
Train_MinReturn : -28.03044319152832
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1380000
TimeSinceStart : 2752.0717329978943
Training Loss : -0.04143289476633072
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 46 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 34.29146957397461
Eval_StdReturn : 12.909638404846191
Eval_MaxReturn : 50.70751190185547
Eval_MinReturn : 19.16439437866211
Eval_AverageEpLen : 150.0
Train_AverageReturn : 34.949378967285156
Train_StdReturn : 19.95219612121582
Train_MaxReturn : 88.67740631103516
Train_MinReturn : -34.80805206298828
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1410000
TimeSinceStart : 2810.5659997463226
Training Loss : -0.06642018258571625
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 47 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 53.98663330078125
Eval_StdReturn : 1.9281268119812012
Eval_MaxReturn : 55.95545959472656
Eval_MinReturn : 51.3684196472168
Eval_AverageEpLen : 150.0
Train_AverageReturn : 41.3547248840332
Train_StdReturn : 24.030580520629883
Train_MaxReturn : 90.23452758789062
Train_MinReturn : -54.68390655517578
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1440000
TimeSinceStart : 2868.725031375885
Training Loss : -0.05022653564810753
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 48 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 63.47834396362305
Eval_StdReturn : 8.95811939239502
Eval_MaxReturn : 70.73063659667969
Eval_MinReturn : 50.856361389160156
Eval_AverageEpLen : 150.0
Train_AverageReturn : 39.03287124633789
Train_StdReturn : 24.395360946655273
Train_MaxReturn : 89.45954895019531
Train_MinReturn : -59.472450256347656
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1470000
TimeSinceStart : 2927.2463715076447
Training Loss : -0.04512335732579231
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 49 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 23.237009048461914
Eval_StdReturn : 39.603302001953125
Eval_MaxReturn : 64.37582397460938
Eval_MinReturn : -30.246387481689453
Eval_AverageEpLen : 150.0
Train_AverageReturn : 32.825401306152344
Train_StdReturn : 29.960182189941406
Train_MaxReturn : 82.81965637207031
Train_MinReturn : -66.39109802246094
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1500000
TimeSinceStart : 2985.6441717147827
Training Loss : -0.06126764044165611
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 50 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 40.62430953979492
Eval_StdReturn : 17.978925704956055
Eval_MaxReturn : 64.66049194335938
Eval_MinReturn : 21.425750732421875
Eval_AverageEpLen : 150.0
Train_AverageReturn : 39.6544189453125
Train_StdReturn : 23.514156341552734
Train_MaxReturn : 77.80160522460938
Train_MinReturn : -42.92816925048828
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1530000
TimeSinceStart : 3043.889971971512
Training Loss : -0.0487113781273365
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 51 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 36.48972702026367
Eval_StdReturn : 24.235610961914062
Eval_MaxReturn : 67.32235717773438
Eval_MinReturn : 8.109657287597656
Eval_AverageEpLen : 150.0
Train_AverageReturn : 51.34083557128906
Train_StdReturn : 18.631248474121094
Train_MaxReturn : 94.75807189941406
Train_MinReturn : -24.48065185546875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1560000
TimeSinceStart : 3102.1848294734955
Training Loss : -0.04781621694564819
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 52 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 74.9380111694336
Eval_StdReturn : 8.45665168762207
Eval_MaxReturn : 86.33549499511719
Eval_MinReturn : 66.10152435302734
Eval_AverageEpLen : 150.0
Train_AverageReturn : 55.23353576660156
Train_StdReturn : 21.580591201782227
Train_MaxReturn : 93.57660675048828
Train_MinReturn : -37.96048355102539
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1590000
TimeSinceStart : 3160.6508395671844
Training Loss : -0.055309440940618515
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 53 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 91.87784576416016
Eval_StdReturn : 13.070358276367188
Eval_MaxReturn : 103.39080810546875
Eval_MinReturn : 73.59778594970703
Eval_AverageEpLen : 150.0
Train_AverageReturn : 61.16850662231445
Train_StdReturn : 20.402448654174805
Train_MaxReturn : 109.74781036376953
Train_MinReturn : -9.100377082824707
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1620000
TimeSinceStart : 3219.012687444687
Training Loss : -0.03722837194800377
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 54 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 58.13335037231445
Eval_StdReturn : 4.30153226852417
Eval_MaxReturn : 64.06404876708984
Eval_MinReturn : 53.995445251464844
Eval_AverageEpLen : 150.0
Train_AverageReturn : 68.13835144042969
Train_StdReturn : 19.644794464111328
Train_MaxReturn : 118.10430145263672
Train_MinReturn : -17.774188995361328
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1650000
TimeSinceStart : 3277.1389939785004
Training Loss : -0.04726710170507431
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 55 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 70.03748321533203
Eval_StdReturn : 9.725406646728516
Eval_MaxReturn : 81.3243637084961
Eval_MinReturn : 57.587425231933594
Eval_AverageEpLen : 150.0
Train_AverageReturn : 65.1755142211914
Train_StdReturn : 14.869538307189941
Train_MaxReturn : 108.53633117675781
Train_MinReturn : 25.45409393310547
Eval_AverageReturn : 187.5360565185547
Eval_StdReturn : 28.431528091430664
Eval_MaxReturn : 215.580810546875
Eval_MinReturn : 148.560791015625
Eval_AverageEpLen : 150.0
Train_AverageReturn : 193.8124237060547
Train_StdReturn : 44.59859085083008
Train_MaxReturn : 311.0367126464844
Train_MinReturn : 87.00209045410156
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1620000
TimeSinceStart : 3215.125390291214
Training Loss : -0.016905542463064194
Baseline Loss : 0.7257050275802612
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 54 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 198.4483642578125
Eval_StdReturn : 23.9789981842041
Eval_MaxReturn : 218.30703735351562
Eval_MinReturn : 164.71327209472656
Eval_AverageEpLen : 150.0
Train_AverageReturn : 192.33358764648438
Train_StdReturn : 47.24829864501953
Train_MaxReturn : 308.8619079589844
Train_MinReturn : 32.68596649169922
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1650000
TimeSinceStart : 3273.1465966701508
Training Loss : -0.03737994655966759
Baseline Loss : 0.5933058857917786
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 55 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 218.78770446777344
Eval_StdReturn : 57.649967193603516
Eval_MaxReturn : 269.0897216796875
Eval_MinReturn : 138.07089233398438
Eval_AverageEpLen : 150.0
Train_AverageReturn : 190.80308532714844
Train_StdReturn : 47.297325134277344
Train_MaxReturn : 328.54046630859375
Train_MinReturn : 70.55382537841797
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1680000
TimeSinceStart : 3331.1802265644073
Training Loss : -0.030879201367497444
Baseline Loss : 0.6053625345230103
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 56 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 214.24774169921875
Eval_StdReturn : 57.203125
Eval_MaxReturn : 261.59259033203125
Eval_MinReturn : 133.76734924316406
Eval_AverageEpLen : 150.0
Train_AverageReturn : 194.11453247070312
Train_StdReturn : 49.861663818359375
Train_MaxReturn : 325.97906494140625
Train_MinReturn : 66.06021881103516
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1710000
TimeSinceStart : 3389.1073875427246
Training Loss : -0.03414614126086235
Baseline Loss : 0.6176733374595642
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 57 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 212.95741271972656
Eval_StdReturn : 36.30381774902344
Eval_MaxReturn : 257.1843566894531
Eval_MinReturn : 168.26222229003906
Eval_AverageEpLen : 150.0
Train_AverageReturn : 208.22105407714844
Train_StdReturn : 39.995384216308594
Train_MaxReturn : 307.0004577636719
Train_MinReturn : 91.87979125976562
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1740000
TimeSinceStart : 3448.1454000473022
Training Loss : -0.02012871950864792
Baseline Loss : 0.6616360545158386
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 58 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 145.80955505371094
Eval_StdReturn : 11.65842342376709
Eval_MaxReturn : 161.10507202148438
Eval_MinReturn : 132.83135986328125
Eval_AverageEpLen : 150.0
Train_AverageReturn : 195.55690002441406
Train_StdReturn : 49.137203216552734
Train_MaxReturn : 309.7385559082031
Train_MinReturn : 61.468589782714844
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1770000
TimeSinceStart : 3506.233464241028
Training Loss : -0.033906228840351105
Baseline Loss : 0.5859199166297913
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 59 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 182.3314208984375
Eval_StdReturn : 34.176605224609375
Eval_MaxReturn : 211.90121459960938
Eval_MinReturn : 134.43638610839844
Eval_AverageEpLen : 150.0
Train_AverageReturn : 142.5013427734375
Train_StdReturn : 50.27938461303711
Train_MaxReturn : 294.5980224609375
Train_MinReturn : 42.399940490722656
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1800000
TimeSinceStart : 3564.958946943283
Training Loss : -0.04529719427227974
Baseline Loss : 0.7337629199028015
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 60 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 228.15296936035156
Eval_StdReturn : 2.9036638736724854
Eval_MaxReturn : 232.02706909179688
Eval_MinReturn : 225.03675842285156
Eval_AverageEpLen : 150.0
Train_AverageReturn : 198.66749572753906
Train_StdReturn : 36.828460693359375
Train_MaxReturn : 287.50750732421875
Train_MinReturn : 111.2171630859375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1830000
TimeSinceStart : 3624.7565610408783
Training Loss : -0.07163716107606888
Baseline Loss : 0.5847457051277161
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 61 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 193.119140625
Eval_StdReturn : 32.922454833984375
Eval_MaxReturn : 233.23739624023438
Eval_MinReturn : 152.5972137451172
Eval_AverageEpLen : 150.0
Train_AverageReturn : 229.67599487304688
Train_StdReturn : 33.446876525878906
Train_MaxReturn : 310.108154296875
Train_MinReturn : 141.9998016357422
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1860000
TimeSinceStart : 3683.40829205513
Training Loss : -0.020175931975245476
Baseline Loss : 0.8527182340621948
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 62 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 227.1980743408203
Eval_StdReturn : 33.38066482543945
Eval_MaxReturn : 261.9993591308594
Eval_MinReturn : 182.17396545410156
Eval_AverageEpLen : 150.0
Train_AverageReturn : 214.42359924316406
Train_StdReturn : 41.05173873901367
Train_MaxReturn : 292.624267578125
Train_MinReturn : 11.467658996582031
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1890000
TimeSinceStart : 3741.549325466156
Training Loss : -0.034363068640232086
Baseline Loss : 0.8016874194145203
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 63 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 216.8203582763672
Eval_StdReturn : 52.29799270629883
Eval_MaxReturn : 264.06689453125
Eval_MinReturn : 143.9178466796875
Eval_AverageEpLen : 150.0
Train_AverageReturn : 233.6666259765625
Train_StdReturn : 37.80982971191406
Train_MaxReturn : 349.4400329589844
Train_MinReturn : 65.97959899902344
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1920000
TimeSinceStart : 3799.9691109657288
Training Loss : -0.0017993154469877481
Baseline Loss : 0.7798976898193359
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...



Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -87.87155151367188
Eval_StdReturn : 43.240779876708984
Eval_MaxReturn : -26.942108154296875
Eval_MinReturn : -122.84733581542969
Eval_AverageEpLen : 150.0
Train_AverageReturn : -62.641990661621094
Train_StdReturn : 38.8977165222168
Train_MaxReturn : 47.402706146240234
Train_MinReturn : -164.2261962890625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1620000
TimeSinceStart : 3219.3628809452057
Training Loss : 0.0026030365843325853
Baseline Loss : 0.9234439134597778
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 54 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -58.23604965209961
Eval_StdReturn : 49.029537200927734
Eval_MaxReturn : -22.22740936279297
Eval_MinReturn : -127.55680847167969
Eval_AverageEpLen : 150.0
Train_AverageReturn : -55.09774398803711
Train_StdReturn : 39.342140197753906
Train_MaxReturn : 50.791587829589844
Train_MinReturn : -176.96682739257812
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1650000
TimeSinceStart : 3277.497688293457
Training Loss : -0.024414855986833572
Baseline Loss : 0.9183139801025391
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 55 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -10.8219575881958
Eval_StdReturn : 63.743324279785156
Eval_MaxReturn : 38.80895233154297
Eval_MinReturn : -100.8094711303711
Eval_AverageEpLen : 150.0
Train_AverageReturn : -55.547508239746094
Train_StdReturn : 37.08181381225586
Train_MaxReturn : 47.581398010253906
Train_MinReturn : -165.23959350585938
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1680000
TimeSinceStart : 3335.6598801612854
Training Loss : -0.014219539240002632
Baseline Loss : 0.9730010628700256
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 56 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -48.88307571411133
Eval_StdReturn : 37.87604522705078
Eval_MaxReturn : -13.222827911376953
Eval_MinReturn : -101.3275375366211
Eval_AverageEpLen : 150.0
Train_AverageReturn : -61.11606979370117
Train_StdReturn : 38.19962692260742
Train_MaxReturn : 47.69221878051758
Train_MinReturn : -192.97059631347656
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1710000
TimeSinceStart : 3393.598354101181
Training Loss : -0.0032776936423033476
Baseline Loss : 0.9437916874885559
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 57 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -22.508272171020508
Eval_StdReturn : 29.198284149169922
Eval_MaxReturn : 13.144591331481934
Eval_MinReturn : -58.375343322753906
Eval_AverageEpLen : 150.0
Train_AverageReturn : -64.18215942382812
Train_StdReturn : 40.80158233642578
Train_MaxReturn : 64.0323257446289
Train_MinReturn : -159.0096435546875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1740000
TimeSinceStart : 3452.6817524433136
Training Loss : -0.011671891435980797
Baseline Loss : 0.9490569829940796
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 58 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -50.64597702026367
Eval_StdReturn : 2.9568893909454346
Eval_MaxReturn : -48.123146057128906
Eval_MinReturn : -54.7955207824707
Eval_AverageEpLen : 150.0
Train_AverageReturn : -67.53016662597656
Train_StdReturn : 43.20335006713867
Train_MaxReturn : 57.72620391845703
Train_MinReturn : -180.72976684570312
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1770000
TimeSinceStart : 3510.701755285263
Training Loss : -0.0005407226854003966
Baseline Loss : 0.9497301578521729
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 59 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -73.26556396484375
Eval_StdReturn : 58.26969528198242
Eval_MaxReturn : -0.21842098236083984
Eval_MinReturn : -142.82127380371094
Eval_AverageEpLen : 150.0
Train_AverageReturn : -68.06840515136719
Train_StdReturn : 47.361446380615234
Train_MaxReturn : 68.58769989013672
Train_MinReturn : -196.23280334472656
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1800000
TimeSinceStart : 3569.8840951919556
Training Loss : 0.003496997058391571
Baseline Loss : 0.9314620494842529
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 60 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -89.42391204833984
Eval_StdReturn : 45.46061325073242
Eval_MaxReturn : -25.383235931396484
Eval_MinReturn : -126.35289764404297
Eval_AverageEpLen : 150.0
Train_AverageReturn : -79.33566284179688
Train_StdReturn : 41.421287536621094
Train_MaxReturn : 28.051101684570312
Train_MinReturn : -194.04888916015625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1830000
TimeSinceStart : 3629.7181107997894
Training Loss : -0.005904695484787226
Baseline Loss : 0.9521113634109497
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 61 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -91.63186645507812
Eval_StdReturn : 18.766969680786133
Eval_MaxReturn : -72.30467987060547
Eval_MinReturn : -117.04803466796875
Eval_AverageEpLen : 150.0
Train_AverageReturn : -86.6086196899414
Train_StdReturn : 45.21185302734375
Train_MaxReturn : 40.39177703857422
Train_MinReturn : -208.95001220703125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1860000
TimeSinceStart : 3687.930030107498
Training Loss : -0.017003308981657028
Baseline Loss : 0.9534918665885925
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 62 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -88.81246185302734
Eval_StdReturn : 37.23503112792969
Eval_MaxReturn : -43.60045623779297
Eval_MinReturn : -134.79745483398438
Eval_AverageEpLen : 150.0
Train_AverageReturn : -77.44648742675781
Train_StdReturn : 43.075008392333984
Train_MaxReturn : 32.74393081665039
Train_MinReturn : -191.1207275390625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1890000
TimeSinceStart : 3746.09126329422
Training Loss : -0.02054714597761631
Baseline Loss : 0.9686315059661865
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 63 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -61.29105758666992
Eval_StdReturn : 35.718955993652344
Eval_MaxReturn : -12.174184799194336
Eval_MinReturn : -96.06788635253906
Eval_AverageEpLen : 150.0
Train_AverageReturn : -78.75428771972656
Train_StdReturn : 46.029483795166016
Train_MaxReturn : 113.29356384277344
Train_MinReturn : -205.3807830810547
Train_AverageEpLen : 150.0
Train_MaxReturn : 71.08639526367188
Train_MinReturn : -166.98751831054688
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1680000
TimeSinceStart : 3332.1839299201965
Training Loss : -0.0051292795687913895
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 56 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -36.37343978881836
Eval_StdReturn : 25.483694076538086
Eval_MaxReturn : -0.334325909614563
Eval_MinReturn : -54.51484680175781
Eval_AverageEpLen : 150.0
Train_AverageReturn : -41.52830123901367
Train_StdReturn : 39.6380500793457
Train_MaxReturn : 86.26262664794922
Train_MinReturn : -156.18313598632812
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1710000
TimeSinceStart : 3390.1711206436157
Training Loss : -0.003928124904632568
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 57 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -9.310884475708008
Eval_StdReturn : 7.991909503936768
Eval_MaxReturn : 0.46333980560302734
Eval_MinReturn : -19.112701416015625
Eval_AverageEpLen : 150.0
Train_AverageReturn : -37.89313507080078
Train_StdReturn : 40.12405014038086
Train_MaxReturn : 64.80496215820312
Train_MinReturn : -161.76712036132812
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1740000
TimeSinceStart : 3449.1831591129303
Training Loss : -0.010373099707067013
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 58 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -50.8930549621582
Eval_StdReturn : 8.262703895568848
Eval_MaxReturn : -40.05268859863281
Eval_MinReturn : -60.09123229980469
Eval_AverageEpLen : 150.0
Train_AverageReturn : -27.952098846435547
Train_StdReturn : 33.862823486328125
Train_MaxReturn : 67.69113159179688
Train_MinReturn : -116.01493835449219
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1770000
TimeSinceStart : 3507.2099792957306
Training Loss : -0.01607588864862919
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 59 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -71.32454681396484
Eval_StdReturn : 54.779422760009766
Eval_MaxReturn : -29.604286193847656
Eval_MinReturn : -148.715576171875
Eval_AverageEpLen : 150.0
Train_AverageReturn : -32.353519439697266
Train_StdReturn : 36.83306884765625
Train_MaxReturn : 70.91168212890625
Train_MinReturn : -150.46469116210938
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1800000
TimeSinceStart : 3566.015479326248
Training Loss : -0.00867008138448
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 60 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -57.9302978515625
Eval_StdReturn : 24.7105712890625
Eval_MaxReturn : -26.15822982788086
Eval_MinReturn : -86.4187240600586
Eval_AverageEpLen : 150.0
Train_AverageReturn : -35.48334884643555
Train_StdReturn : 36.954158782958984
Train_MaxReturn : 82.81722259521484
Train_MinReturn : -150.54376220703125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1830000
TimeSinceStart : 3625.9273006916046
Training Loss : -0.0038565918803215027
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 61 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -43.9452018737793
Eval_StdReturn : 19.50029182434082
Eval_MaxReturn : -16.647401809692383
Eval_MinReturn : -60.98746109008789
Eval_AverageEpLen : 150.0
Train_AverageReturn : -43.15829086303711
Train_StdReturn : 31.6637020111084
Train_MaxReturn : 59.05350875854492
Train_MinReturn : -142.60061645507812
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1860000
TimeSinceStart : 3684.411889076233
Training Loss : -0.015531111508607864
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 62 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -35.36509323120117
Eval_StdReturn : 20.68485450744629
Eval_MaxReturn : -6.130281448364258
Eval_MinReturn : -50.870872497558594
Eval_AverageEpLen : 150.0
Train_AverageReturn : -50.157569885253906
Train_StdReturn : 33.16895294189453
Train_MaxReturn : 25.21371078491211
Train_MinReturn : -145.77127075195312
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1890000
TimeSinceStart : 3742.555247783661
Training Loss : -0.006185536738485098
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 63 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -41.89090347290039
Eval_StdReturn : 16.45551300048828
Eval_MaxReturn : -24.584867477416992
Eval_MinReturn : -64.01803588867188
Eval_AverageEpLen : 150.0
Train_AverageReturn : -52.981712341308594
Train_StdReturn : 33.85953903198242
Train_MaxReturn : 40.799049377441406
Train_MinReturn : -197.4893798828125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1920000
TimeSinceStart : 3800.9562788009644
Training Loss : 0.004793497733771801
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 64 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -58.42476272583008
Eval_StdReturn : 20.66749382019043
Eval_MaxReturn : -41.19482421875
Eval_MinReturn : -87.48636627197266
Eval_AverageEpLen : 150.0
Train_AverageReturn : -61.424842834472656
Train_StdReturn : 29.186681747436523
Train_MaxReturn : 14.254262924194336
Train_MinReturn : -163.4060821533203
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1950000
TimeSinceStart : 3859.0068004131317
Training Loss : -0.005000642966479063
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 65 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -80.3737564086914
Eval_StdReturn : 24.268020629882812
Eval_MaxReturn : -47.066551208496094
Eval_MinReturn : -104.1951904296875
Eval_AverageEpLen : 150.0
Train_AverageReturn : -66.85664367675781
Train_StdReturn : 29.219648361206055
Train_MaxReturn : 33.18206024169922
Train_MinReturn : -175.85537719726562
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1980000
TimeSinceStart : 3916.996091604233
Training Loss : -0.0121023990213871
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 66 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -56.3350944519043
Eval_StdReturn : 9.164249420166016
Eval_MaxReturn : -43.47502136230469
Eval_MinReturn : -64.15763092041016
Eval_AverageEpLen : 150.0
Train_AverageReturn : -76.16923522949219
Train_StdReturn : 32.271644592285156
Train_MaxReturn : 26.327062606811523
Train_MinReturn : -182.12008666992188
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2010000
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1680000
TimeSinceStart : 3335.3118228912354
Training Loss : -0.06671658158302307
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 56 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 84.50141143798828
Eval_StdReturn : 17.07207679748535
Eval_MaxReturn : 108.64326477050781
Eval_MinReturn : 72.18183898925781
Eval_AverageEpLen : 150.0
Train_AverageReturn : 69.84307861328125
Train_StdReturn : 13.944656372070312
Train_MaxReturn : 101.56526184082031
Train_MinReturn : 20.10053253173828
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1710000
TimeSinceStart : 3393.390968799591
Training Loss : -0.06592076271772385
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 57 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 77.56888580322266
Eval_StdReturn : 11.524276733398438
Eval_MaxReturn : 89.30160522460938
Eval_MinReturn : 61.90605163574219
Eval_AverageEpLen : 150.0
Train_AverageReturn : 81.56793975830078
Train_StdReturn : 13.228132247924805
Train_MaxReturn : 110.282470703125
Train_MinReturn : 32.29629135131836
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1740000
TimeSinceStart : 3452.5258758068085
Training Loss : -0.06847298890352249
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 58 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 76.16165161132812
Eval_StdReturn : 13.056004524230957
Eval_MaxReturn : 94.00716400146484
Eval_MinReturn : 63.134986877441406
Eval_AverageEpLen : 150.0
Train_AverageReturn : 89.99980163574219
Train_StdReturn : 16.083749771118164
Train_MaxReturn : 124.43580627441406
Train_MinReturn : 32.57701873779297
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1770000
TimeSinceStart : 3510.5214524269104
Training Loss : -0.05764227733016014
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 59 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 83.14067840576172
Eval_StdReturn : 28.399169921875
Eval_MaxReturn : 121.43696594238281
Eval_MinReturn : 53.513267517089844
Eval_AverageEpLen : 150.0
Train_AverageReturn : 84.20267486572266
Train_StdReturn : 23.094715118408203
Train_MaxReturn : 132.04434204101562
Train_MinReturn : 13.344778060913086
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1800000
TimeSinceStart : 3569.8217549324036
Training Loss : -0.07000614702701569
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 60 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 100.96356201171875
Eval_StdReturn : 9.859474182128906
Eval_MaxReturn : 110.23912048339844
Eval_MinReturn : 87.30986022949219
Eval_AverageEpLen : 150.0
Train_AverageReturn : 93.61986541748047
Train_StdReturn : 24.597904205322266
Train_MaxReturn : 143.33607482910156
Train_MinReturn : 3.1261444091796875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1830000
TimeSinceStart : 3629.724585056305
Training Loss : -0.049560509622097015
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 61 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 102.2785873413086
Eval_StdReturn : 8.610471725463867
Eval_MaxReturn : 114.14494323730469
Eval_MinReturn : 93.97843933105469
Eval_AverageEpLen : 150.0
Train_AverageReturn : 102.85414123535156
Train_StdReturn : 22.999547958374023
Train_MaxReturn : 148.0556640625
Train_MinReturn : -20.655132293701172
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1860000
TimeSinceStart : 3687.8610837459564
Training Loss : -0.039739176630973816
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 62 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 91.51180267333984
Eval_StdReturn : 7.19925594329834
Eval_MaxReturn : 97.95235443115234
Eval_MinReturn : 81.46266174316406
Eval_AverageEpLen : 150.0
Train_AverageReturn : 104.16185760498047
Train_StdReturn : 20.04195785522461
Train_MaxReturn : 149.801025390625
Train_MinReturn : 1.622553825378418
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1890000
TimeSinceStart : 3745.947943687439
Training Loss : -0.04465463012456894
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 63 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 107.31243896484375
Eval_StdReturn : 1.1095808744430542
Eval_MaxReturn : 108.40664672851562
Eval_MinReturn : 105.79127502441406
Eval_AverageEpLen : 150.0
Train_AverageReturn : 104.16413879394531
Train_StdReturn : 18.78144073486328
Train_MaxReturn : 137.7941131591797
Train_MinReturn : 17.798633575439453
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1920000
TimeSinceStart : 3804.3862562179565
Training Loss : -0.04132752865552902
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 64 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 130.60855102539062
Eval_StdReturn : 9.32187557220459
Eval_MaxReturn : 142.9139404296875
Eval_MinReturn : 120.35962677001953
Eval_AverageEpLen : 150.0
Train_AverageReturn : 107.77421569824219
Train_StdReturn : 15.934608459472656
Train_MaxReturn : 155.45736694335938
Train_MinReturn : 29.982872009277344
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1950000
TimeSinceStart : 3862.5321424007416
Training Loss : -0.02955184131860733
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 65 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 122.63516235351562
Eval_StdReturn : 10.928004264831543
Eval_MaxReturn : 137.72976684570312
Eval_MinReturn : 112.21617126464844
Eval_AverageEpLen : 150.0
Train_AverageReturn : 113.45092010498047
Train_StdReturn : 22.776676177978516
Train_MaxReturn : 155.08090209960938
Train_MinReturn : 1.9477910995483398
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1980000
TimeSinceStart : 3920.5853979587555
Training Loss : -0.0355573408305645
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 66 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 100.46109008789062
Eval_StdReturn : 22.138290405273438
Eval_MaxReturn : 124.23590850830078
Eval_MinReturn : 70.93212890625
Eval_AverageEpLen : 150.0
Train_AverageReturn : 113.13493347167969
Train_StdReturn : 25.12409210205078
Train_MaxReturn : 175.5216064453125
Train_MinReturn : -5.908150672912598
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2010000
TimeSinceStart : 3978.862146615982
Training Loss : -0.031651388853788376
Initial_DataCollection_AverageReturn : -88.6635513305664


********** Iteration 64 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 157.46340942382812
Eval_StdReturn : 22.79020118713379
Eval_MaxReturn : 173.89553833007812
Eval_MinReturn : 125.23529052734375
Eval_AverageEpLen : 150.0
Train_AverageReturn : 208.1257781982422
Train_StdReturn : 42.5168571472168
Train_MaxReturn : 316.34149169921875
Train_MinReturn : 93.15933227539062
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1950000
TimeSinceStart : 3858.109677553177
Training Loss : -0.019775088876485825
Baseline Loss : 0.7429871559143066
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 65 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 143.76722717285156
Eval_StdReturn : 21.9384765625
Eval_MaxReturn : 174.2479248046875
Eval_MinReturn : 123.51285552978516
Eval_AverageEpLen : 150.0
Train_AverageReturn : 166.40371704101562
Train_StdReturn : 36.01939010620117
Train_MaxReturn : 259.8160095214844
Train_MinReturn : 93.99004364013672
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1980000
TimeSinceStart : 3916.1874487400055
Training Loss : -0.022247087210416794
Baseline Loss : 0.7958536744117737
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 66 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 258.6135559082031
Eval_StdReturn : 22.51327133178711
Eval_MaxReturn : 287.6717529296875
Eval_MinReturn : 232.8155975341797
Eval_AverageEpLen : 150.0
Train_AverageReturn : 178.21347045898438
Train_StdReturn : 34.06159591674805
Train_MaxReturn : 273.6001892089844
Train_MinReturn : 106.43356323242188
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2010000
TimeSinceStart : 3974.440414428711
Training Loss : -0.03121694177389145
Baseline Loss : 0.8162528872489929
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 67 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 251.85743713378906
Eval_StdReturn : 28.409786224365234
Eval_MaxReturn : 284.75750732421875
Eval_MinReturn : 215.43585205078125
Eval_AverageEpLen : 150.0
Train_AverageReturn : 220.96534729003906
Train_StdReturn : 37.198333740234375
Train_MaxReturn : 328.95880126953125
Train_MinReturn : 119.74955749511719
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2040000
TimeSinceStart : 4033.4977850914
Training Loss : -0.01391752902418375
Baseline Loss : 0.7594650387763977
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 68 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 187.4130859375
Eval_StdReturn : 39.37322235107422
Eval_MaxReturn : 233.7281494140625
Eval_MinReturn : 137.48687744140625
Eval_AverageEpLen : 150.0
Train_AverageReturn : 230.4618377685547
Train_StdReturn : 39.67335891723633
Train_MaxReturn : 326.89666748046875
Train_MinReturn : 137.46823120117188
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2070000
TimeSinceStart : 4093.613687515259
Training Loss : -0.01521370094269514
Baseline Loss : 0.7360134720802307
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 69 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 207.3747100830078
Eval_StdReturn : 21.653249740600586
Eval_MaxReturn : 223.81332397460938
Eval_MinReturn : 176.78079223632812
Eval_AverageEpLen : 150.0
Train_AverageReturn : 212.71852111816406
Train_StdReturn : 37.08047866821289
Train_MaxReturn : 300.0662536621094
Train_MinReturn : 114.7437744140625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2100000
TimeSinceStart : 4151.5533101558685
Training Loss : -0.03303339704871178
Baseline Loss : 0.7082982063293457
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 70 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 205.7614288330078
Eval_StdReturn : 21.964614868164062
Eval_MaxReturn : 235.0569305419922
Eval_MinReturn : 182.1696014404297
Eval_AverageEpLen : 150.0
Train_AverageReturn : 214.4051513671875
Train_StdReturn : 37.991024017333984
Train_MaxReturn : 344.24560546875
Train_MinReturn : 107.1457748413086
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2130000
TimeSinceStart : 4209.936820268631
Training Loss : -0.026147859171032906
Baseline Loss : 0.718029260635376
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 71 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 220.9681854248047
Eval_StdReturn : 39.42443084716797
Eval_MaxReturn : 253.70758056640625
Eval_MinReturn : 165.514892578125
Eval_AverageEpLen : 150.0
Train_AverageReturn : 220.9676971435547
Train_StdReturn : 35.89487075805664
Train_MaxReturn : 332.164306640625
Train_MinReturn : 144.61903381347656
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2160000
TimeSinceStart : 4270.966144561768
Training Loss : -0.00776485214009881
Baseline Loss : 0.7321633100509644
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 72 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 202.3556365966797
Eval_StdReturn : 53.92863845825195
Eval_MaxReturn : 262.8725280761719
Eval_MinReturn : 131.90109252929688
Eval_AverageEpLen : 150.0
Train_AverageReturn : 231.6758575439453
Train_StdReturn : 39.277286529541016
Train_MaxReturn : 339.5736999511719
Train_MinReturn : 86.70916748046875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2190000
TimeSinceStart : 4330.444838285446
Training Loss : -0.029287831857800484
Baseline Loss : 0.6776931285858154
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 73 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 217.6038818359375
Eval_StdReturn : 16.99077033996582
Eval_MaxReturn : 239.33404541015625
Eval_MinReturn : 197.85739135742188
Eval_AverageEpLen : 150.0
Train_AverageReturn : 230.96905517578125
Train_StdReturn : 37.77597427368164
Train_MaxReturn : 346.62738037109375
Train_MinReturn : 139.47608947753906
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2220000
TimeSinceStart : 4388.472526788712
Training Loss : -0.002954617841169238
Baseline Loss : 0.6642847061157227
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 74 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 269.7734069824219
Eval_StdReturn : 34.01487731933594
Eval_MaxReturn : 314.3709716796875
Eval_MinReturn : 231.86016845703125
Eval_AverageEpLen : 150.0
Train_AverageReturn : 191.3996124267578
Train_StdReturn : 45.284847259521484
Train_MaxReturn : 299.6996765136719
Train_MinReturn : 74.31297302246094
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2250000
Train_EnvstepsSoFar : 1920000
TimeSinceStart : 3804.70303606987
Training Loss : -0.01764121651649475
Baseline Loss : 0.8809650540351868
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 64 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -72.46562957763672
Eval_StdReturn : 38.04961395263672
Eval_MaxReturn : -35.87544250488281
Eval_MinReturn : -124.9298324584961
Eval_AverageEpLen : 150.0
Train_AverageReturn : -67.70341491699219
Train_StdReturn : 41.66414260864258
Train_MaxReturn : 52.84856033325195
Train_MinReturn : -194.14334106445312
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1950000
TimeSinceStart : 3862.9199397563934
Training Loss : -0.008987141773104668
Baseline Loss : 0.9363742470741272
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 65 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -54.869537353515625
Eval_StdReturn : 35.98356628417969
Eval_MaxReturn : -6.625753402709961
Eval_MinReturn : -93.01386260986328
Eval_AverageEpLen : 150.0
Train_AverageReturn : -54.959720611572266
Train_StdReturn : 42.47377395629883
Train_MaxReturn : 46.66692352294922
Train_MinReturn : -157.53598022460938
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 1980000
TimeSinceStart : 3921.0041551589966
Training Loss : -0.00687935808673501
Baseline Loss : 0.9445222616195679
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 66 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -84.0464096069336
Eval_StdReturn : 62.629920959472656
Eval_MaxReturn : 2.1608848571777344
Eval_MinReturn : -144.7565155029297
Eval_AverageEpLen : 150.0
Train_AverageReturn : -49.65195846557617
Train_StdReturn : 41.604618072509766
Train_MaxReturn : 51.8673095703125
Train_MinReturn : -162.35821533203125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2010000
TimeSinceStart : 3979.3901991844177
Training Loss : -0.00043054402340203524
Baseline Loss : 0.9486941695213318
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 67 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -45.4183235168457
Eval_StdReturn : 24.00381088256836
Eval_MaxReturn : -23.66018295288086
Eval_MinReturn : -78.86312103271484
Eval_AverageEpLen : 150.0
Train_AverageReturn : -36.88527297973633
Train_StdReturn : 47.845088958740234
Train_MaxReturn : 70.89901733398438
Train_MinReturn : -163.46640014648438
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2040000
TimeSinceStart : 4038.9117333889008
Training Loss : -0.018375292420387268
Baseline Loss : 0.9183871150016785
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 68 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -4.752981662750244
Eval_StdReturn : 41.393314361572266
Eval_MaxReturn : 32.2210578918457
Eval_MinReturn : -62.5439453125
Eval_AverageEpLen : 150.0
Train_AverageReturn : -21.4074649810791
Train_StdReturn : 50.29691696166992
Train_MaxReturn : 143.72067260742188
Train_MinReturn : -172.79408264160156
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2070000
TimeSinceStart : 4098.745547771454
Training Loss : -0.002017728751525283
Baseline Loss : 0.8953946828842163
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 69 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -23.283493041992188
Eval_StdReturn : 3.9222164154052734
Eval_MaxReturn : -19.541589736938477
Eval_MinReturn : -28.700469970703125
Eval_AverageEpLen : 150.0
Train_AverageReturn : -22.940031051635742
Train_StdReturn : 54.11111068725586
Train_MaxReturn : 121.99171447753906
Train_MinReturn : -174.51153564453125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2100000
TimeSinceStart : 4156.695122003555
Training Loss : -0.00430002436041832
Baseline Loss : 0.8823806047439575
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 70 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -36.6589469909668
Eval_StdReturn : 80.14667510986328
Eval_MaxReturn : 21.591594696044922
Eval_MinReturn : -149.98867797851562
Eval_AverageEpLen : 150.0
Train_AverageReturn : -26.49557113647461
Train_StdReturn : 55.090538024902344
Train_MaxReturn : 147.0899658203125
Train_MinReturn : -170.7624053955078
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2130000
TimeSinceStart : 4215.6041514873505
Training Loss : -0.012068233452737331
Baseline Loss : 0.8924466371536255
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 71 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 43.81135940551758
Eval_StdReturn : 44.703739166259766
Eval_MaxReturn : 101.27296447753906
Eval_MinReturn : -7.750556945800781
Eval_AverageEpLen : 150.0
Train_AverageReturn : -19.137475967407227
Train_StdReturn : 62.16981506347656
Train_MaxReturn : 118.31779479980469
Train_MinReturn : -189.9106903076172
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2160000
TimeSinceStart : 4276.735055446625
Training Loss : -0.0006761271506547928
Baseline Loss : 0.8696948289871216
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 72 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -55.9234619140625
Eval_StdReturn : 56.47013473510742
Eval_MaxReturn : -14.549308776855469
Eval_MinReturn : -135.7666778564453
Eval_AverageEpLen : 150.0
Train_AverageReturn : -29.327329635620117
Train_StdReturn : 65.35627746582031
Train_MaxReturn : 195.66683959960938
Train_MinReturn : -176.4701385498047
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2190000
TimeSinceStart : 4336.060240030289
Training Loss : -0.008652362041175365
Baseline Loss : 0.8623075485229492
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 73 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -12.20639705657959
Eval_StdReturn : 121.1647720336914
Eval_MaxReturn : 98.66293334960938
Eval_MinReturn : -180.78851318359375
Eval_AverageEpLen : 150.0
Train_AverageReturn : -26.52764129638672
Train_StdReturn : 62.46211624145508
Train_MaxReturn : 136.15914916992188
Train_MinReturn : -207.87158203125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2220000
TimeSinceStart : 4394.045692443848
Training Loss : -0.016421444714069366
Baseline Loss : 0.8492055535316467
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 74 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -88.87126922607422
Eval_StdReturn : 22.005605697631836
Eval_MaxReturn : -64.57627868652344
TimeSinceStart : 3975.205614089966
Training Loss : 0.006592500954866409
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 67 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -106.11285400390625
Eval_StdReturn : 16.771896362304688
Eval_MaxReturn : -86.46522521972656
Eval_MinReturn : -127.44417572021484
Eval_AverageEpLen : 150.0
Train_AverageReturn : -84.25503540039062
Train_StdReturn : 32.75712585449219
Train_MaxReturn : 23.853858947753906
Train_MinReturn : -166.98373413085938
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2040000
TimeSinceStart : 4034.1769802570343
Training Loss : -0.020485762506723404
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 68 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -75.29668426513672
Eval_StdReturn : 15.380549430847168
Eval_MaxReturn : -53.56309509277344
Eval_MinReturn : -86.92528533935547
Eval_AverageEpLen : 150.0
Train_AverageReturn : -93.6808090209961
Train_StdReturn : 32.88145065307617
Train_MaxReturn : 26.891555786132812
Train_MinReturn : -208.96755981445312
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2070000
TimeSinceStart : 4094.264815568924
Training Loss : 0.003117112210020423
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 69 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -101.75616455078125
Eval_StdReturn : 5.800082206726074
Eval_MaxReturn : -96.30256652832031
Eval_MinReturn : -109.78910827636719
Eval_AverageEpLen : 150.0
Train_AverageReturn : -96.67729187011719
Train_StdReturn : 31.74332046508789
Train_MaxReturn : 11.736572265625
Train_MinReturn : -168.68252563476562
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2100000
TimeSinceStart : 4152.223711490631
Training Loss : -4.300537329982035e-05
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 70 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -96.2200927734375
Eval_StdReturn : 23.5548095703125
Eval_MaxReturn : -63.29167556762695
Eval_MinReturn : -117.04701232910156
Eval_AverageEpLen : 150.0
Train_AverageReturn : -97.70199584960938
Train_StdReturn : 27.619529724121094
Train_MaxReturn : -2.4427413940429688
Train_MinReturn : -156.98367309570312
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2130000
TimeSinceStart : 4210.617206335068
Training Loss : -0.011988227255642414
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 71 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -73.04794311523438
Eval_StdReturn : 19.093820571899414
Eval_MaxReturn : -46.04582214355469
Eval_MinReturn : -86.70719909667969
Eval_AverageEpLen : 150.0
Train_AverageReturn : -96.15765380859375
Train_StdReturn : 23.63785171508789
Train_MaxReturn : -2.060957908630371
Train_MinReturn : -162.946533203125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2160000
TimeSinceStart : 4271.617776632309
Training Loss : 0.00174904172308743
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 72 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -67.51605224609375
Eval_StdReturn : 19.932065963745117
Eval_MaxReturn : -43.09148406982422
Eval_MinReturn : -91.91485595703125
Eval_AverageEpLen : 150.0
Train_AverageReturn : -87.96296691894531
Train_StdReturn : 19.761737823486328
Train_MaxReturn : -35.98558044433594
Train_MinReturn : -164.97332763671875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2190000
TimeSinceStart : 4331.11723780632
Training Loss : -0.004215128719806671
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 73 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -64.45055389404297
Eval_StdReturn : 25.507118225097656
Eval_MaxReturn : -28.565950393676758
Eval_MinReturn : -85.57733917236328
Eval_AverageEpLen : 150.0
Train_AverageReturn : -78.51284790039062
Train_StdReturn : 20.44270133972168
Train_MaxReturn : 20.451454162597656
Train_MinReturn : -125.09747314453125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2220000
TimeSinceStart : 4389.092101097107
Training Loss : -0.0004892496508546174
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 74 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -52.03718948364258
Eval_StdReturn : 10.112781524658203
Eval_MaxReturn : -39.18206024169922
Eval_MinReturn : -63.89262008666992
Eval_AverageEpLen : 150.0
Train_AverageReturn : -67.98944091796875
Train_StdReturn : 18.335678100585938
Train_MaxReturn : -14.422009468078613
Train_MinReturn : -141.305419921875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2250000
TimeSinceStart : 4447.081465244293
Training Loss : -0.017019441351294518
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 75 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -57.8200798034668
Eval_StdReturn : 46.02394104003906
Eval_MaxReturn : 4.870588302612305
Eval_MinReturn : -104.32176208496094
Eval_AverageEpLen : 150.0
Train_AverageReturn : -58.02460861206055
Train_StdReturn : 19.336936950683594
Train_MaxReturn : 2.5281944274902344
Train_MinReturn : -118.83049774169922
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2280000
TimeSinceStart : 4505.407593250275
Training Loss : -0.006109397858381271
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 76 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -60.83713150024414
Eval_StdReturn : 18.633974075317383
Eval_MaxReturn : -38.4886589050293
Eval_MinReturn : -84.10462188720703
Eval_AverageEpLen : 150.0
Train_AverageReturn : -55.50456619262695
Train_StdReturn : 17.19429588317871
Train_MaxReturn : 5.334957122802734
Train_MinReturn : -102.45095825195312
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2310000
TimeSinceStart : 4564.115188837051
Training Loss : -0.008763006888329983
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 77 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -40.446834564208984
Eval_StdReturn : 8.862076759338379
Eval_MaxReturn : -32.92763900756836
Eval_MinReturn : -52.88979721069336
Eval_AverageEpLen : 150.0
Train_AverageReturn : -53.00425338745117
Train_StdReturn : 21.909345626831055
Train_MaxReturn : 20.60686683654785
Train_MinReturn : -136.16839599609375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2340000
TimeSinceStart : 4622.343699216843
Training Loss : -0.008221804164350033
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 67 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 118.09708404541016
Eval_StdReturn : 14.273406982421875
Eval_MaxReturn : 134.9119873046875
Eval_MinReturn : 100.01805114746094
Eval_AverageEpLen : 150.0
Train_AverageReturn : 114.40133666992188
Train_StdReturn : 22.690000534057617
Train_MaxReturn : 161.5634002685547
Train_MinReturn : 4.323038101196289
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2040000
TimeSinceStart : 4038.1885755062103
Training Loss : -0.02084709145128727
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 68 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 109.71521759033203
Eval_StdReturn : 19.468250274658203
Eval_MaxReturn : 136.32064819335938
Eval_MinReturn : 90.27796936035156
Eval_AverageEpLen : 150.0
Train_AverageReturn : 114.81947326660156
Train_StdReturn : 22.729053497314453
Train_MaxReturn : 165.97222900390625
Train_MinReturn : 39.58888626098633
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2070000
TimeSinceStart : 4097.886709690094
Training Loss : -0.02356131002306938
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 69 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 112.30010986328125
Eval_StdReturn : 14.117870330810547
Eval_MaxReturn : 132.2642822265625
Eval_MinReturn : 102.10568237304688
Eval_AverageEpLen : 150.0
Train_AverageReturn : 103.98162841796875
Train_StdReturn : 21.7443790435791
Train_MaxReturn : 148.73388671875
Train_MinReturn : 32.013397216796875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2100000
TimeSinceStart : 4155.826909065247
Training Loss : -0.023590760305523872
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 70 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 114.55038452148438
Eval_StdReturn : 4.577126502990723
Eval_MaxReturn : 120.96224975585938
Eval_MinReturn : 110.57560729980469
Eval_AverageEpLen : 150.0
Train_AverageReturn : 116.619873046875
Train_StdReturn : 14.45826244354248
Train_MaxReturn : 153.55368041992188
Train_MinReturn : 67.50458526611328
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2130000
TimeSinceStart : 4214.683413267136
Training Loss : -0.040532294660806656
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 71 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 130.10791015625
Eval_StdReturn : 6.000890254974365
Eval_MaxReturn : 137.18914794921875
Eval_MinReturn : 122.5166015625
Eval_AverageEpLen : 150.0
Train_AverageReturn : 113.59176635742188
Train_StdReturn : 16.20554542541504
Train_MaxReturn : 143.06997680664062
Train_MinReturn : 13.417728424072266
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2160000
TimeSinceStart : 4275.793167114258
Training Loss : -0.03707185015082359
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 72 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 110.874267578125
Eval_StdReturn : 11.60933780670166
Eval_MaxReturn : 120.01455688476562
Eval_MinReturn : 94.49284362792969
Eval_AverageEpLen : 150.0
Train_AverageReturn : 117.93836975097656
Train_StdReturn : 17.29911231994629
Train_MaxReturn : 161.0021514892578
Train_MinReturn : 7.939607620239258
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2190000
TimeSinceStart : 4335.264339923859
Training Loss : -0.02576521784067154
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 73 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 93.04583740234375
Eval_StdReturn : 7.174567222595215
Eval_MaxReturn : 100.0876235961914
Eval_MinReturn : 83.19868469238281
Eval_AverageEpLen : 150.0
Train_AverageReturn : 121.53446960449219
Train_StdReturn : 18.890399932861328
Train_MaxReturn : 162.24420166015625
Train_MinReturn : 29.983238220214844
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2220000
TimeSinceStart : 4393.287868499756
Training Loss : -0.03471831977367401
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 74 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 114.5494384765625
Eval_StdReturn : 1.5313738584518433
Eval_MaxReturn : 116.7010269165039
Eval_MinReturn : 113.25996398925781
Eval_AverageEpLen : 150.0
Train_AverageReturn : 107.17791748046875
Train_StdReturn : 25.62631607055664
Train_MaxReturn : 159.87124633789062
Train_MinReturn : -33.99918746948242
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2250000
TimeSinceStart : 4451.6616015434265
Training Loss : -0.020394116640090942
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 75 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 127.34393310546875
Eval_StdReturn : 0.7678029537200928
Eval_MaxReturn : 128.3404541015625
Eval_MinReturn : 126.4721908569336
Eval_AverageEpLen : 150.0
Train_AverageReturn : 110.34529113769531
Train_StdReturn : 27.4762020111084
Train_MaxReturn : 160.56845092773438
Train_MinReturn : -34.44276428222656
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2280000
TimeSinceStart : 4509.736905813217
Training Loss : -0.02705361880362034
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 76 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 117.2248306274414
Eval_StdReturn : 21.25537872314453
Eval_MaxReturn : 146.55490112304688
Eval_MinReturn : 96.85917663574219
Eval_AverageEpLen : 150.0
Train_AverageReturn : 114.1561050415039
Train_StdReturn : 21.85016632080078
Train_MaxReturn : 154.63238525390625
Train_MinReturn : 39.9964714050293
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2310000
TimeSinceStart : 4568.451204299927
Training Loss : -0.03516576066613197
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 77 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 103.05290985107422
Eval_StdReturn : 13.3372220993042
Eval_MaxReturn : 121.73623657226562
Eval_MinReturn : 91.47023010253906
Eval_AverageEpLen : 150.0
Train_AverageReturn : 107.54183959960938
Train_StdReturn : 19.592449188232422
Train_MaxReturn : 141.22752380371094
Train_MinReturn : 33.659629821777344
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2340000
TimeSinceStart : 4626.545519828796
Training Loss : -0.043841585516929626
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 78 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...
TimeSinceStart : 4446.412368059158
Training Loss : -0.020515356212854385
Baseline Loss : 0.6767499446868896
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 75 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 298.86181640625
Eval_StdReturn : 24.565616607666016
Eval_MaxReturn : 333.0324401855469
Eval_MinReturn : 276.3468933105469
Eval_AverageEpLen : 150.0
Train_AverageReturn : 248.4317169189453
Train_StdReturn : 40.655452728271484
Train_MaxReturn : 346.6290283203125
Train_MinReturn : 114.64576721191406
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2280000
TimeSinceStart : 4504.835328578949
Training Loss : -0.040716104209423065
Baseline Loss : 0.7011160254478455
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 76 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 252.8478240966797
Eval_StdReturn : 26.698301315307617
Eval_MaxReturn : 282.5715026855469
Eval_MinReturn : 217.82225036621094
Eval_AverageEpLen : 150.0
Train_AverageReturn : 256.737548828125
Train_StdReturn : 38.67716979980469
Train_MaxReturn : 358.1484375
Train_MinReturn : 152.29913330078125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2310000
TimeSinceStart : 4563.46772813797
Training Loss : -0.02189711481332779
Baseline Loss : 0.7158689498901367
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 77 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 168.68568420410156
Eval_StdReturn : 33.76097869873047
Eval_MaxReturn : 205.91468811035156
Eval_MinReturn : 124.18284606933594
Eval_AverageEpLen : 150.0
Train_AverageReturn : 220.87869262695312
Train_StdReturn : 44.66468811035156
Train_MaxReturn : 321.30718994140625
Train_MinReturn : 91.60997772216797
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2340000
TimeSinceStart : 4621.662401437759
Training Loss : -0.028313549235463142
Baseline Loss : 0.6835789680480957
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 78 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 217.1007537841797
Eval_StdReturn : 36.15149688720703
Eval_MaxReturn : 267.97064208984375
Eval_MinReturn : 187.2401123046875
Eval_AverageEpLen : 150.0
Train_AverageReturn : 187.85791015625
Train_StdReturn : 42.315223693847656
Train_MaxReturn : 296.8319396972656
Train_MinReturn : 73.48956298828125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2370000
TimeSinceStart : 4680.425850868225
Training Loss : -0.03280116990208626
Baseline Loss : 0.7151392102241516
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 79 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 273.9295959472656
Eval_StdReturn : 25.643505096435547
Eval_MaxReturn : 307.4866943359375
Eval_MinReturn : 245.2420196533203
Eval_AverageEpLen : 150.0
Train_AverageReturn : 204.6923370361328
Train_StdReturn : 40.679378509521484
Train_MaxReturn : 351.34722900390625
Train_MinReturn : 111.71725463867188
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2400000
TimeSinceStart : 4739.114604949951
Training Loss : -0.028141861781477928
Baseline Loss : 0.6577728390693665
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 80 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 218.0471954345703
Eval_StdReturn : 16.421024322509766
Eval_MaxReturn : 233.9254150390625
Eval_MinReturn : 195.43203735351562
Eval_AverageEpLen : 150.0
Train_AverageReturn : 250.05996704101562
Train_StdReturn : 40.656341552734375
Train_MaxReturn : 337.3004150390625
Train_MinReturn : 154.64797973632812
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2430000
TimeSinceStart : 4800.289078474045
Training Loss : -0.004693883471190929
Baseline Loss : 0.6931638717651367
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 81 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 188.3954620361328
Eval_StdReturn : 51.499290466308594
Eval_MaxReturn : 259.5812072753906
Eval_MinReturn : 139.4718475341797
Eval_AverageEpLen : 150.0
Train_AverageReturn : 213.38174438476562
Train_StdReturn : 52.89958190917969
Train_MaxReturn : 345.2647705078125
Train_MinReturn : 71.74740600585938
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2460000
TimeSinceStart : 4859.972202301025
Training Loss : -0.01396569050848484
Baseline Loss : 0.5889435410499573
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 82 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 307.4839782714844
Eval_StdReturn : 52.5927848815918
Eval_MaxReturn : 371.4686279296875
Eval_MinReturn : 242.65150451660156
Eval_AverageEpLen : 150.0
Train_AverageReturn : 227.0127410888672
Train_StdReturn : 54.98100662231445
Train_MaxReturn : 384.46197509765625
Train_MinReturn : 98.83255004882812
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2490000
TimeSinceStart : 4919.020354747772
Training Loss : -0.017913391813635826
Baseline Loss : 0.5812868475914001
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 83 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 283.15570068359375
Eval_StdReturn : 74.78206634521484
Eval_MaxReturn : 385.88287353515625
Eval_MinReturn : 210.0232696533203
Eval_AverageEpLen : 150.0
Train_AverageReturn : 304.3517761230469
Train_StdReturn : 55.05704116821289
Train_MaxReturn : 438.1181335449219
Train_MinReturn : 121.706298828125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2520000
TimeSinceStart : 4977.936237812042
Training Loss : -0.02486947365105152
Baseline Loss : 0.8211212754249573
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 84 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 347.0655517578125
Eval_StdReturn : 22.15818214416504
Eval_MaxReturn : 375.29547119140625
Eval_MinReturn : 321.1700439453125
Eval_AverageEpLen : 150.0
Train_AverageReturn : 323.3069152832031
Train_StdReturn : 47.40437698364258
Train_MaxReturn : 485.9563293457031
Train_MinReturn : 200.25759887695312
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2550000
TimeSinceStart : 5037.951514720917
Training Loss : -0.0037588044069707394
Baseline Loss : 0.8362096548080444
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 85 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 317.0676574707031
Eval_StdReturn : 57.38512420654297
Eval_MaxReturn : 393.598388671875
Eval_MinReturn : 255.41714477539062
Eval_AverageEpLen : 150.0
Eval_MinReturn : -117.8617172241211
Eval_AverageEpLen : 150.0
Train_AverageReturn : -37.66740798950195
Train_StdReturn : 59.64924240112305
Train_MaxReturn : 92.19112396240234
Train_MinReturn : -188.6064453125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2250000
TimeSinceStart : 4452.475539922714
Training Loss : -0.008920426480472088
Baseline Loss : 0.9904600381851196
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 75 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -70.8960952758789
Eval_StdReturn : 51.892486572265625
Eval_MaxReturn : -9.79541301727295
Eval_MinReturn : -136.6497802734375
Eval_AverageEpLen : 150.0
Train_AverageReturn : -30.1133975982666
Train_StdReturn : 60.120853424072266
Train_MaxReturn : 134.02725219726562
Train_MinReturn : -182.98448181152344
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2280000
TimeSinceStart : 4510.599361896515
Training Loss : -0.0034210693556815386
Baseline Loss : 0.9188456535339355
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 76 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -48.48750305175781
Eval_StdReturn : 53.16297149658203
Eval_MaxReturn : 1.2161610126495361
Eval_MinReturn : -122.19229125976562
Eval_AverageEpLen : 150.0
Train_AverageReturn : -34.792667388916016
Train_StdReturn : 60.11714553833008
Train_MaxReturn : 92.54936981201172
Train_MinReturn : -180.1409149169922
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2310000
TimeSinceStart : 4569.476355314255
Training Loss : -0.021482137963175774
Baseline Loss : 0.9407164454460144
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 77 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -7.8000922203063965
Eval_StdReturn : 19.409774780273438
Eval_MaxReturn : 19.508506774902344
Eval_MinReturn : -23.860498428344727
Eval_AverageEpLen : 150.0
Train_AverageReturn : -43.2396354675293
Train_StdReturn : 70.95258331298828
Train_MaxReturn : 108.33364868164062
Train_MinReturn : -266.53485107421875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2340000
TimeSinceStart : 4627.681386470795
Training Loss : 0.00892584677785635
Baseline Loss : 0.8703757524490356
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 78 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -25.668912887573242
Eval_StdReturn : 1.9966970682144165
Eval_MaxReturn : -22.855398178100586
Eval_MinReturn : -27.283767700195312
Eval_AverageEpLen : 150.0
Train_AverageReturn : -37.89449691772461
Train_StdReturn : 57.11565017700195
Train_MaxReturn : 100.06416320800781
Train_MinReturn : -205.56378173828125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2370000
TimeSinceStart : 4686.480518102646
Training Loss : -0.010881771333515644
Baseline Loss : 0.8933213353157043
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 79 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -10.533493041992188
Eval_StdReturn : 45.24807357788086
Eval_MaxReturn : 45.24483108520508
Eval_MinReturn : -65.58267211914062
Eval_AverageEpLen : 150.0
Train_AverageReturn : -48.023067474365234
Train_StdReturn : 63.864906311035156
Train_MaxReturn : 88.46763610839844
Train_MinReturn : -245.44122314453125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2400000
TimeSinceStart : 4745.638030290604
Training Loss : 0.0021205139346420765
Baseline Loss : 0.9092757701873779
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 80 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -50.27714157104492
Eval_StdReturn : 36.06833267211914
Eval_MaxReturn : -0.27905476093292236
Eval_MinReturn : -84.02435302734375
Eval_AverageEpLen : 150.0
Train_AverageReturn : -55.69371032714844
Train_StdReturn : 60.54380416870117
Train_MaxReturn : 91.90206909179688
Train_MinReturn : -231.06761169433594
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2430000
TimeSinceStart : 4806.925073623657
Training Loss : -0.014109362848103046
Baseline Loss : 0.9284121990203857
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 81 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -54.46549987792969
Eval_StdReturn : 32.3477897644043
Eval_MaxReturn : -8.762863159179688
Eval_MinReturn : -79.05489349365234
Eval_AverageEpLen : 150.0
Train_AverageReturn : -52.041709899902344
Train_StdReturn : 57.31827926635742
Train_MaxReturn : 113.20972442626953
Train_MinReturn : -217.6224365234375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2460000
TimeSinceStart : 4866.198526620865
Training Loss : -0.006577512715011835
Baseline Loss : 0.9095548391342163
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 82 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -36.4256706237793
Eval_StdReturn : 47.95339584350586
Eval_MaxReturn : 7.096336364746094
Eval_MinReturn : -103.2274169921875
Eval_AverageEpLen : 150.0
Train_AverageReturn : -71.6213607788086
Train_StdReturn : 65.91947937011719
Train_MaxReturn : 74.64122772216797
Train_MinReturn : -266.6605529785156
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2490000
TimeSinceStart : 4925.19389629364
Training Loss : -0.0033251913264393806
Baseline Loss : 0.8675275444984436
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 83 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -18.133056640625
Eval_StdReturn : 34.47798156738281
Eval_MaxReturn : 29.454011917114258
Eval_MinReturn : -51.12987518310547
Eval_AverageEpLen : 150.0
Train_AverageReturn : -63.33693313598633
Train_StdReturn : 60.41741180419922
Train_MaxReturn : 72.76127624511719
Train_MinReturn : -246.31915283203125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2520000
TimeSinceStart : 4984.817793607712
Training Loss : -0.001387064578011632
Baseline Loss : 0.9332068562507629
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 84 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -37.5620002746582
Eval_StdReturn : 24.009990692138672
Eval_MaxReturn : -14.705081939697266
Eval_MinReturn : -70.73650360107422
Eval_AverageEpLen : 150.0
Train_AverageReturn : -61.41006851196289
Train_StdReturn : 61.462398529052734
Train_MaxReturn : 90.19474792480469
Train_MinReturn : -269.08599853515625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2550000
TimeSinceStart : 5044.6353669166565
Training Loss : -0.00688771391287446
Baseline Loss : 0.8990079760551453
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 85 ************

Collecting data to be used for training...
Done logging...




********** Iteration 78 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -51.333126068115234
Eval_StdReturn : 20.638174057006836
Eval_MaxReturn : -22.26127052307129
Eval_MinReturn : -68.1100082397461
Eval_AverageEpLen : 150.0
Train_AverageReturn : -52.554527282714844
Train_StdReturn : 25.01054573059082
Train_MaxReturn : 11.428496360778809
Train_MinReturn : -145.56753540039062
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2370000
TimeSinceStart : 4681.007961511612
Training Loss : -0.004005786031484604
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 79 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -35.74669647216797
Eval_StdReturn : 35.10382843017578
Eval_MaxReturn : 7.3937530517578125
Eval_MinReturn : -78.5911865234375
Eval_AverageEpLen : 150.0
Train_AverageReturn : -58.60564422607422
Train_StdReturn : 27.44872283935547
Train_MaxReturn : 9.655601501464844
Train_MinReturn : -163.115234375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2400000
TimeSinceStart : 4739.612994670868
Training Loss : -0.002270349068567157
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 80 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -95.1474380493164
Eval_StdReturn : 20.33799934387207
Eval_MaxReturn : -66.76589965820312
Eval_MinReturn : -113.37769317626953
Eval_AverageEpLen : 150.0
Train_AverageReturn : -72.7224349975586
Train_StdReturn : 27.11577606201172
Train_MaxReturn : -3.0125021934509277
Train_MinReturn : -157.50894165039062
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2430000
TimeSinceStart : 4801.020924329758
Training Loss : 0.0027300699148327112
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 81 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -52.896854400634766
Eval_StdReturn : 13.727118492126465
Eval_MaxReturn : -33.48685073852539
Eval_MinReturn : -62.90103530883789
Eval_AverageEpLen : 150.0
Train_AverageReturn : -74.01280212402344
Train_StdReturn : 25.80250358581543
Train_MaxReturn : -11.269559860229492
Train_MinReturn : -155.14334106445312
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2460000
TimeSinceStart : 4860.846130371094
Training Loss : 0.0064571634866297245
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 82 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -108.3945083618164
Eval_StdReturn : 37.89241409301758
Eval_MaxReturn : -81.38453674316406
Eval_MinReturn : -161.9818878173828
Eval_AverageEpLen : 150.0
Train_AverageReturn : -80.57592010498047
Train_StdReturn : 32.38645553588867
Train_MaxReturn : 20.673297882080078
Train_MinReturn : -193.7733154296875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2490000
TimeSinceStart : 4919.934875965118
Training Loss : -0.020791446790099144
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 83 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -92.37216186523438
Eval_StdReturn : 27.154407501220703
Eval_MaxReturn : -53.983070373535156
Eval_MinReturn : -112.433349609375
Eval_AverageEpLen : 150.0
Train_AverageReturn : -86.58094787597656
Train_StdReturn : 33.0217170715332
Train_MaxReturn : 17.71312713623047
Train_MinReturn : -210.2663116455078
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2520000
TimeSinceStart : 4978.87189745903
Training Loss : -0.014476144686341286
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 84 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -109.7236557006836
Eval_StdReturn : 61.92420196533203
Eval_MaxReturn : -22.18824577331543
Eval_MinReturn : -155.74392700195312
Eval_AverageEpLen : 150.0
Train_AverageReturn : -88.42047882080078
Train_StdReturn : 31.91326904296875
Train_MaxReturn : 5.822667598724365
Train_MinReturn : -205.6888427734375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2550000
TimeSinceStart : 5038.900768518448
Training Loss : -0.007946732454001904
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 85 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -101.00940704345703
Eval_StdReturn : 13.280278205871582
Eval_MaxReturn : -84.3164291381836
Eval_MinReturn : -116.80955505371094
Eval_AverageEpLen : 150.0
Train_AverageReturn : -90.42406463623047
Train_StdReturn : 34.652610778808594
Train_MaxReturn : 36.779537200927734
Train_MinReturn : -187.36508178710938
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2580000
TimeSinceStart : 5098.439179182053
Training Loss : -0.006241050083190203
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 86 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -71.92505645751953
Eval_StdReturn : 20.527204513549805
Eval_MaxReturn : -44.46578598022461
Eval_MinReturn : -93.81193542480469
Eval_AverageEpLen : 150.0
Train_AverageReturn : -94.15509796142578
Train_StdReturn : 30.71957778930664
Train_MaxReturn : -4.5491943359375
Train_MinReturn : -236.80575561523438
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2610000
TimeSinceStart : 5159.906459093094
Training Loss : -0.004980314057320356
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 87 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -78.53079986572266
Eval_StdReturn : 9.685826301574707
Eval_MaxReturn : -65.90660095214844
Eval_MinReturn : -89.44670867919922
Eval_AverageEpLen : 150.0
Train_AverageReturn : -91.5240249633789
Train_StdReturn : 28.65879249572754
Train_MaxReturn : 48.02070617675781
Train_MinReturn : -195.75930786132812
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2640000
TimeSinceStart : 5221.588612318039
Training Loss : -0.008026708848774433
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 88 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -119.57563018798828
Eval_StdReturn : 16.315608978271484
Eval_MaxReturn : -96.5353012084961
Eval_MinReturn : -132.1709747314453
Eval_AverageEpLen : 150.0
Train_AverageReturn : -88.2939224243164
Train_StdReturn : 27.14434242248535
Train_MaxReturn : 59.33979415893555
Train_MinReturn : -167.32501220703125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2670000
TimeSinceStart : 5284.520797967911
Training Loss : -0.008319521322846413
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 89 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Collecting data for eval...
Eval_AverageReturn : 78.87828826904297
Eval_StdReturn : 45.48141860961914
Eval_MaxReturn : 116.07454681396484
Eval_MinReturn : 14.836042404174805
Eval_AverageEpLen : 150.0
Train_AverageReturn : 106.50723266601562
Train_StdReturn : 24.740924835205078
Train_MaxReturn : 151.31735229492188
Train_MinReturn : 0.8356533050537109
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2370000
TimeSinceStart : 4685.154287338257
Training Loss : -0.016501985490322113
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 79 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 140.7740936279297
Eval_StdReturn : 1.9696282148361206
Eval_MaxReturn : 142.94590759277344
Eval_MinReturn : 138.17770385742188
Eval_AverageEpLen : 150.0
Train_AverageReturn : 119.56437683105469
Train_StdReturn : 21.784683227539062
Train_MaxReturn : 160.34373474121094
Train_MinReturn : 40.16837692260742
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2400000
TimeSinceStart : 4744.23970246315
Training Loss : -0.037399034947156906
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 80 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 122.20706939697266
Eval_StdReturn : 12.484898567199707
Eval_MaxReturn : 132.33741760253906
Eval_MinReturn : 104.61827850341797
Eval_AverageEpLen : 150.0
Train_AverageReturn : 127.5039291381836
Train_StdReturn : 22.88772201538086
Train_MaxReturn : 168.90780639648438
Train_MinReturn : 22.620677947998047
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2430000
TimeSinceStart : 4805.4522387981415
Training Loss : -0.029469938948750496
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 81 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 110.4747314453125
Eval_StdReturn : 15.79466724395752
Eval_MaxReturn : 131.79913330078125
Eval_MinReturn : 94.05409240722656
Eval_AverageEpLen : 150.0
Train_AverageReturn : 108.71724700927734
Train_StdReturn : 42.72501754760742
Train_MaxReturn : 180.1956024169922
Train_MinReturn : -7.980542182922363
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2460000
TimeSinceStart : 4864.779502153397
Training Loss : -0.001910460996441543
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 82 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 138.8785858154297
Eval_StdReturn : 11.601062774658203
Eval_MaxReturn : 155.21829223632812
Eval_MinReturn : 129.42921447753906
Eval_AverageEpLen : 150.0
Train_AverageReturn : 101.85366821289062
Train_StdReturn : 37.976402282714844
Train_MaxReturn : 171.57269287109375
Train_MinReturn : -12.384621620178223
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2490000
TimeSinceStart : 4923.79932808876
Training Loss : -0.0014447232242673635
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 83 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 107.56449127197266
Eval_StdReturn : 28.73949432373047
Eval_MaxReturn : 142.19317626953125
Eval_MinReturn : 71.82249450683594
Eval_AverageEpLen : 150.0
Train_AverageReturn : 118.25470733642578
Train_StdReturn : 28.164796829223633
Train_MaxReturn : 176.38243103027344
Train_MinReturn : -0.21601295471191406
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2520000
TimeSinceStart : 4983.215198516846
Training Loss : -0.011913450434803963
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 84 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 101.3713150024414
Eval_StdReturn : 19.814443588256836
Eval_MaxReturn : 129.32090759277344
Eval_MinReturn : 85.65479278564453
Eval_AverageEpLen : 150.0
Train_AverageReturn : 99.7413101196289
Train_StdReturn : 30.33820343017578
Train_MaxReturn : 171.34527587890625
Train_MinReturn : -19.62317657470703
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2550000
TimeSinceStart : 5042.728277206421
Training Loss : -0.033945538103580475
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 85 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 122.14879608154297
Eval_StdReturn : 27.073949813842773
Eval_MaxReturn : 141.9343719482422
Eval_MinReturn : 83.86769104003906
Eval_AverageEpLen : 150.0
Train_AverageReturn : 101.57781982421875
Train_StdReturn : 29.87706184387207
Train_MaxReturn : 162.65902709960938
Train_MinReturn : -21.88359260559082
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2580000
TimeSinceStart : 5102.226507902145
Training Loss : -0.02730376273393631
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 86 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 125.38851165771484
Eval_StdReturn : 7.498549938201904
Eval_MaxReturn : 133.56434631347656
Eval_MinReturn : 115.45173645019531
Eval_AverageEpLen : 150.0
Train_AverageReturn : 114.46460723876953
Train_StdReturn : 27.539278030395508
Train_MaxReturn : 157.07301330566406
Train_MinReturn : -13.287656784057617
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2610000
TimeSinceStart : 5163.628145456314
Training Loss : -0.01917814463376999
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 87 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 125.20550537109375
Eval_StdReturn : 13.587403297424316
Eval_MaxReturn : 136.7277069091797
Eval_MinReturn : 106.12691497802734
Eval_AverageEpLen : 150.0
Train_AverageReturn : 124.06820678710938
Train_StdReturn : 24.187040328979492
Train_MaxReturn : 162.83157348632812
Train_MinReturn : -12.973367691040039
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2640000
TimeSinceStart : 5225.815082788467
Training Loss : -0.03704891726374626
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 88 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 109.92476654052734
Eval_StdReturn : 9.208465576171875
Eval_MaxReturn : 117.99529266357422
Eval_MinReturn : 97.0383071899414
Eval_AverageEpLen : 150.0
Train_AverageReturn : 126.06890869140625
Train_StdReturn : 27.920867919921875
Train_MaxReturn : 178.59152221679688
Train_MinReturn : -11.935964584350586
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2670000
TimeSinceStart : 5289.0903832912445
Training Loss : -0.02254328690469265
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 89 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 111.2222671508789
Eval_StdReturn : 3.55658221244812
Eval_MaxReturn : 115.96473693847656

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -77.47808074951172
Eval_StdReturn : 13.945816993713379
Eval_MaxReturn : -67.20673370361328
Eval_MinReturn : -97.19467163085938
Eval_AverageEpLen : 150.0
Train_AverageReturn : -66.65026092529297
Train_StdReturn : 57.94878005981445
Train_MaxReturn : 87.0220947265625
Train_MinReturn : -250.84677124023438
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2580000
TimeSinceStart : 5104.564950227737
Training Loss : -0.0026939036324620247
Baseline Loss : 0.9394358396530151
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 86 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -28.22296905517578
Eval_StdReturn : 28.766334533691406
Eval_MaxReturn : 3.1634037494659424
Eval_MinReturn : -66.33098602294922
Eval_AverageEpLen : 150.0
Train_AverageReturn : -59.79624557495117
Train_StdReturn : 57.99955749511719
Train_MaxReturn : 57.29199981689453
Train_MinReturn : -213.86929321289062
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2610000
TimeSinceStart : 5166.0436408519745
Training Loss : -0.008656094782054424
Baseline Loss : 0.9254054427146912
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 87 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -85.59041595458984
Eval_StdReturn : 34.387916564941406
Eval_MaxReturn : -51.81378173828125
Eval_MinReturn : -132.77967834472656
Eval_AverageEpLen : 150.0
Train_AverageReturn : -52.993614196777344
Train_StdReturn : 49.17369842529297
Train_MaxReturn : 52.44913101196289
Train_MinReturn : -234.46392822265625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2640000
TimeSinceStart : 5228.879180908203
Training Loss : 0.0033759113866835833
Baseline Loss : 0.9332740306854248
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 88 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -95.75811767578125
Eval_StdReturn : 18.387346267700195
Eval_MaxReturn : -82.49261474609375
Eval_MinReturn : -121.75996398925781
Eval_AverageEpLen : 150.0
Train_AverageReturn : -57.13648986816406
Train_StdReturn : 41.92263412475586
Train_MaxReturn : 49.8942756652832
Train_MinReturn : -172.683837890625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2670000
TimeSinceStart : 5291.748975753784
Training Loss : -0.01013844832777977
Baseline Loss : 0.9892343282699585
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 89 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -49.88920211791992
Eval_StdReturn : 21.104299545288086
Eval_MaxReturn : -34.039398193359375
Eval_MinReturn : -79.71558380126953
Eval_AverageEpLen : 150.0
Train_AverageReturn : -58.82589340209961
Train_StdReturn : 47.858924865722656
Train_MaxReturn : 89.71888732910156
Train_MinReturn : -222.2591552734375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2700000
TimeSinceStart : 5351.871840953827
Training Loss : -0.002307629445567727
Baseline Loss : 0.9614861011505127
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 90 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -41.19266891479492
Eval_StdReturn : 22.361751556396484
Eval_MaxReturn : -14.591657638549805
Eval_MinReturn : -69.30403137207031
Eval_AverageEpLen : 150.0
Train_AverageReturn : -65.92961120605469
Train_StdReturn : 47.716468811035156
Train_MaxReturn : 41.70794677734375
Train_MinReturn : -246.83837890625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2730000
TimeSinceStart : 5413.108156681061
Training Loss : -0.008187898434698582
Baseline Loss : 0.9628665447235107
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 91 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -66.9405517578125
Eval_StdReturn : 16.18594741821289
Eval_MaxReturn : -48.36148452758789
Eval_MinReturn : -87.80985260009766
Eval_AverageEpLen : 150.0
Train_AverageReturn : -70.4566879272461
Train_StdReturn : 53.777801513671875
Train_MaxReturn : 73.76544189453125
Train_MinReturn : -255.9276580810547
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2760000
TimeSinceStart : 5477.605392217636
Training Loss : -0.009522868320345879
Baseline Loss : 0.9429216384887695
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 92 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -72.95512390136719
Eval_StdReturn : 57.61494827270508
Eval_MaxReturn : -29.14099884033203
Eval_MinReturn : -154.3555908203125
Eval_AverageEpLen : 150.0
Train_AverageReturn : -70.96666717529297
Train_StdReturn : 55.30207443237305
Train_MaxReturn : 50.09418487548828
Train_MinReturn : -240.61651611328125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2790000
TimeSinceStart : 5539.301580905914
Training Loss : -0.0019640238024294376
Baseline Loss : 0.9490805864334106
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 93 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -36.759361267089844
Eval_StdReturn : 28.419971466064453
Eval_MaxReturn : -10.27203369140625
Eval_MinReturn : -76.182373046875
Eval_AverageEpLen : 150.0
Train_AverageReturn : -65.01476287841797
Train_StdReturn : 62.66578674316406
Train_MaxReturn : 107.36688995361328
Train_MinReturn : -307.4022216796875
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2820000
TimeSinceStart : 5603.232908248901
Training Loss : -0.005758956074714661
Baseline Loss : 0.9490048289299011
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 94 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -39.81312942504883
Eval_StdReturn : 35.3875732421875
Eval_MaxReturn : 9.975419044494629
Eval_MinReturn : -69.09440612792969
Eval_AverageEpLen : 150.0
Train_AverageReturn : -46.47557067871094
Train_StdReturn : 58.055450439453125
Train_MaxReturn : 104.01139831542969
Train_MinReturn : -274.7124938964844
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2850000
TimeSinceStart : 5663.557804822922
Training Loss : -0.0076228477992117405
Baseline Loss : 0.9389312863349915
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 95 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -12.305679321289062
Eval_StdReturn : 22.490093231201172
Eval_MaxReturn : 18.162866592407227
Eval_MinReturn : -35.44293975830078
Eval_AverageEpLen : 150.0
Train_AverageReturn : -34.386512756347656
Train_StdReturn : 52.29389953613281
Train_MaxReturn : 86.04765319824219
Train_MinReturn : -212.36361694335938
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2880000
TimeSinceStart : 5728.497929811478
Train_AverageReturn : 321.0142822265625
Train_StdReturn : 49.96658706665039
Train_MaxReturn : 445.4423828125
Train_MinReturn : 158.33453369140625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2580000
TimeSinceStart : 5097.370741844177
Training Loss : -0.024428831413388252
Baseline Loss : 0.746217668056488
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 86 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 225.8421173095703
Eval_StdReturn : 32.779754638671875
Eval_MaxReturn : 272.08270263671875
Eval_MinReturn : 199.8714599609375
Eval_AverageEpLen : 150.0
Train_AverageReturn : 310.9049987792969
Train_StdReturn : 53.95805740356445
Train_MaxReturn : 460.45721435546875
Train_MinReturn : 140.8036346435547
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2610000
TimeSinceStart : 5158.689269065857
Training Loss : -0.025076407939195633
Baseline Loss : 0.7494655251502991
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 87 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 196.1491241455078
Eval_StdReturn : 43.52687072753906
Eval_MaxReturn : 257.69879150390625
Eval_MinReturn : 164.59280395507812
Eval_AverageEpLen : 150.0
Train_AverageReturn : 274.76898193359375
Train_StdReturn : 68.50200653076172
Train_MaxReturn : 434.88818359375
Train_MinReturn : 121.22010803222656
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2640000
TimeSinceStart : 5220.556543111801
Training Loss : -0.01529716420918703
Baseline Loss : 0.7396324276924133
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 88 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 311.48541259765625
Eval_StdReturn : 41.7045783996582
Eval_MaxReturn : 342.12518310546875
Eval_MinReturn : 252.52139282226562
Eval_AverageEpLen : 150.0
Train_AverageReturn : 254.98715209960938
Train_StdReturn : 62.4675178527832
Train_MaxReturn : 418.6708984375
Train_MinReturn : 70.310302734375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2670000
TimeSinceStart : 5284.004447698593
Training Loss : -0.022468583658337593
Baseline Loss : 0.7199350595474243
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 89 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 299.6535949707031
Eval_StdReturn : 32.12366485595703
Eval_MaxReturn : 345.0499267578125
Eval_MinReturn : 275.4468688964844
Eval_AverageEpLen : 150.0
Train_AverageReturn : 279.3228454589844
Train_StdReturn : 51.542633056640625
Train_MaxReturn : 379.2555236816406
Train_MinReturn : 110.57504272460938
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2700000
TimeSinceStart : 5344.6782858371735
Training Loss : -0.014143007807433605
Baseline Loss : 0.6994957327842712
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 90 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 266.8652648925781
Eval_StdReturn : 14.849278450012207
Eval_MaxReturn : 283.944091796875
Eval_MinReturn : 247.74346923828125
Eval_AverageEpLen : 150.0
Train_AverageReturn : 296.4737243652344
Train_StdReturn : 40.67437744140625
Train_MaxReturn : 384.4364929199219
Train_MinReturn : 146.7970733642578
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2730000
TimeSinceStart : 5405.118445396423
Training Loss : -0.01722348853945732
Baseline Loss : 0.7365418076515198
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 91 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 292.0646667480469
Eval_StdReturn : 18.130603790283203
Eval_MaxReturn : 305.4727478027344
Eval_MinReturn : 266.4332275390625
Eval_AverageEpLen : 150.0
Train_AverageReturn : 286.3176574707031
Train_StdReturn : 34.89128112792969
Train_MaxReturn : 367.9563293457031
Train_MinReturn : 175.41497802734375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2760000
TimeSinceStart : 5469.690620660782
Training Loss : -0.025671936571598053
Baseline Loss : 0.7496135234832764
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 92 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 202.08900451660156
Eval_StdReturn : 27.66044807434082
Eval_MaxReturn : 230.25302124023438
Eval_MinReturn : 164.4965362548828
Eval_AverageEpLen : 150.0
Train_AverageReturn : 274.5107727050781
Train_StdReturn : 35.38984298706055
Train_MaxReturn : 347.8760681152344
Train_MinReturn : 170.87501525878906
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2790000
TimeSinceStart : 5531.090778589249
Training Loss : -0.02566884458065033
Baseline Loss : 0.7556841373443604
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 93 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 201.6088104248047
Eval_StdReturn : 9.180795669555664
Eval_MaxReturn : 212.9100799560547
Eval_MinReturn : 190.42269897460938
Eval_AverageEpLen : 150.0
Train_AverageReturn : 239.8264617919922
Train_StdReturn : 36.14564514160156
Train_MaxReturn : 355.8855285644531
Train_MinReturn : 113.02787780761719
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2820000
TimeSinceStart : 5595.1751346588135
Training Loss : -0.006089110393077135
Baseline Loss : 0.7021692395210266
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 94 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 199.8272247314453
Eval_StdReturn : 27.17150115966797
Eval_MaxReturn : 235.9085693359375
Eval_MinReturn : 170.33935546875
Eval_AverageEpLen : 150.0
Train_AverageReturn : 202.9062957763672
Train_StdReturn : 34.231990814208984
Train_MaxReturn : 304.5076904296875
Train_MinReturn : 112.43829345703125
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2850000
TimeSinceStart : 5656.281281232834
Training Loss : -0.014102588407695293
Baseline Loss : 0.7643170952796936
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 95 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 276.2972106933594
Eval_StdReturn : 8.54840087890625
Eval_MaxReturn : 286.71990966796875
Eval_MinReturn : 265.78131103515625
Eval_AverageEpLen : 150.0
Train_AverageReturn : 214.22027587890625
Train_StdReturn : 36.55982208251953
Train_MaxReturn : 332.43511962890625
Train_MinReturn : 77.47496032714844
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2880000
TimeSinceStart : 5720.085671901703
Training Loss : -0.015172491781413555
Baseline Loss : 0.712549090385437
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 96 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 205.46238708496094
Eval_StdReturn : 59.753440856933594
Eval_MaxReturn : 289.84332275390625
Eval_MinReturn : 159.32186889648438
Eval_AverageEpLen : 150.0
Train_AverageReturn : 231.5414276123047
Train_StdReturn : 42.96450424194336
Train_MaxReturn : 336.00994873046875
Train_MinReturn : 96.4378890991211
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2910000
TimeSinceStart : 5782.051096200943
Training Loss : -0.03431488573551178
Baseline Loss : 0.6967185139656067
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 97 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 208.34559631347656
Eval_StdReturn : 14.002559661865234
Eval_MaxReturn : 222.45492553710938
Eval_MinReturn : 189.25753784179688
Eval_AverageEpLen : 150.0
Train_AverageReturn : 229.3531036376953
Train_StdReturn : 45.96609878540039
Train_MaxReturn : 333.1888732910156
Train_MinReturn : 41.4058952331543
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2940000
TimeSinceStart : 5844.143944740295
Training Loss : -0.004751540254801512
Baseline Loss : 0.6524196267127991
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 98 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 202.19354248046875
Eval_StdReturn : 36.037757873535156
Eval_MaxReturn : 252.9761199951172
Eval_MinReturn : 173.07029724121094
Eval_AverageEpLen : 150.0
Train_AverageReturn : 235.18203735351562
Train_StdReturn : 44.82286071777344
Train_MaxReturn : 350.5352783203125
Train_MinReturn : 93.63520050048828
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2970000
TimeSinceStart : 5906.190165519714
Training Loss : -0.01928700879216194
Baseline Loss : 0.6886795163154602
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 99 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 264.1204833984375
Eval_StdReturn : 8.709888458251953
Eval_MaxReturn : 271.6181945800781
Eval_MinReturn : 251.9080810546875
Eval_AverageEpLen : 150.0
Train_AverageReturn : 231.16307067871094
Train_StdReturn : 49.92170333862305
Train_MaxReturn : 368.66363525390625
Train_MinReturn : 88.3726577758789
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 3000000
TimeSinceStart : 5969.879862070084
Training Loss : -0.00888257659971714
Baseline Loss : 0.6381245255470276
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...



Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -81.11621856689453
Eval_StdReturn : 18.02962303161621
Eval_MaxReturn : -55.832252502441406
Eval_MinReturn : -96.611572265625
Eval_AverageEpLen : 150.0
Train_AverageReturn : -87.99144744873047
Train_StdReturn : 24.010892868041992
Train_MaxReturn : -12.117118835449219
Train_MinReturn : -160.10861206054688
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2700000
TimeSinceStart : 5345.0877521038055
Training Loss : -0.01550899539142847
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 90 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -82.739501953125
Eval_StdReturn : 4.816413879394531
Eval_MaxReturn : -77.50785827636719
Eval_MinReturn : -89.13278198242188
Eval_AverageEpLen : 150.0
Train_AverageReturn : -86.45435333251953
Train_StdReturn : 23.311960220336914
Train_MaxReturn : -24.706689834594727
Train_MinReturn : -185.13336181640625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2730000
TimeSinceStart : 5405.806177854538
Training Loss : -0.01133112981915474
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 91 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -86.01912689208984
Eval_StdReturn : 11.775617599487305
Eval_MaxReturn : -75.38912963867188
Eval_MinReturn : -102.43592834472656
Eval_AverageEpLen : 150.0
Train_AverageReturn : -83.32230377197266
Train_StdReturn : 17.305667877197266
Train_MaxReturn : -40.453338623046875
Train_MinReturn : -129.9166259765625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2760000
TimeSinceStart : 5471.0650815963745
Training Loss : -0.012779499404132366
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 92 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -72.5930404663086
Eval_StdReturn : 12.358586311340332
Eval_MaxReturn : -55.438995361328125
Eval_MinReturn : -84.06938171386719
Eval_AverageEpLen : 150.0
Train_AverageReturn : -76.93741607666016
Train_StdReturn : 21.892791748046875
Train_MaxReturn : -14.869832992553711
Train_MinReturn : -140.8704376220703
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2790000
TimeSinceStart : 5532.8582463264465
Training Loss : -0.0037012207321822643
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 93 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -54.74491500854492
Eval_StdReturn : 15.987232208251953
Eval_MaxReturn : -36.3404426574707
Eval_MinReturn : -75.32009887695312
Eval_AverageEpLen : 150.0
Train_AverageReturn : -74.11619567871094
Train_StdReturn : 22.059844970703125
Train_MaxReturn : -9.593936920166016
Train_MinReturn : -141.70639038085938
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2820000
TimeSinceStart : 5597.056953907013
Training Loss : -0.018585393205285072
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 94 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -32.70859146118164
Eval_StdReturn : 36.18080520629883
Eval_MaxReturn : 18.337753295898438
Eval_MinReturn : -61.2779426574707
Eval_AverageEpLen : 150.0
Train_AverageReturn : -68.87713623046875
Train_StdReturn : 26.899782180786133
Train_MaxReturn : 15.046394348144531
Train_MinReturn : -144.2150115966797
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2850000
TimeSinceStart : 5658.011693477631
Training Loss : -0.007380241062492132
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 95 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -30.92667579650879
Eval_StdReturn : 33.6611442565918
Eval_MaxReturn : -4.759759902954102
Eval_MinReturn : -78.44962310791016
Eval_AverageEpLen : 150.0
Train_AverageReturn : -64.07757568359375
Train_StdReturn : 32.8206672668457
Train_MaxReturn : 32.14275360107422
Train_MinReturn : -166.49942016601562
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2880000
TimeSinceStart : 5722.053375720978
Training Loss : -0.021832888945937157
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 96 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -23.998624801635742
Eval_StdReturn : 8.008744239807129
Eval_MaxReturn : -13.035174369812012
Eval_MinReturn : -31.942474365234375
Eval_AverageEpLen : 150.0
Train_AverageReturn : -59.272918701171875
Train_StdReturn : 39.62989044189453
Train_MaxReturn : 23.503467559814453
Train_MinReturn : -182.65814208984375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2910000
TimeSinceStart : 5784.07509636879
Training Loss : -0.009471760131418705
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 97 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -79.83625793457031
Eval_StdReturn : 35.09908676147461
Eval_MaxReturn : -31.657867431640625
Eval_MinReturn : -114.27198791503906
Eval_AverageEpLen : 150.0
Train_AverageReturn : -66.4555435180664
Train_StdReturn : 48.66388702392578
Train_MaxReturn : 56.70085906982422
Train_MinReturn : -181.8131103515625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2940000
TimeSinceStart : 5846.429258346558
Training Loss : 0.014175360091030598
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 98 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -106.37837982177734
Eval_StdReturn : 46.11073303222656
Eval_MaxReturn : -45.43317794799805
Eval_MinReturn : -156.9398193359375
Eval_AverageEpLen : 150.0
Train_AverageReturn : -72.25946044921875
Train_StdReturn : 55.8104133605957
Train_MaxReturn : 78.64556121826172
Train_MinReturn : -168.95738220214844
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2970000
TimeSinceStart : 5908.748113632202
Training Loss : -0.00778347160667181
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 99 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -43.08864974975586
Eval_StdReturn : 39.61676788330078
Eval_MaxReturn : -11.342779159545898
Eval_MinReturn : -98.94135284423828
Eval_AverageEpLen : 150.0
Train_AverageReturn : -68.18074798583984
Train_StdReturn : 56.533878326416016
Train_MaxReturn : 85.04395294189453
Train_MinReturn : -197.26174926757812
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 3000000
TimeSinceStart : 5971.710082769394
Training Loss : -0.017236502841114998
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...


Eval_MinReturn : 107.39994812011719
Eval_AverageEpLen : 150.0
Train_AverageReturn : 122.217529296875
Train_StdReturn : 21.665605545043945
Train_MaxReturn : 165.21902465820312
Train_MinReturn : 7.64787483215332
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2700000
TimeSinceStart : 5349.452416419983
Training Loss : -0.027621585875749588
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 90 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 135.2978057861328
Eval_StdReturn : 15.175395965576172
Eval_MaxReturn : 156.75277709960938
Eval_MinReturn : 124.12091064453125
Eval_AverageEpLen : 150.0
Train_AverageReturn : 111.37454986572266
Train_StdReturn : 22.709617614746094
Train_MaxReturn : 158.1368408203125
Train_MinReturn : 32.87136459350586
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2730000
TimeSinceStart : 5410.485357284546
Training Loss : -0.009569618850946426
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 91 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 101.2143325805664
Eval_StdReturn : 5.93574333190918
Eval_MaxReturn : 109.3348159790039
Eval_MinReturn : 95.31210327148438
Eval_AverageEpLen : 150.0
Train_AverageReturn : 117.39117431640625
Train_StdReturn : 26.532676696777344
Train_MaxReturn : 172.67156982421875
Train_MinReturn : -8.158763885498047
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2760000
TimeSinceStart : 5475.232932806015
Training Loss : -0.011082787998020649
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 92 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 97.52627563476562
Eval_StdReturn : 26.03731346130371
Eval_MaxReturn : 124.060302734375
Eval_MinReturn : 62.14882278442383
Eval_AverageEpLen : 150.0
Train_AverageReturn : 95.30744171142578
Train_StdReturn : 40.03116226196289
Train_MaxReturn : 150.1798553466797
Train_MinReturn : -42.90129470825195
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2790000
TimeSinceStart : 5536.96310544014
Training Loss : -0.014553830958902836
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 93 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 89.43810272216797
Eval_StdReturn : 26.085397720336914
Eval_MaxReturn : 116.30680847167969
Eval_MinReturn : 54.11250686645508
Eval_AverageEpLen : 150.0
Train_AverageReturn : 88.90985107421875
Train_StdReturn : 35.828189849853516
Train_MaxReturn : 141.23635864257812
Train_MinReturn : -39.689918518066406
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2820000
TimeSinceStart : 5601.0594255924225
Training Loss : -0.0013402837794274092
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 94 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 87.82520294189453
Eval_StdReturn : 16.00616455078125
Eval_MaxReturn : 99.29112243652344
Eval_MinReturn : 65.1897201538086
Eval_AverageEpLen : 150.0
Train_AverageReturn : 95.74916076660156
Train_StdReturn : 27.010543823242188
Train_MaxReturn : 140.38055419921875
Train_MinReturn : -25.90911865234375
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2850000
TimeSinceStart : 5661.913962364197
Training Loss : -0.012724537402391434
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 95 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 43.74747848510742
Eval_StdReturn : 31.312597274780273
Eval_MaxReturn : 77.87162780761719
Eval_MinReturn : 2.2441482543945312
Eval_AverageEpLen : 150.0
Train_AverageReturn : 90.11640930175781
Train_StdReturn : 32.31856155395508
Train_MaxReturn : 146.05105590820312
Train_MinReturn : -26.210691452026367
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2880000
TimeSinceStart : 5727.106730937958
Training Loss : -0.015933815389871597
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 96 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 54.14817428588867
Eval_StdReturn : 18.49359130859375
Eval_MaxReturn : 69.35858154296875
Eval_MinReturn : 28.117387771606445
Eval_AverageEpLen : 150.0
Train_AverageReturn : 39.624656677246094
Train_StdReturn : 36.59147644042969
Train_MaxReturn : 119.25282287597656
Train_MinReturn : -61.88357925415039
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2910000
TimeSinceStart : 5788.835844755173
Training Loss : 0.0054343999363482
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 97 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 111.3547592163086
Eval_StdReturn : 13.803204536437988
Eval_MaxReturn : 127.68148803710938
Eval_MinReturn : 93.92472839355469
Eval_AverageEpLen : 150.0
Train_AverageReturn : 47.151248931884766
Train_StdReturn : 32.694969177246094
Train_MaxReturn : 131.87109375
Train_MinReturn : -47.56840515136719
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2940000
TimeSinceStart : 5851.540993928909
Training Loss : -0.011929597705602646
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 98 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 96.67278289794922
Eval_StdReturn : 62.326541900634766
Eval_MaxReturn : 146.8865509033203
Eval_MinReturn : 8.829704284667969
Eval_AverageEpLen : 150.0
Train_AverageReturn : 111.1875991821289
Train_StdReturn : 21.878124237060547
Train_MaxReturn : 152.63568115234375
Train_MinReturn : 24.128276824951172
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2970000
TimeSinceStart : 5913.564158201218
Training Loss : -0.01937771774828434
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 99 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 104.51031494140625
Eval_StdReturn : 16.49991798400879
Eval_MaxReturn : 120.52182006835938
Eval_MinReturn : 81.80440521240234
Eval_AverageEpLen : 150.0
Train_AverageReturn : 109.86112976074219
Train_StdReturn : 34.69117736816406
Train_MaxReturn : 159.29489135742188
Train_MinReturn : -5.181462287902832
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 3000000
TimeSinceStart : 5975.1753985881805
Training Loss : -0.012582073919475079
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...


Training Loss : -0.012571863830089569
Baseline Loss : 0.9335076808929443
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 96 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -30.683944702148438
Eval_StdReturn : 26.86979103088379
Eval_MaxReturn : 2.271535873413086
Eval_MinReturn : -63.54553985595703
Eval_AverageEpLen : 150.0
Train_AverageReturn : -13.426054954528809
Train_StdReturn : 46.2911491394043
Train_MaxReturn : 96.32957458496094
Train_MinReturn : -249.8521728515625
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2910000
TimeSinceStart : 5790.1455681324005
Training Loss : -0.01649988628923893
Baseline Loss : 0.928089439868927
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 97 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 18.54341697692871
Eval_StdReturn : 7.647775173187256
Eval_MaxReturn : 24.169239044189453
Eval_MinReturn : 7.730801105499268
Eval_AverageEpLen : 150.0
Train_AverageReturn : -1.9298367500305176
Train_StdReturn : 35.47935104370117
Train_MaxReturn : 100.30091857910156
Train_MinReturn : -104.43525695800781
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2940000
TimeSinceStart : 5853.131739616394
Training Loss : -0.00669332267716527
Baseline Loss : 0.9673659205436707
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 98 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 5.260592937469482
Eval_StdReturn : 21.295188903808594
Eval_MaxReturn : 35.36274719238281
Eval_MinReturn : -10.579707145690918
Eval_AverageEpLen : 150.0
Train_AverageReturn : -5.324737071990967
Train_StdReturn : 33.324317932128906
Train_MaxReturn : 83.91175842285156
Train_MinReturn : -170.56637573242188
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 2970000
TimeSinceStart : 5915.448577165604
Training Loss : -0.004032576456665993
Baseline Loss : 0.9347541332244873
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...




********** Iteration 99 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : -25.302526473999023
Eval_StdReturn : 13.81637954711914
Eval_MaxReturn : -13.736122131347656
Eval_MinReturn : -44.72399139404297
Eval_AverageEpLen : 150.0
Train_AverageReturn : -15.350017547607422
Train_StdReturn : 24.71540069580078
Train_MaxReturn : 72.9502182006836
Train_MinReturn : -122.64268493652344
Train_AverageEpLen : 150.0
Train_EnvstepsSoFar : 3000000
TimeSinceStart : 5976.439497232437
Training Loss : -0.00912544783204794
Baseline Loss : 0.958943784236908
Initial_DataCollection_AverageReturn : -88.6635513305664
Done logging...


