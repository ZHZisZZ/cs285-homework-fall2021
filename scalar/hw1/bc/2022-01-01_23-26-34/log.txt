#!/bin/bash
# NOTE: This script is used for better grouping of experiment data, and the data 
# generated by this script does not follow the homework submission specifications.

export PYTHONPATH=.

video_log_freq=5
eval_batch_size=10000
num_agent_train_steps_per_iter=5000

DATA_DIR=./data
EXP_DIR=${DATA_DIR}/bc/`date +%Y-%m-%d_%H-%M-%S`
LOG_PATH=${EXP_DIR}/log.txt
# clear other data files
rm -rf $(find ${DATA_DIR} -maxdepth 1 -name '*q1_*' 2> /dev/null)
# create data directory for this experiment and logfile
mkdir -p $EXP_DIR; touch $LOG_PATH
# dump experiment commands and hyperparameters (this file) to logfile
cat $0 >> $LOG_PATH; echo "\n\n" >> $LOG_PATH

for env in Ant Humanoid Walker2d HalfCheetah Hopper
do 
    python cs285/scripts/run_hw1.py \
        --expert_policy_file cs285/policies/experts/${env}.pkl \
        --env_name ${env}-v2 --exp_name bc_${env} --n_iter 1 \
        --expert_data cs285/expert_data/expert_data_${env}-v2.pkl \
        --eval_batch_size ${eval_batch_size} \
        --num_agent_train_steps_per_iter ${num_agent_train_steps_per_iter} \
        --video_log_freq ${video_log_freq} >> $LOG_PATH
done

mv $(find ${DATA_DIR} -maxdepth 1 -name '*q1_*' 2> /dev/null) $EXP_DIR



########################
logging outputs to  /home/zzh/Desktop/CS285/cs285-homework-fall2021/hw1/cs285/scripts/../../data/q1_bc_Ant_Ant-v2_2022-01-01_23-26-34
########################
Using GPU id 0
Loading expert policy from... cs285/policies/experts/Ant.pkl
obs (1, 111) (1, 111)
Done restoring expert policy...


********** Iteration 0 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 4677.927734375
Eval_StdReturn : 126.8599853515625
Eval_MaxReturn : 4909.62158203125
Eval_MinReturn : 4424.70947265625
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 4713.6533203125
Train_StdReturn : 12.196533203125
Train_MaxReturn : 4725.849609375
Train_MinReturn : 4701.45654296875
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 0
TimeSinceStart : 11.350284576416016
Training Loss : -2.446242570877075
Initial_DataCollection_AverageReturn : 4713.6533203125
Done logging...


########################
logging outputs to  /home/zzh/Desktop/CS285/cs285-homework-fall2021/hw1/cs285/scripts/../../data/q1_bc_Humanoid_Humanoid-v2_2022-01-01_23-26-49
########################
Using GPU id 0
Loading expert policy from... cs285/policies/experts/Humanoid.pkl
obs (1, 376) (1, 376)
Done restoring expert policy...


********** Iteration 0 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 291.07781982421875
Eval_StdReturn : 30.324705123901367
Eval_MaxReturn : 405.86663818359375
Eval_MinReturn : 224.61758422851562
Eval_AverageEpLen : 53.833333333333336
Train_AverageReturn : 10344.517578125
Train_StdReturn : 20.9814453125
Train_MaxReturn : 10365.4990234375
Train_MinReturn : 10323.5361328125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 0
TimeSinceStart : 13.890806674957275
Training Loss : 0.1651475578546524
Initial_DataCollection_AverageReturn : 10344.517578125
Done logging...


########################
logging outputs to  /home/zzh/Desktop/CS285/cs285-homework-fall2021/hw1/cs285/scripts/../../data/q1_bc_Walker2d_Walker2d-v2_2022-01-01_23-27-06
########################
Using GPU id 0
Loading expert policy from... cs285/policies/experts/Walker2d.pkl
obs (1, 17) (1, 17)
Done restoring expert policy...


********** Iteration 0 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 5013.5361328125
Eval_StdReturn : 898.9456787109375
Eval_MaxReturn : 5521.576171875
Eval_MinReturn : 2317.072265625
Eval_AverageEpLen : 934.0
Train_AverageReturn : 5566.845703125
Train_StdReturn : 9.237548828125
Train_MaxReturn : 5576.08349609375
Train_MinReturn : 5557.6083984375
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 0
TimeSinceStart : 10.696754932403564
Training Loss : -1.3312077522277832
Initial_DataCollection_AverageReturn : 5566.845703125
Done logging...


########################
logging outputs to  /home/zzh/Desktop/CS285/cs285-homework-fall2021/hw1/cs285/scripts/../../data/q1_bc_HalfCheetah_HalfCheetah-v2_2022-01-01_23-27-19
########################
Using GPU id 0
Loading expert policy from... cs285/policies/experts/HalfCheetah.pkl
obs (1, 17) (1, 17)
Done restoring expert policy...


********** Iteration 0 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 4134.45361328125
Eval_StdReturn : 61.3955192565918
Eval_MaxReturn : 4244.86328125
Eval_MinReturn : 4042.0498046875
Eval_AverageEpLen : 1000.0
Train_AverageReturn : 4205.7783203125
Train_StdReturn : 83.038818359375
Train_MaxReturn : 4288.81689453125
Train_MinReturn : 4122.7392578125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 0
TimeSinceStart : 9.739197492599487
Training Loss : -2.190131664276123
Initial_DataCollection_AverageReturn : 4205.7783203125
Done logging...


########################
logging outputs to  /home/zzh/Desktop/CS285/cs285-homework-fall2021/hw1/cs285/scripts/../../data/q1_bc_Hopper_Hopper-v2_2022-01-01_23-27-32
########################
Using GPU id 0
Loading expert policy from... cs285/policies/experts/Hopper.pkl
obs (1, 11) (1, 11)
Done restoring expert policy...


********** Iteration 0 ************

Collecting data to be used for training...

Training agent using sampled data from replay buffer...

Beginning logging procedure...

Collecting data for eval...
Eval_AverageReturn : 807.9420776367188
Eval_StdReturn : 351.1786804199219
Eval_MaxReturn : 1872.687255859375
Eval_MinReturn : 421.4342346191406
Eval_AverageEpLen : 261.5128205128205
Train_AverageReturn : 3772.67041015625
Train_StdReturn : 1.9483642578125
Train_MaxReturn : 3774.61865234375
Train_MinReturn : 3770.721923828125
Train_AverageEpLen : 1000.0
Train_EnvstepsSoFar : 0
TimeSinceStart : 10.212641954421997
Training Loss : -2.0189826488494873
Initial_DataCollection_AverageReturn : 3772.67041015625
Done logging...


